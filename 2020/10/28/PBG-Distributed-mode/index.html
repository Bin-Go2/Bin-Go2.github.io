

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon-32x32.ico">
  <link rel="icon" type="image/png" href="/img/favicon-32x32.ico">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="æˆ‘ç†Šäººæ—æ°¸ä¸ä¸ºå¥´ï¼ï¼å¼å¼å¼ï¼ï¼ï¼">
  <meta name="author" content="Bin">
  <meta name="keywords" content="">
  <title>PyTorch-BigGraph åˆ†å¸ƒå¼ - BIN&#39;S BLOG</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.4.0/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- ä¸»é¢˜ä¾èµ–çš„å›¾æ ‡åº“ï¼Œä¸è¦è‡ªè¡Œä¿®æ”¹ -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- è‡ªå®šä¹‰æ ·å¼ä¿æŒåœ¨æœ€åº•éƒ¨ -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.8.6","typing":{"enable":false,"typeSpeed":70,"cursorChar":"","loop":false},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"copy_btn":true,"image_zoom":{"enable":true},"lazyload":{"enable":true,"onlypost":false},"web_analytics":{"enable":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null}}};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.1.1"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>BIN'S BLOG</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                Home
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                Archives
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                Categories
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                Tags
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                About
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" href="javascript:">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="PyTorch-BigGraph åˆ†å¸ƒå¼">
              
                PyTorch-BigGraph åˆ†å¸ƒå¼
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2020-10-28 19:13" pubdate>
        October 28, 2020 pm
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      3.2k å­—
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      45
       min
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">PyTorch-BigGraph åˆ†å¸ƒå¼</h1>
            
            <div class="markdown-body">
              <h1 id="PyTorch-BigGraph-åˆ†å¸ƒå¼"><a href="#PyTorch-BigGraph-åˆ†å¸ƒå¼" class="headerlink" title="PyTorch-BigGraph åˆ†å¸ƒå¼"></a>PyTorch-BigGraph åˆ†å¸ƒå¼</h1><p>PBG can perform training across multiple machines which communicate over a network, in order to reduce training time on large graphs. Distributed training is able to concurrently utilize larger computing resources, as well as to keep the entire model stored in memory across all machines, avoiding the need to swap it to disk. On each machine, the training is further parallelized across multiple subprocesses.<br>PBGå¯ä»¥åœ¨é€šè¿‡ç½‘ç»œè¿›è¡Œé€šä¿¡çš„å¤šå°æœºå™¨ä¸Šæ‰§è¡Œè®­ç»ƒï¼Œä»¥å‡å°‘å¤§å›¾ä¸Šçš„è®­ç»ƒæ—¶é—´ã€‚åˆ†å¸ƒå¼è®­ç»ƒèƒ½å¤Ÿåˆ©ç”¨å·¨å¤§çš„è®¡ç®—èµ„æºï¼ŒåŒæ—¶å…¶å¯ä»¥å°†æ•´ä¸ªæ¨¡å‹å­˜å‚¨åœ¨æ‰€æœ‰æœºå™¨çš„å†…å­˜ä¸­è€Œä¸éœ€è¦è¿›è¡Œç£ç›˜äº¤æ¢ã€‚åœ¨æ¯ä¸€å°æœºå™¨ä¸Šï¼Œè®­ç»ƒé€šè¿‡å¤šä¸ªå­è¿›ç¨‹è¿›è¡Œã€‚</p>
<h2 id="Set-up"><a href="#Set-up" class="headerlink" title="Set up"></a>Set up</h2><p>In order to perform distributed training, the configuration file must first be updated to contain the specification of the desired distributed setup. If training should be carried out on ğ‘ machines, then the num_machines key in the config must be set to that value. In addition, the distributed_init_method must describe a way for the trainers to discover each other and set up their communication. All valid values for the init_method argument of torch.distributed.init_process_group() are accepted here. Usually this will be a path to a shared network filesystem or the network address of one of the machines. See the PyTorch docs for more information and a complete reference.<br>ä¸ºäº†æ‰§è¡Œåˆ†å¸ƒå¼è®­ç»ƒï¼Œé…ç½®æ–‡ä»¶å¿…é¡»é¦–å…ˆè¿›è¡Œç›¸åº”é…ç½®ï¼Œå…¶éœ€è¦åŒ…æ‹¬åˆ†å¸ƒå¼éƒ¨ç½²çš„ç›¸å…³é…ç½®ã€‚å¦‚æœè®­ç»ƒåœ¨Nå°æœºå™¨ä¸Šè¿è¡Œï¼Œnum_machineså¿…é¡»è¦è¦é…ç½®æˆNã€‚å¦å¤–ï¼Œdistributed_init_methodå¿…é¡»æè¿°å„ä¸ªæœºå™¨ä¹‹é—´çš„é€šä¿¡æ–¹å¼ã€‚è¿™é‡Œèƒ½å¤Ÿæ¥å—æ‰€æœ‰torch.distributed.init_process_group()é‡Œé¢çš„å‚æ•°ã€‚é€šå¸¸æ¥è¯´ï¼Œåˆ†å¸ƒå¼è®­ç»ƒå°†ä¸€å°è®¡ç®—æœºçš„ç½‘ç»œåœ°å€è®¾ç½®ä¸ºæ–‡ä»¶å…±äº«ç³»ç»Ÿçš„åœ°å€ã€‚ æœ‰å…³æ›´å¤šä¿¡æ¯å’Œå®Œæ•´å‚è€ƒï¼Œè¯·å‚è§PyTorchæ–‡æ¡£ã€‚</p>
<p>To launch distributed training, call torchbiggraph_train â€“rank rank config.py on each machine, with rank replaced by an integer between 0 and ğ‘âˆ’1 (inclusive), different for each machine. Each machine must have PBG installed and have a copy of the config file.<br>è¦å¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒï¼Œé¦–å…ˆåœ¨æ¯å°æœºå™¨ä¸Šè°ƒç”¨torchbiggraph_train â€“rank rank config.pyï¼Œ å…¶ä¸­æ¯å°æœºå™¨æœ‰å„è‡ªçš„rankå€¼ï¼ˆä»1åˆ°N-1ï¼‰ã€‚æ¯å°æœºå™¨å¿…é¡»å®‰è£…äº†PBGï¼Œå¹¶ä¸”å…·æœ‰é…ç½®æ–‡ä»¶çš„å‰¯æœ¬ã€‚</p>
<p>In some uncommon circumstances, one may want to store the embeddings on different machines than the ones that are performing training. In that case, one would set num_partition_servers to a positive value and manually launch some instances of torchbiggraph_partitionserver as well. See below for more information on this.<br>ç‰¹å®šæƒ…å†µä¸‹ï¼Œå¯èƒ½æœ‰å°†åµŒå…¥å­˜å‚¨åœ¨ä¸åŒæœºå™¨è€Œä¸æ˜¯ä¸€å°æœºå™¨ä¸Šçš„éœ€æ±‚ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œéœ€è¦åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®num_partition_serversä¸ºä¸€ä¸ªæ­£æ•°å¹¶ä¸”æ‰‹åŠ¨ä½¿ç”¨torchbiggraph_partitionserveræ¥å¯åŠ¨ä¸€äº›å®ä¾‹ã€‚è¯¦æƒ…è§ä¸‹æ–‡</p>
<blockquote>
<p>Tip<br> A good default setting is to set num_machines to half the number of partitions (see below why) and leave num_partition_servers unset.<br> ä¸€ä¸ªå¥½çš„é»˜è®¤è®¾ç½®æ˜¯å°†num_machinesè®¾ç½®ä¸ºåˆ†åŒºæ•°çš„ä¸€åŠï¼ˆè¯·å‚é˜…ä¸‹é¢çš„åŸå› ï¼‰ï¼Œå¹¶ä¿æŒnum_partition_serversä¸ºæœªè®¾ç½®çŠ¶æ€ã€‚</p>
</blockquote>
<blockquote>
<p>Warning<br> Unpartitioned entity types should not be used with distributed training. While the embeddings of partitioned entity types are only in use on one machine at a time and are swapped between machines as needed, the embeddings of unpartitioned entity types are communicated asynchronously through a poorly-optimized parameter server which was designed for sharing relation parameters, which are small. It cannot support synchronizing large amounts of parameters, e.g. an unpartitioned entity type with more than 1000 entities. In that case, the quality of the unpartitioned embeddings will likely be very poor.<br> æœªåˆ†åŒºçš„å®ä½“ä¸åº”è¯¥è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒã€‚å®ä½“ç±»å‹çš„åˆ†åŒºä»…åœ¨åŒä¸€æ—¶åˆ»åœ¨æŸä¸€å°æœºå™¨ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¸”æ ¹æ®éœ€è¦åœ¨ä¸åŒæœºå™¨é—´è¿›è¡Œäº¤æ¢ã€‚æœªåˆ†åŒºçš„å®ä½“ç±»å‹çš„åµŒå…¥è®¡ç®—æ˜¯é€šè¿‡æ¬ ä¼˜åŒ–çš„å‚æ•°æœåŠ¡åœ¨æœºå™¨ä¹‹é—´è¿›è¡Œå¼‚æ­¥äº¤æ¢çš„ï¼Œè¿™ä¸ªæœåŠ¡åªæ˜¯è®¾è®¡æˆç”¨æ¥è¿›è¡Œå…³ç³»å‚æ•°çš„å…±äº«å¹¶ä¸”å¾ˆå°ã€‚å…¶ä¸èƒ½æ”¯æŒå¤§é‡å‚æ•°çš„åŒæ­¥ã€‚ä¾‹å¦‚ï¼šå¯¹äºä¸€ä¸ªæœªåˆ†åŒºçš„è¶…è¿‡1000ä¸ªå®ä½“çš„å®ä½“ç±»å‹ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæœªåˆ†åŒºçš„å¾—åˆ°çš„åµŒå…¥è´¨é‡ä¼šå¾ˆå·®ã€‚</p>
</blockquote>
<h2 id="Communication-protocols"><a href="#Communication-protocols" class="headerlink" title="Communication protocols"></a>Communication protocols</h2><p> Distributed training requires the machines to coordinate and communicate in various ways for different purposes. These tasks are:<br> åˆ†å¸ƒå¼è®­ç»ƒæ±‚æœºå™¨ä»¥å„ç§æ–¹å¼é’ˆå¯¹ä¸åŒç›®çš„è¿›è¡Œåè°ƒå’Œé€šä¿¡ã€‚ è¿™äº›ä»»åŠ¡æ˜¯ï¼š</p>
<p> â€¢ synchronizing which trainer is operating on which bucket, assigning them so that there are no conflicts<br> â€¢ passing the embeddings of an entity partition from one trainer to the next one when needed (as this is data that is only accessed by one trainer at a time)<br> â€¢ sharing parameters that all trainers need access to simultaneously, by collecting and redistributing the updates to them.</p>
<p> â€¢ åŒæ­¥å“ªä¸ªè®­ç»ƒå™¨åœ¨è®­ç»ƒå“ªä¸ªæ¡¶ï¼Œåˆ†é…å¥½ä»»åŠ¡ä»¥é˜²äº§ç”Ÿå†²çª<br> â€¢ å°†ä¸€ä¸ªå®ä½“åˆ†åŒºçš„åµŒå…¥ä»ä¸€ä¸ªè®­ç»ƒå™¨ä¼ å…¥åˆ°å¦ä¸€ä¸ªè®­ç»ƒå™¨ ï¼ˆå› ä¸ºä¸€ä¸ªè®­ç»ƒå™¨åªä½¿ç”¨ä¸€æ¬¡åœ¨ä¸€ä¸ªepochä¸­ï¼‰<br> â€¢ é€šè¿‡æ”¶é›†å’Œé‡æ–°åˆ†å‘å‚æ•°æ¥å®ç°å„ä¸ªè®­ç»ƒå™¨é—´çš„å‚æ•°å…±äº«</p>
<p> Each of these is implemented by a separate â€œprotocolâ€, and each trainer takes part in some or all of them by launching subprocesses that act as clients or servers for the different protocols. These protocols are explained below to provide insight into the system.</p>
<p> è¿™äº›ä¸­çš„æ¯ä¸€ä¸ªä»»åŠ¡éƒ½ç”±å•ç‹¬çš„â€œåè®®â€å®ç°ï¼Œå¹¶ä¸”æ¯ä¸ªè®­ç»ƒå™¨éƒ½é€šè¿‡å¯åŠ¨å……å½“é’ˆå¯¹ä¸åŒåè®®çš„å®¢æˆ·ç«¯æˆ–æœåŠ¡å™¨çš„å­è¿›ç¨‹æ¥å‚ä¸æ•´ä¸ªè¿‡ç¨‹çš„ä¸€éƒ¨åˆ†æˆ–å…¨éƒ¨ã€‚ä¸‹é¢è¯´æ˜è¿™äº›åè®®ä»¥æä¾›å¯¹ç³»ç»Ÿçš„äº†è§£ã€‚</p>
<h3 id="Synchronizing-bucket-access"><a href="#Synchronizing-bucket-access" class="headerlink" title="Synchronizing bucket access"></a>Synchronizing bucket access</h3><p>PBG parallelizes training across multiple machines by having them all operate simultaneously on disjoint buckets (i.e., buckets that donâ€™t have any partition in common). Therefore, each partition is in use by up to one machine at a time, and each machine uses up to two partitions (the only exception is for buckets â€œon the diagonalâ€, that have the same left- and right-hand side partition). This means that the number of buckets one can simultaneously train on is about half the total number of partitions.<br>PBGé€šè¿‡ä½¿å®ƒä»¬åŒæ—¶åœ¨ä¸ç›¸äº¤çš„å­˜å‚¨æ¡¶ï¼ˆå³æ²¡æœ‰å…±åŒåˆ†åŒºçš„å­˜å‚¨æ¡¶ï¼‰ä¸ŠåŒæ—¶è¿è¡Œæ¥å¹¶è¡ŒåŒ–å¤šå°æœºå™¨çš„åŸ¹è®­ã€‚ï¼ˆä¹Ÿå°±æ˜¯æ‰€è°“çš„æ•°æ®åˆ†åŒºï¼‰ã€‚å› æ­¤ï¼Œæ¯ä¸ªåˆ†åŒºä¸€æ¬¡æœ€å¤šåœ¨ä¸€å°æœºå™¨ä¸Šè¢«ä½¿ç”¨ï¼Œå¹¶ä¸”è¢«ä¸ªæœºå™¨ä¸€æ¬¡è®­ç»ƒæœ€å¤šç”¨ä¸¤ä¸ªåˆ†åŒºï¼ˆå”¯ä¸€çš„ä¾‹å¤–æ˜¯â€œå¯¹è§’çº¿â€ä¸Šçš„å­˜å‚¨æ¡¶ï¼Œå®ƒä»¬å…·æœ‰ç›¸åŒçš„å·¦ä¾§å’Œå³ä¾§åˆ†åŒºï¼‰ï¼‰ã€‚è¿™æ„å‘³åŒæ—¶å¯ä»¥è®­ç»ƒçš„æ¡¶çš„æ•°é‡å¤§æ¦‚æ˜¯ä¸€èˆ¬çš„åˆ†åŒºæ•°é‡ã€‚</p>
<p>The way the machines agree on which one gets to operate on what bucket is through a â€œlock serverâ€. The server is implicitly started by the trainer of rank 0. All other machines connect to it as clients, ask for a new bucket to operate on (when they need one), get a bucket assigned from the server (or none, if all buckets have already been trained on or are â€œlockedâ€ because their partitions are in use by another trainer), train on it, then report it as done and repeat. The lock server tries to optimize I/O by preferring, when a trainer asks for a bucket, to assign one that has as many partitions in common with the previous bucket that the trainer trained on, so that these partitions can be kept in memory rather than having to be unloaded and reloaded.<br>æœºå™¨é—´é€šè¿‡â€œé”æœåŠ¡â€çš„å½¢å¼æ¥è¡¨æ˜å“ªä¸ªæ¡¶æ­£åœ¨è¢«æ“ä½œã€‚æœåŠ¡å™¨ç”±çº§åˆ«0ï¼ˆmasterï¼‰çš„è®­ç»ƒå™¨éšå¼å¯åŠ¨ï¼Œæ‰€æœ‰å…¶ä»–æœºå™¨ä½œä¸ºå®¢æˆ·ç«¯è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œå½“å®ƒä»¬éœ€è¦æ–°çš„æ¡¶çš„æ—¶å€™ï¼Œä»–ä»¬å‘masterè¯·æ±‚å¹¶ä¸”å¾—åˆ°ä¸€ä¸ªæ–°çš„æ¡¶æ•°æ®ï¼ˆå¯èƒ½æ²¡æ‹¿åˆ°ï¼Œå› ä¸ºå¯èƒ½å­˜åœ¨æ‰€æœ‰çš„æ¡¶éƒ½è¢«è®­ç»ƒå®Œä¸€æ¬¡äº†æˆ–è€…æ¡¶æ˜¯é”ä½çš„çŠ¶æ€ï¼‰æ¥è¿›è¡Œè®­ç»ƒã€æŠ¥å‘Šç„¶åé‡å¤æ‰§è¡Œã€‚å½“ä¸€ä¸ªè®­ç»ƒå™¨è¯·æ±‚æ–°æ¡¶çš„æ—¶å€™ï¼Œé”å®šæœåŠ¡å™¨é€šè¿‡ä¼˜å…ˆåˆ†é…ä¸è¯¥è®­ç»ƒå™¨ä¸Šä¸€æ¬¡è®­ç»ƒçš„æ•°æ®æœ‰è¾ƒå¤šç›¸åŒåˆ†åŒºçš„æ¡¶æ¥ä¼˜åŒ–I/Oï¼Œé€šè¿‡è¿™æ ·é‚£äº›åˆ†åŒºå°±å¯ä»¥è¢«ä¿ç•™åœ¨å†…å­˜ä¸Šè€Œä¸æ˜¯è¢«å¸è½½ç„¶ååˆåŠ è½½ã€‚</p>
<h3 id="Exchanging-partition-embeddings"><a href="#Exchanging-partition-embeddings" class="headerlink" title="Exchanging partition embeddings"></a>Exchanging partition embeddings</h3><p>When a trainer starts operating on a bucket it needs access to the embeddings of all entities (of all types) that belong to either the left- or the right-hand side partition of the bucket. The â€œlockingâ€ mechanism of the lock server ensures that at most one trainer is operating on a partition at any given time. This doesnâ€™t hold for unpartitioned entity types, which are shared among all trainers; see below. Thus each trainer has exclusive hold of the partitions itâ€™s training on.<br>å½“ä¸€ä¸ªè®­ç»ƒå™¨å¼€å§‹åœ¨ä¸€ä¸ªæ¡¶ä¸Šæ‰§è¡Œè®­ç»ƒçš„æ—¶å€™ï¼Œä»–éœ€è¦è·å–é¦–å…ˆè·å–å±äºæ¡¶çš„å·¦ä¾§æˆ–å³ä¾§åˆ†åŒºçš„æ‰€æœ‰å®ä½“ï¼ˆæ‰€æœ‰ç±»å‹ï¼‰çš„åµŒå…¥ã€‚ é”å®šæœåŠ¡å™¨çš„â€œé”å®šâ€æœºåˆ¶ç¡®ä¿åœ¨ä»»ä½•ç»™å®šæ—¶é—´æœ€å¤šæœ‰ä¸€ä¸ªè®­ç»ƒå™¨åœ¨ä¸€ä¸ªåˆ†åŒºä¸Šè¿è¡Œã€‚è¿™ä¸ªæœºåˆ¶ä¸é€‚ç”¨äºæœªåˆ†åŒºçš„å®ä½“ï¼Œå› ä¸ºä»–ä»¬è¢«æ‰€æœ‰çš„è®­ç»ƒå™¨å…±äº«ã€‚è§ä¸‹æ–‡ã€‚ å› æ­¤ï¼Œæ¯ä¸ªè®­ç»ƒå™¨åœ¨è®­ç»ƒæ—¶å¯ä»¥ç‹¬å å…¶è®­ç»ƒçš„åˆ†åŒºã€‚</p>
<p>Once a trainer starts working on a new bucket it needs to acquire the embeddings of its partitions, and once itâ€™s done it needs to release them and make them available, in their updated version, to the next trainer that needs them. In order to do this, thereâ€™s a system of so-called â€œpartition serversâ€ that store the embeddings, provide them upon request to the trainers who need them, receive back the updated embedding and store it.<br>å½“ä¸€ä¸ªè®­ç»ƒå™¨å¼€å§‹åœ¨æ–°çš„æ¡¶ä¸Šä¸Šå·¥ä½œåï¼Œéœ€è¦è·å–å…¶åˆ†åŒºçš„åµŒå…¥å†…å®¹ï¼Œå®Œæˆåï¼Œéœ€è¦é‡Šæ”¾å®ƒä»¬å¹¶ä»¥æ›´æ–°ç‰ˆæœ¬å°†å…¶æä¾›ç»™éœ€è¦è¯¥è®­ç»ƒçš„ä¸‹ä¸€ä¸ªè®­ç»ƒå™¨ã€‚ ä¸ºæ­¤ï¼Œæœ‰ä¸€ä¸ªæ‰€è°“çš„â€œåˆ†åŒºæœåŠ¡å™¨â€ç³»ç»Ÿï¼Œç”¨äºå­˜å‚¨åµŒå…¥å†…å®¹ï¼Œå¹¶æ ¹æ®éœ€è¦å°†å…¶æä¾›ç»™éœ€è¦å®ƒä»¬çš„è®­ç»ƒå™¨ï¼Œå¹¶æ¥æ”¶æ›´æ–°çš„åµŒå…¥å†…å®¹å¹¶è¿›è¡Œå­˜å‚¨ã€‚</p>
<p>This service is optional, and is disabled when num_partition_servers is set to zero. In that case the trainers â€œsendâ€ each other the embeddings simply by writing them to the checkpoint directory (which should reside on a shared disk) and then fetching them back from there.<br>æ­¤æœåŠ¡æ˜¯å¯é€‰çš„ï¼Œå¹¶ä¸”åœ¨num_partition_serversè®¾ç½®ä¸ºé›¶æ—¶è¢«ç¦ç”¨ã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè®­ç»ƒå™¨åªéœ€å°†åµŒå…¥å†…å®¹å†™å…¥â€œæ£€æŸ¥ç‚¹â€ç›®å½•ï¼ˆåº”ä½äºå…±äº«ç£ç›˜ä¸Šï¼‰ï¼Œç„¶åä»é‚£é‡Œå–å›å®ƒä»¬ï¼Œå³å¯ç›¸äº’â€œå‘é€â€åµŒå…¥å†…å®¹ã€‚</p>
<p>When this system is enabled, it can operate in two modes. The simplest mode is triggered when num_partition_servers is -1 (the default): in that case all trainers spawn a local process that acts as a partition server. If, on the other hand, num_partition_servers is a positive value then the trainers will not spawn any process, but will instead connect to the partition servers that the user must have provisioned manually by launching the torchbiggraph_partitionserver command on the appropriate number of machines.<br>å¯ç”¨æ­¤ç³»ç»Ÿåï¼Œå®ƒå¯ä»¥åœ¨ä¸¤ç§æ¨¡å¼ä¸‹è¿è¡Œã€‚ å½“num_partition_serversä¸º-1ï¼ˆé»˜è®¤å€¼ï¼‰æ—¶ï¼Œå°†è§¦å‘æœ€ç®€å•çš„æ¨¡å¼ï¼šåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‰€æœ‰è®­ç»ƒå™¨éƒ½ä¼šç”Ÿæˆä¸€ä¸ªå……å½“åˆ†åŒºæœåŠ¡å™¨çš„æœ¬åœ°è¿›ç¨‹ã€‚ å¦ä¸€æ–¹é¢ï¼Œå¦‚æœnum_partition_serversä¸ºæ­£å€¼ï¼Œé‚£ä¹ˆè®­ç»ƒå™¨å°†ä¸ä¼šäº§ç”Ÿä»»ä½•è¿›ç¨‹ï¼Œè€Œæ˜¯å°†ä¼šè¿æ¥åˆ°ç”¨æˆ·æ‰‹åŠ¨è®¾ç½®çš„æä¾›çš„åˆ†åŒºæœåŠ¡å™¨ä¸Šï¼Œç”¨æˆ·é€šè¿‡åœ¨é€‚å½“æ•°é‡çš„æœºå™¨ä¸Šè¿è¡Œtorchbiggraph_partitionserveræ¥å®ç°é¢„å…ˆä¾›ç»™ã€‚</p>
<h3 id="Updating-shared-parameters"><a href="#Updating-shared-parameters" class="headerlink" title="Updating shared parameters"></a>Updating shared parameters</h3><p>Some parameters of the model need to be used by all trainers at the same time (this includes the operator weights, the global embeddings of each entity type, the embeddings of the unpartitioned entities). These are parameters that donâ€™t depend on what bucket the trainer is operating on, and therefore are always present on all trainers (as opposed to the entity embeddings, which are loaded and unloaded as needed). These parameters are synchronized using a series of â€œparameter serversâ€. Each trainer starts a local parameter server (in a separate subprocess) and connects to all other parameter servers. Each parameter that is shared between trainers is then stored in a parameter server (possibly sharded across several of them, if too large). Each trainer also has a loop (also in a separate subprocess) which, at regular intervals, goes over each shared parameter, computes the difference between its current local value and the value it had when it was last synced with the server where the parameter is hosted and sends that delta to that server. The server, in turn, accumulates all the deltas it receives from all trainers, updates the value of the parameter and sends this new value back to the trainers. The parameter server performs throttling to 100 updates/s or 1GB/s, in order to prevent the parameter server from starving the other communication.<br>æ‰€æœ‰è®­ç»ƒå™¨å¿…é¡»åŒæ—¶ä½¿ç”¨æ¨¡å‹çš„æŸäº›å‚æ•°ï¼ˆè¿™åŒ…æ‹¬æ“ä½œå‘˜æƒé‡ï¼Œæ¯ç§å®ä½“ç±»å‹çš„å…¨å±€åµŒå…¥ï¼Œæœªåˆ†åŒºå®ä½“çš„åµŒå…¥ï¼‰ã€‚è¿™äº›å‚æ•°å¹¶ä¸å–å†³äºé‚£äº›è®­ç»ƒå™¨æ­£åœ¨æ“ä½œçš„æ¡¶ï¼Œå› æ­¤å…¶å§‹ç»ˆå­˜åœ¨äºæ‰€æœ‰è®­ç»ƒå™¨ä¸Šï¼ˆä¸å®ä½“åµŒå…¥æƒ…å†µç›¸ä»¿ï¼Œå®ä½“åµŒå…¥æ ¹æ®éœ€è¦è¿›è¡ŒåŠ è½½å’Œå¸è½½ï¼‰è¿™äº›å‚æ•°ä½¿ç”¨ä¸€ç³»åˆ—â€œå‚æ•°æœåŠ¡å™¨â€è¿›è¡ŒåŒæ­¥ã€‚æ¯ä¸€ä¸ªè®­ç»ƒå™¨å¼€å¯ä¸€ä¸ªæœ¬åœ°çš„å‚æ•°æœåŠ¡å™¨ï¼ˆä»¥ä¸€ä¸ªç‹¬è‡ªçš„å­è¿›ç¨‹ï¼‰å¹¶ä¸”å’Œå…¶ä»–æ‰€æœ‰çš„å‚æ•°æœåŠ¡å™¨è¿›è¡Œè¿æ¥ã€‚æ¯ä¸€ä¸ªè¢«è®­ç»ƒå™¨å…±äº«çš„å‚æ•°è¢«å­˜å‚¨åœ¨å‚æ•°æœåŠ¡å™¨ä¸­ï¼ˆå¦‚æœå‚æ•°å¤ªå¤§çš„è¯ï¼Œåˆ™å¯èƒ½å°†å…¶åˆ†æ•£åœ¨å…¶ä¸­çš„å‡ ä¸ªæœåŠ¡å™¨ä¸­ï¼‰ã€‚æ¯ä¸€ä¸ªè®­ç»ƒå™¨è¿˜æœ‰ä¸€ä¸ªloopï¼ˆåŒæ ·ä¹Ÿåœ¨ä¸€ä¸ªå­è¿›ç¨‹ä¸­ï¼‰ï¼Œè¯¥å¾ªç¯ä»¥å›ºå®šçš„æ—¶é—´é—´éš”éå†æ¯ä¸ªå…±äº«å‚æ•°ï¼Œè®¡ç®—å…¶å½“å‰æœ¬åœ°å€¼ä¸ä¸Šæ¬¡ä¸è¯¥æœåŠ¡å™¨ä¸Šæ¬¡ä¸æœåŠ¡å™¨åŒæ­¥æ—¶æ‰€å…·æœ‰çš„å€¼ä¹‹é—´çš„å·®ï¼Œé‚£äº›æœåŠ¡å™¨çš„å‚æ•°å€¼æ˜¯è¢«æ‰˜ç®¡å¹¶ä¸”å‘é€åˆ°æœ¬åœ°çš„å­è¿›ç¨‹ä¸­ã€‚åè¿‡æ¥ï¼ŒæœåŠ¡å™¨ä¼šç´¯ç§¯ä»æ‰€æœ‰è®­ç»ƒå™¨é‚£é‡Œæ”¶åˆ°çš„æ‰€æœ‰å·®ï¼Œæ›´æ–°å‚æ•°çš„å€¼ï¼Œç„¶åå°†æ­¤æ–°å€¼å‘é€å›è®­ç»ƒå™¨ã€‚å‚æ•°æœåŠ¡å™¨æ‰§è¡Œé™åˆ¶è‡³100ä¸ªæ›´æ–°æ¯ç§’æˆ–è€…1GBæ¯ç§’ï¼Œä»¥é˜²æ­¢å‚æ•°æœåŠ¡å™¨ä½¿å…¶ä»–é€šä¿¡ä¸­æ–­ã€‚</p>
<p>æºåœ°å€ï¼š<a target="_blank" rel="noopener" href="https://torchbiggraph.readthedocs.io/en/latest/distributed_training.html">https://torchbiggraph.readthedocs.io/en/latest/distributed_training.html</a></p>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/PyTorch-BigGraph/">PyTorch-BigGraph</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">æœ¬åšå®¢æ‰€æœ‰æ–‡ç« é™¤ç‰¹åˆ«å£°æ˜å¤–ï¼Œå‡é‡‡ç”¨ <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 åè®®</a> ï¼Œè½¬è½½è¯·æ³¨æ˜å‡ºå¤„ï¼</p>
              
              
                <div class="post-prevnext row">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2020/10/30/PBG-Loss-calculation/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">PyTorch-BigGraph æŸå¤±è®¡ç®—</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2020/10/27/PBG-Batch-preparation/">
                        <span class="hidden-mobile">PyTorch-BigGraph  æ‰¹å‡†å¤‡</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments">
                
                
  <div id="gitalk-container"></div>
  <script type="text/javascript">
    Fluid.utils.waitElementVisible('gitalk-container', function() {
      Fluid.utils.createCssLink('/css/gitalk.css')
      Fluid.utils.createScript('https://cdn.jsdelivr.net/npm/gitalk@1.7.0/dist/gitalk.min.js', function () {
        var gitalk = new Gitalk({
          clientID: 'c9f6f4b080eae23ae2ba',
          clientSecret: '0aac49a549da89963c40ba56b3f2085a792edb1f',
          repo: 'Bin-Go2.github.io',
          owner: 'Bin-Go2',
          admin: "Bin-Go2",
          id: '11ec00868b34f4faa6a61557e7e30cc4',
          language: 'en',
          labels: ["Gitalk"],
          perPage: 10,
          pagerDirection: 'last',
          createIssueManually: true,
          distractionFreeMode: true
        });
        gitalk.render('gitalk-container');
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;TOC</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
     <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- ä¸è’œå­ç»Ÿè®¡PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            Page Views 
            <span id="busuanzi_value_site_pv"></span>
             
          </span>
      
      
        <!-- ä¸è’œå­ç»Ÿè®¡UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            Unique vistors 
            <span id="busuanzi_value_site_uv"></span>
             
          </span>
      
    
  </div>


  

  
</footer>

<!-- SCRIPTS -->

  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":200})
    NProgress.start()
    document.addEventListener('DOMContentLoaded', function() {
      window.NProgress && window.NProgress.inc();
    })
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.0/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.0/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>






  <script  src="/js/local-search.js" ></script>
  <script>
    (function () {
      var path = "/search.xml";
      var inputArea = document.querySelector("#local-search-input");
      inputArea.onclick = function () {
        searchFunc(path, 'local-search-input', 'local-search-result');
        this.onclick = null
      }
    })()
  </script>















<!-- ä¸»é¢˜çš„å¯åŠ¨é¡¹ ä¿æŒåœ¨æœ€åº•éƒ¨ -->
<script  src="/js/boot.js" ></script>



</body>
</html>
