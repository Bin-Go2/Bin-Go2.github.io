<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.1.1">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.ico">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="PyTorch-BigGraph åˆ†å¸ƒå¼PBG can perform training across multiple machines which communicate over a network, in order to reduce training time on large graphs. Distributed training is able to concurrently u">
<meta property="og:type" content="article">
<meta property="og:title" content="PyTorch-BigGraph åˆ†å¸ƒå¼">
<meta property="og:url" content="http://example.com/2020/10/28/PBG-Distributed-mode/index.html">
<meta property="og:site_name" content="Bin&#39;s blog">
<meta property="og:description" content="PyTorch-BigGraph åˆ†å¸ƒå¼PBG can perform training across multiple machines which communicate over a network, in order to reduce training time on large graphs. Distributed training is able to concurrently u">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2020-10-29T02:13:43.000Z">
<meta property="article:modified_time" content="2020-10-29T08:44:43.402Z">
<meta property="article:author" content="Bin">
<meta property="article:tag" content="PyTorch-BigGraph">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://example.com/2020/10/28/PBG-Distributed-mode/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>PyTorch-BigGraph åˆ†å¸ƒå¼ | Bin's blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Bin's blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">ä»Šæ—¥æ‘¸é±¼è¿›åº¦ï¼š 1/ âˆ</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2020/10/28/PBG-Distributed-mode/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="Bin">
      <meta itemprop="description" content="æˆ‘ç†Šäººæ—æ°¸ä¸ä¸ºå¥´ï¼ï¼å¼å¼å¼ï¼ï¼ï¼">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Bin's blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          PyTorch-BigGraph åˆ†å¸ƒå¼
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-10-28 19:13:43" itemprop="dateCreated datePublished" datetime="2020-10-28T19:13:43-07:00">2020-10-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-10-29 01:44:43" itemprop="dateModified" datetime="2020-10-29T01:44:43-07:00">2020-10-29</time>
              </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Disqus: </span>
    
    <a title="disqus" href="/2020/10/28/PBG-Distributed-mode/#disqus_thread" itemprop="discussionUrl">
      <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2020/10/28/PBG-Distributed-mode/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="PyTorch-BigGraph-åˆ†å¸ƒå¼"><a href="#PyTorch-BigGraph-åˆ†å¸ƒå¼" class="headerlink" title="PyTorch-BigGraph åˆ†å¸ƒå¼"></a>PyTorch-BigGraph åˆ†å¸ƒå¼</h1><p>PBG can perform training across multiple machines which communicate over a network, in order to reduce training time on large graphs. Distributed training is able to concurrently utilize larger computing resources, as well as to keep the entire model stored in memory across all machines, avoiding the need to swap it to disk. On each machine, the training is further parallelized across multiple subprocesses.<br>PBGå¯ä»¥åœ¨é€šè¿‡ç½‘ç»œè¿›è¡Œé€šä¿¡çš„å¤šå°æœºå™¨ä¸Šæ‰§è¡Œè®­ç»ƒï¼Œä»¥å‡å°‘å¤§å›¾ä¸Šçš„è®­ç»ƒæ—¶é—´ã€‚åˆ†å¸ƒå¼è®­ç»ƒèƒ½å¤Ÿåˆ©ç”¨å·¨å¤§çš„è®¡ç®—èµ„æºï¼ŒåŒæ—¶å…¶å¯ä»¥å°†æ•´ä¸ªæ¨¡å‹å­˜å‚¨åœ¨æ‰€æœ‰æœºå™¨çš„å†…å­˜ä¸­è€Œä¸éœ€è¦è¿›è¡Œç£ç›˜äº¤æ¢ã€‚åœ¨æ¯ä¸€å°æœºå™¨ä¸Šï¼Œè®­ç»ƒé€šè¿‡å¤šä¸ªå­è¿›ç¨‹è¿›è¡Œã€‚</p>
<h2 id="Set-up"><a href="#Set-up" class="headerlink" title="Set up"></a>Set up</h2><p>In order to perform distributed training, the configuration file must first be updated to contain the specification of the desired distributed setup. If training should be carried out on ğ‘ machines, then the num_machines key in the config must be set to that value. In addition, the distributed_init_method must describe a way for the trainers to discover each other and set up their communication. All valid values for the init_method argument of torch.distributed.init_process_group() are accepted here. Usually this will be a path to a shared network filesystem or the network address of one of the machines. See the PyTorch docs for more information and a complete reference.<br>ä¸ºäº†æ‰§è¡Œåˆ†å¸ƒå¼è®­ç»ƒï¼Œé…ç½®æ–‡ä»¶å¿…é¡»é¦–å…ˆè¿›è¡Œç›¸åº”é…ç½®ï¼Œå…¶éœ€è¦åŒ…æ‹¬åˆ†å¸ƒå¼éƒ¨ç½²çš„ç›¸å…³é…ç½®ã€‚å¦‚æœè®­ç»ƒåœ¨Nå°æœºå™¨ä¸Šè¿è¡Œï¼Œnum_machineså¿…é¡»è¦è¦é…ç½®æˆNã€‚å¦å¤–ï¼Œdistributed_init_methodå¿…é¡»æè¿°å„ä¸ªæœºå™¨ä¹‹é—´çš„é€šä¿¡æ–¹å¼ã€‚è¿™é‡Œèƒ½å¤Ÿæ¥å—æ‰€æœ‰torch.distributed.init_process_group()é‡Œé¢çš„å‚æ•°ã€‚é€šå¸¸æ¥è¯´ï¼Œåˆ†å¸ƒå¼è®­ç»ƒå°†ä¸€å°è®¡ç®—æœºçš„ç½‘ç»œåœ°å€è®¾ç½®ä¸ºæ–‡ä»¶å…±äº«ç³»ç»Ÿçš„åœ°å€ã€‚ æœ‰å…³æ›´å¤šä¿¡æ¯å’Œå®Œæ•´å‚è€ƒï¼Œè¯·å‚è§PyTorchæ–‡æ¡£ã€‚</p>
<p>To launch distributed training, call torchbiggraph_train â€“rank rank config.py on each machine, with rank replaced by an integer between 0 and ğ‘âˆ’1 (inclusive), different for each machine. Each machine must have PBG installed and have a copy of the config file.<br>è¦å¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒï¼Œé¦–å…ˆåœ¨æ¯å°æœºå™¨ä¸Šè°ƒç”¨torchbiggraph_train â€“rank rank config.pyï¼Œ å…¶ä¸­æ¯å°æœºå™¨æœ‰å„è‡ªçš„rankå€¼ï¼ˆä»1åˆ°N-1ï¼‰ã€‚æ¯å°æœºå™¨å¿…é¡»å®‰è£…äº†PBGï¼Œå¹¶ä¸”å…·æœ‰é…ç½®æ–‡ä»¶çš„å‰¯æœ¬ã€‚</p>
<p>In some uncommon circumstances, one may want to store the embeddings on different machines than the ones that are performing training. In that case, one would set num_partition_servers to a positive value and manually launch some instances of torchbiggraph_partitionserver as well. See below for more information on this.<br>ç‰¹å®šæƒ…å†µä¸‹ï¼Œå¯èƒ½æœ‰å°†åµŒå…¥å­˜å‚¨åœ¨ä¸åŒæœºå™¨è€Œä¸æ˜¯ä¸€å°æœºå™¨ä¸Šçš„éœ€æ±‚ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œéœ€è¦åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®num_partition_serversä¸ºä¸€ä¸ªæ­£æ•°å¹¶ä¸”æ‰‹åŠ¨ä½¿ç”¨torchbiggraph_partitionserveræ¥å¯åŠ¨ä¸€äº›å®ä¾‹ã€‚è¯¦æƒ…è§ä¸‹æ–‡</p>
<blockquote>
<p>Tip<br> A good default setting is to set num_machines to half the number of partitions (see below why) and leave num_partition_servers unset.<br> ä¸€ä¸ªå¥½çš„é»˜è®¤è®¾ç½®æ˜¯å°†num_machinesè®¾ç½®ä¸ºåˆ†åŒºæ•°çš„ä¸€åŠï¼ˆè¯·å‚é˜…ä¸‹é¢çš„åŸå› ï¼‰ï¼Œå¹¶ä¿æŒnum_partition_serversä¸ºæœªè®¾ç½®çŠ¶æ€ã€‚</p>
</blockquote>
<blockquote>
<p>Warning<br> Unpartitioned entity types should not be used with distributed training. While the embeddings of partitioned entity types are only in use on one machine at a time and are swapped between machines as needed, the embeddings of unpartitioned entity types are communicated asynchronously through a poorly-optimized parameter server which was designed for sharing relation parameters, which are small. It cannot support synchronizing large amounts of parameters, e.g. an unpartitioned entity type with more than 1000 entities. In that case, the quality of the unpartitioned embeddings will likely be very poor.<br> æœªåˆ†åŒºçš„å®ä½“ä¸åº”è¯¥è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒã€‚å®ä½“ç±»å‹çš„åˆ†åŒºä»…åœ¨åŒä¸€æ—¶åˆ»åœ¨æŸä¸€å°æœºå™¨ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¸”æ ¹æ®éœ€è¦åœ¨ä¸åŒæœºå™¨é—´è¿›è¡Œäº¤æ¢ã€‚æœªåˆ†åŒºçš„å®ä½“ç±»å‹çš„åµŒå…¥è®¡ç®—æ˜¯é€šè¿‡æ¬ ä¼˜åŒ–çš„å‚æ•°æœåŠ¡åœ¨æœºå™¨ä¹‹é—´è¿›è¡Œå¼‚æ­¥äº¤æ¢çš„ï¼Œè¿™ä¸ªæœåŠ¡åªæ˜¯è®¾è®¡æˆç”¨æ¥è¿›è¡Œå…³ç³»å‚æ•°çš„å…±äº«å¹¶ä¸”å¾ˆå°ã€‚å…¶ä¸èƒ½æ”¯æŒå¤§é‡å‚æ•°çš„åŒæ­¥ã€‚ä¾‹å¦‚ï¼šå¯¹äºä¸€ä¸ªæœªåˆ†åŒºçš„è¶…è¿‡1000ä¸ªå®ä½“çš„å®ä½“ç±»å‹ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæœªåˆ†åŒºçš„å¾—åˆ°çš„åµŒå…¥è´¨é‡ä¼šå¾ˆå·®ã€‚</p>
</blockquote>
<h2 id="Communication-protocols"><a href="#Communication-protocols" class="headerlink" title="Communication protocols"></a>Communication protocols</h2><p> Distributed training requires the machines to coordinate and communicate in various ways for different purposes. These tasks are:<br> åˆ†å¸ƒå¼è®­ç»ƒæ±‚æœºå™¨ä»¥å„ç§æ–¹å¼é’ˆå¯¹ä¸åŒç›®çš„è¿›è¡Œåè°ƒå’Œé€šä¿¡ã€‚ è¿™äº›ä»»åŠ¡æ˜¯ï¼š</p>
<p> â€¢ synchronizing which trainer is operating on which bucket, assigning them so that there are no conflicts<br> â€¢ passing the embeddings of an entity partition from one trainer to the next one when needed (as this is data that is only accessed by one trainer at a time)<br> â€¢ sharing parameters that all trainers need access to simultaneously, by collecting and redistributing the updates to them.</p>
<p> â€¢ åŒæ­¥å“ªä¸ªè®­ç»ƒå™¨åœ¨è®­ç»ƒå“ªä¸ªæ¡¶ï¼Œåˆ†é…å¥½ä»»åŠ¡ä»¥é˜²äº§ç”Ÿå†²çª<br> â€¢ å°†ä¸€ä¸ªå®ä½“åˆ†åŒºçš„åµŒå…¥ä»ä¸€ä¸ªè®­ç»ƒå™¨ä¼ å…¥åˆ°å¦ä¸€ä¸ªè®­ç»ƒå™¨ ï¼ˆå› ä¸ºä¸€ä¸ªè®­ç»ƒå™¨åªä½¿ç”¨ä¸€æ¬¡åœ¨ä¸€ä¸ªepochä¸­ï¼‰<br> â€¢ é€šè¿‡æ”¶é›†å’Œé‡æ–°åˆ†å‘å‚æ•°æ¥å®ç°å„ä¸ªè®­ç»ƒå™¨é—´çš„å‚æ•°å…±äº«</p>
<p> Each of these is implemented by a separate â€œprotocolâ€, and each trainer takes part in some or all of them by launching subprocesses that act as clients or servers for the different protocols. These protocols are explained below to provide insight into the system.</p>
<p> è¿™äº›ä¸­çš„æ¯ä¸€ä¸ªä»»åŠ¡éƒ½ç”±å•ç‹¬çš„â€œåè®®â€å®ç°ï¼Œå¹¶ä¸”æ¯ä¸ªè®­ç»ƒå™¨éƒ½é€šè¿‡å¯åŠ¨å……å½“é’ˆå¯¹ä¸åŒåè®®çš„å®¢æˆ·ç«¯æˆ–æœåŠ¡å™¨çš„å­è¿›ç¨‹æ¥å‚ä¸æ•´ä¸ªè¿‡ç¨‹çš„ä¸€éƒ¨åˆ†æˆ–å…¨éƒ¨ã€‚ä¸‹é¢è¯´æ˜è¿™äº›åè®®ä»¥æä¾›å¯¹ç³»ç»Ÿçš„äº†è§£ã€‚</p>
<h3 id="Synchronizing-bucket-access"><a href="#Synchronizing-bucket-access" class="headerlink" title="Synchronizing bucket access"></a>Synchronizing bucket access</h3><p>PBG parallelizes training across multiple machines by having them all operate simultaneously on disjoint buckets (i.e., buckets that donâ€™t have any partition in common). Therefore, each partition is in use by up to one machine at a time, and each machine uses up to two partitions (the only exception is for buckets â€œon the diagonalâ€, that have the same left- and right-hand side partition). This means that the number of buckets one can simultaneously train on is about half the total number of partitions.<br>PBGé€šè¿‡ä½¿å®ƒä»¬åŒæ—¶åœ¨ä¸ç›¸äº¤çš„å­˜å‚¨æ¡¶ï¼ˆå³æ²¡æœ‰å…±åŒåˆ†åŒºçš„å­˜å‚¨æ¡¶ï¼‰ä¸ŠåŒæ—¶è¿è¡Œæ¥å¹¶è¡ŒåŒ–å¤šå°æœºå™¨çš„åŸ¹è®­ã€‚ï¼ˆä¹Ÿå°±æ˜¯æ‰€è°“çš„æ•°æ®åˆ†åŒºï¼‰ã€‚å› æ­¤ï¼Œæ¯ä¸ªåˆ†åŒºä¸€æ¬¡æœ€å¤šåœ¨ä¸€å°æœºå™¨ä¸Šè¢«ä½¿ç”¨ï¼Œå¹¶ä¸”è¢«ä¸ªæœºå™¨ä¸€æ¬¡è®­ç»ƒæœ€å¤šç”¨ä¸¤ä¸ªåˆ†åŒºï¼ˆå”¯ä¸€çš„ä¾‹å¤–æ˜¯â€œå¯¹è§’çº¿â€ä¸Šçš„å­˜å‚¨æ¡¶ï¼Œå®ƒä»¬å…·æœ‰ç›¸åŒçš„å·¦ä¾§å’Œå³ä¾§åˆ†åŒºï¼‰ï¼‰ã€‚è¿™æ„å‘³åŒæ—¶å¯ä»¥è®­ç»ƒçš„æ¡¶çš„æ•°é‡å¤§æ¦‚æ˜¯ä¸€èˆ¬çš„åˆ†åŒºæ•°é‡ã€‚</p>
<p>The way the machines agree on which one gets to operate on what bucket is through a â€œlock serverâ€. The server is implicitly started by the trainer of rank 0. All other machines connect to it as clients, ask for a new bucket to operate on (when they need one), get a bucket assigned from the server (or none, if all buckets have already been trained on or are â€œlockedâ€ because their partitions are in use by another trainer), train on it, then report it as done and repeat. The lock server tries to optimize I/O by preferring, when a trainer asks for a bucket, to assign one that has as many partitions in common with the previous bucket that the trainer trained on, so that these partitions can be kept in memory rather than having to be unloaded and reloaded.<br>æœºå™¨é—´é€šè¿‡â€œé”æœåŠ¡â€çš„å½¢å¼æ¥è¡¨æ˜å“ªä¸ªæ¡¶æ­£åœ¨è¢«æ“ä½œã€‚æœåŠ¡å™¨ç”±çº§åˆ«0ï¼ˆmasterï¼‰çš„è®­ç»ƒå™¨éšå¼å¯åŠ¨ï¼Œæ‰€æœ‰å…¶ä»–æœºå™¨ä½œä¸ºå®¢æˆ·ç«¯è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œå½“å®ƒä»¬éœ€è¦æ–°çš„æ¡¶çš„æ—¶å€™ï¼Œä»–ä»¬å‘masterè¯·æ±‚å¹¶ä¸”å¾—åˆ°ä¸€ä¸ªæ–°çš„æ¡¶æ•°æ®ï¼ˆå¯èƒ½æ²¡æ‹¿åˆ°ï¼Œå› ä¸ºå¯èƒ½å­˜åœ¨æ‰€æœ‰çš„æ¡¶éƒ½è¢«è®­ç»ƒå®Œä¸€æ¬¡äº†æˆ–è€…æ¡¶æ˜¯é”ä½çš„çŠ¶æ€ï¼‰æ¥è¿›è¡Œè®­ç»ƒã€æŠ¥å‘Šç„¶åé‡å¤æ‰§è¡Œã€‚å½“ä¸€ä¸ªè®­ç»ƒå™¨è¯·æ±‚æ–°æ¡¶çš„æ—¶å€™ï¼Œé”å®šæœåŠ¡å™¨é€šè¿‡ä¼˜å…ˆåˆ†é…ä¸è¯¥è®­ç»ƒå™¨ä¸Šä¸€æ¬¡è®­ç»ƒçš„æ•°æ®æœ‰è¾ƒå¤šç›¸åŒåˆ†åŒºçš„æ¡¶æ¥ä¼˜åŒ–I/Oï¼Œé€šè¿‡è¿™æ ·é‚£äº›åˆ†åŒºå°±å¯ä»¥è¢«ä¿ç•™åœ¨å†…å­˜ä¸Šè€Œä¸æ˜¯è¢«å¸è½½ç„¶ååˆåŠ è½½ã€‚</p>
<h3 id="Exchanging-partition-embeddings"><a href="#Exchanging-partition-embeddings" class="headerlink" title="Exchanging partition embeddings"></a>Exchanging partition embeddings</h3><p>When a trainer starts operating on a bucket it needs access to the embeddings of all entities (of all types) that belong to either the left- or the right-hand side partition of the bucket. The â€œlockingâ€ mechanism of the lock server ensures that at most one trainer is operating on a partition at any given time. This doesnâ€™t hold for unpartitioned entity types, which are shared among all trainers; see below. Thus each trainer has exclusive hold of the partitions itâ€™s training on.<br>å½“ä¸€ä¸ªè®­ç»ƒå™¨å¼€å§‹åœ¨ä¸€ä¸ªæ¡¶ä¸Šæ‰§è¡Œè®­ç»ƒçš„æ—¶å€™ï¼Œä»–éœ€è¦è·å–é¦–å…ˆè·å–å±äºæ¡¶çš„å·¦ä¾§æˆ–å³ä¾§åˆ†åŒºçš„æ‰€æœ‰å®ä½“ï¼ˆæ‰€æœ‰ç±»å‹ï¼‰çš„åµŒå…¥ã€‚ é”å®šæœåŠ¡å™¨çš„â€œé”å®šâ€æœºåˆ¶ç¡®ä¿åœ¨ä»»ä½•ç»™å®šæ—¶é—´æœ€å¤šæœ‰ä¸€ä¸ªè®­ç»ƒå™¨åœ¨ä¸€ä¸ªåˆ†åŒºä¸Šè¿è¡Œã€‚è¿™ä¸ªæœºåˆ¶ä¸é€‚ç”¨äºæœªåˆ†åŒºçš„å®ä½“ï¼Œå› ä¸ºä»–ä»¬è¢«æ‰€æœ‰çš„è®­ç»ƒå™¨å…±äº«ã€‚è§ä¸‹æ–‡ã€‚ å› æ­¤ï¼Œæ¯ä¸ªè®­ç»ƒå™¨åœ¨è®­ç»ƒæ—¶å¯ä»¥ç‹¬å å…¶è®­ç»ƒçš„åˆ†åŒºã€‚</p>
<p>Once a trainer starts working on a new bucket it needs to acquire the embeddings of its partitions, and once itâ€™s done it needs to release them and make them available, in their updated version, to the next trainer that needs them. In order to do this, thereâ€™s a system of so-called â€œpartition serversâ€ that store the embeddings, provide them upon request to the trainers who need them, receive back the updated embedding and store it.<br>å½“ä¸€ä¸ªè®­ç»ƒå™¨å¼€å§‹åœ¨æ–°çš„æ¡¶ä¸Šä¸Šå·¥ä½œåï¼Œéœ€è¦è·å–å…¶åˆ†åŒºçš„åµŒå…¥å†…å®¹ï¼Œå®Œæˆåï¼Œéœ€è¦é‡Šæ”¾å®ƒä»¬å¹¶ä»¥æ›´æ–°ç‰ˆæœ¬å°†å…¶æä¾›ç»™éœ€è¦è¯¥è®­ç»ƒçš„ä¸‹ä¸€ä¸ªè®­ç»ƒå™¨ã€‚ ä¸ºæ­¤ï¼Œæœ‰ä¸€ä¸ªæ‰€è°“çš„â€œåˆ†åŒºæœåŠ¡å™¨â€ç³»ç»Ÿï¼Œç”¨äºå­˜å‚¨åµŒå…¥å†…å®¹ï¼Œå¹¶æ ¹æ®éœ€è¦å°†å…¶æä¾›ç»™éœ€è¦å®ƒä»¬çš„è®­ç»ƒå™¨ï¼Œå¹¶æ¥æ”¶æ›´æ–°çš„åµŒå…¥å†…å®¹å¹¶è¿›è¡Œå­˜å‚¨ã€‚</p>
<p>This service is optional, and is disabled when num_partition_servers is set to zero. In that case the trainers â€œsendâ€ each other the embeddings simply by writing them to the checkpoint directory (which should reside on a shared disk) and then fetching them back from there.<br>æ­¤æœåŠ¡æ˜¯å¯é€‰çš„ï¼Œå¹¶ä¸”åœ¨num_partition_serversè®¾ç½®ä¸ºé›¶æ—¶è¢«ç¦ç”¨ã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè®­ç»ƒå™¨åªéœ€å°†åµŒå…¥å†…å®¹å†™å…¥â€œæ£€æŸ¥ç‚¹â€ç›®å½•ï¼ˆåº”ä½äºå…±äº«ç£ç›˜ä¸Šï¼‰ï¼Œç„¶åä»é‚£é‡Œå–å›å®ƒä»¬ï¼Œå³å¯ç›¸äº’â€œå‘é€â€åµŒå…¥å†…å®¹ã€‚</p>
<p>When this system is enabled, it can operate in two modes. The simplest mode is triggered when num_partition_servers is -1 (the default): in that case all trainers spawn a local process that acts as a partition server. If, on the other hand, num_partition_servers is a positive value then the trainers will not spawn any process, but will instead connect to the partition servers that the user must have provisioned manually by launching the torchbiggraph_partitionserver command on the appropriate number of machines.<br>å¯ç”¨æ­¤ç³»ç»Ÿåï¼Œå®ƒå¯ä»¥åœ¨ä¸¤ç§æ¨¡å¼ä¸‹è¿è¡Œã€‚ å½“num_partition_serversä¸º-1ï¼ˆé»˜è®¤å€¼ï¼‰æ—¶ï¼Œå°†è§¦å‘æœ€ç®€å•çš„æ¨¡å¼ï¼šåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‰€æœ‰è®­ç»ƒå™¨éƒ½ä¼šç”Ÿæˆä¸€ä¸ªå……å½“åˆ†åŒºæœåŠ¡å™¨çš„æœ¬åœ°è¿›ç¨‹ã€‚ å¦ä¸€æ–¹é¢ï¼Œå¦‚æœnum_partition_serversä¸ºæ­£å€¼ï¼Œé‚£ä¹ˆè®­ç»ƒå™¨å°†ä¸ä¼šäº§ç”Ÿä»»ä½•è¿›ç¨‹ï¼Œè€Œæ˜¯å°†ä¼šè¿æ¥åˆ°ç”¨æˆ·æ‰‹åŠ¨è®¾ç½®çš„æä¾›çš„åˆ†åŒºæœåŠ¡å™¨ä¸Šï¼Œç”¨æˆ·é€šè¿‡åœ¨é€‚å½“æ•°é‡çš„æœºå™¨ä¸Šè¿è¡Œtorchbiggraph_partitionserveræ¥å®ç°é¢„å…ˆä¾›ç»™ã€‚</p>
<h3 id="Updating-shared-parameters"><a href="#Updating-shared-parameters" class="headerlink" title="Updating shared parameters"></a>Updating shared parameters</h3><p>Some parameters of the model need to be used by all trainers at the same time (this includes the operator weights, the global embeddings of each entity type, the embeddings of the unpartitioned entities). These are parameters that donâ€™t depend on what bucket the trainer is operating on, and therefore are always present on all trainers (as opposed to the entity embeddings, which are loaded and unloaded as needed). These parameters are synchronized using a series of â€œparameter serversâ€. Each trainer starts a local parameter server (in a separate subprocess) and connects to all other parameter servers. Each parameter that is shared between trainers is then stored in a parameter server (possibly sharded across several of them, if too large). Each trainer also has a loop (also in a separate subprocess) which, at regular intervals, goes over each shared parameter, computes the difference between its current local value and the value it had when it was last synced with the server where the parameter is hosted and sends that delta to that server. The server, in turn, accumulates all the deltas it receives from all trainers, updates the value of the parameter and sends this new value back to the trainers. The parameter server performs throttling to 100 updates/s or 1GB/s, in order to prevent the parameter server from starving the other communication.<br>æ‰€æœ‰è®­ç»ƒå™¨å¿…é¡»åŒæ—¶ä½¿ç”¨æ¨¡å‹çš„æŸäº›å‚æ•°ï¼ˆè¿™åŒ…æ‹¬æ“ä½œå‘˜æƒé‡ï¼Œæ¯ç§å®ä½“ç±»å‹çš„å…¨å±€åµŒå…¥ï¼Œæœªåˆ†åŒºå®ä½“çš„åµŒå…¥ï¼‰ã€‚è¿™äº›å‚æ•°å¹¶ä¸å–å†³äºé‚£äº›è®­ç»ƒå™¨æ­£åœ¨æ“ä½œçš„æ¡¶ï¼Œå› æ­¤å…¶å§‹ç»ˆå­˜åœ¨äºæ‰€æœ‰è®­ç»ƒå™¨ä¸Šï¼ˆä¸å®ä½“åµŒå…¥æƒ…å†µç›¸ä»¿ï¼Œå®ä½“åµŒå…¥æ ¹æ®éœ€è¦è¿›è¡ŒåŠ è½½å’Œå¸è½½ï¼‰è¿™äº›å‚æ•°ä½¿ç”¨ä¸€ç³»åˆ—â€œå‚æ•°æœåŠ¡å™¨â€è¿›è¡ŒåŒæ­¥ã€‚æ¯ä¸€ä¸ªè®­ç»ƒå™¨å¼€å¯ä¸€ä¸ªæœ¬åœ°çš„å‚æ•°æœåŠ¡å™¨ï¼ˆä»¥ä¸€ä¸ªç‹¬è‡ªçš„å­è¿›ç¨‹ï¼‰å¹¶ä¸”å’Œå…¶ä»–æ‰€æœ‰çš„å‚æ•°æœåŠ¡å™¨è¿›è¡Œè¿æ¥ã€‚æ¯ä¸€ä¸ªè¢«è®­ç»ƒå™¨å…±äº«çš„å‚æ•°è¢«å­˜å‚¨åœ¨å‚æ•°æœåŠ¡å™¨ä¸­ï¼ˆå¦‚æœå‚æ•°å¤ªå¤§çš„è¯ï¼Œåˆ™å¯èƒ½å°†å…¶åˆ†æ•£åœ¨å…¶ä¸­çš„å‡ ä¸ªæœåŠ¡å™¨ä¸­ï¼‰ã€‚æ¯ä¸€ä¸ªè®­ç»ƒå™¨è¿˜æœ‰ä¸€ä¸ªloopï¼ˆåŒæ ·ä¹Ÿåœ¨ä¸€ä¸ªå­è¿›ç¨‹ä¸­ï¼‰ï¼Œè¯¥å¾ªç¯ä»¥å›ºå®šçš„æ—¶é—´é—´éš”éå†æ¯ä¸ªå…±äº«å‚æ•°ï¼Œè®¡ç®—å…¶å½“å‰æœ¬åœ°å€¼ä¸ä¸Šæ¬¡ä¸è¯¥æœåŠ¡å™¨ä¸Šæ¬¡ä¸æœåŠ¡å™¨åŒæ­¥æ—¶æ‰€å…·æœ‰çš„å€¼ä¹‹é—´çš„å·®ï¼Œé‚£äº›æœåŠ¡å™¨çš„å‚æ•°å€¼æ˜¯è¢«æ‰˜ç®¡å¹¶ä¸”å‘é€åˆ°æœ¬åœ°çš„å­è¿›ç¨‹ä¸­ã€‚åè¿‡æ¥ï¼ŒæœåŠ¡å™¨ä¼šç´¯ç§¯ä»æ‰€æœ‰è®­ç»ƒå™¨é‚£é‡Œæ”¶åˆ°çš„æ‰€æœ‰å·®ï¼Œæ›´æ–°å‚æ•°çš„å€¼ï¼Œç„¶åå°†æ­¤æ–°å€¼å‘é€å›è®­ç»ƒå™¨ã€‚å‚æ•°æœåŠ¡å™¨æ‰§è¡Œé™åˆ¶è‡³100ä¸ªæ›´æ–°æ¯ç§’æˆ–è€…1GBæ¯ç§’ï¼Œä»¥é˜²æ­¢å‚æ•°æœåŠ¡å™¨ä½¿å…¶ä»–é€šä¿¡ä¸­æ–­ã€‚</p>

    </div>


    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/PyTorch-BigGraph/" rel="tag"># PyTorch-BigGraph</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/10/27/PBG-Batch-preparation/" rel="prev" title="PyTorch-BigGraph  æ‰¹å‡†å¤‡">
      <i class="fa fa-chevron-left"></i> PyTorch-BigGraph  æ‰¹å‡†å¤‡
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/10/30/PBG-Loss-calculation/" rel="next" title="PyTorch-BigGraph æŸå¤±å‡½æ•°">
      PyTorch-BigGraph æŸå¤±å‡½æ•° <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  
  


          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#PyTorch-BigGraph-%E5%88%86%E5%B8%83%E5%BC%8F"><span class="nav-number">1.</span> <span class="nav-text">PyTorch-BigGraph åˆ†å¸ƒå¼</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Set-up"><span class="nav-number">1.1.</span> <span class="nav-text">Set up</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Communication-protocols"><span class="nav-number">1.2.</span> <span class="nav-text">Communication protocols</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Synchronizing-bucket-access"><span class="nav-number">1.2.1.</span> <span class="nav-text">Synchronizing bucket access</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Exchanging-partition-embeddings"><span class="nav-number">1.2.2.</span> <span class="nav-text">Exchanging partition embeddings</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Updating-shared-parameters"><span class="nav-number">1.2.3.</span> <span class="nav-text">Updating shared parameters</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Bin"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Bin</p>
  <div class="site-description" itemprop="description">æˆ‘ç†Šäººæ—æ°¸ä¸ä¸ºå¥´ï¼ï¼å¼å¼å¼ï¼ï¼ï¼</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">29</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/Bin-Go2" title="GitHub â†’ https:&#x2F;&#x2F;github.com&#x2F;Bin-Go2" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:binzhangsam@gmail.com" title="E-Mail â†’ mailto:binzhangsam@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Bin</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://pisces.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a>
  </div>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<span id="busuanzi_container_site_pv">æ€»è®¿é—®é‡<span id="busuanzi_value_site_pv"></span>æ¬¡</span>

<div class="theme-info">
    <div class="powered-by"></div>
    <span class="post-count">å…±29.8kå­—</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

<script>
  function loadCount() {
    var d = document, s = d.createElement('script');
    s.src = 'https://https-bin-go2-github-io.disqus.com/count.js';
    s.id = 'dsq-count-scr';
    (d.head || d.body).appendChild(s);
  }
  // defer loading until the whole page loading is completed
  window.addEventListener('load', loadCount, false);
</script>
<script>
  var disqus_config = function() {
    this.page.url = "http://example.com/2020/10/28/PBG-Distributed-mode/";
    this.page.identifier = "2020/10/28/PBG-Distributed-mode/";
    this.page.title = "PyTorch-BigGraph åˆ†å¸ƒå¼";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://https-bin-go2-github-io.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });
</script>

</body>
</html>
