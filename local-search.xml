<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>çŸ¥è¯†å›¾è°±å¤ä¹ å¤§çº²</title>
    <link href="/2020/12/03/558overview/"/>
    <url>/2020/12/03/558overview/</url>
    
    <content type="html"><![CDATA[<h1 id="Week-1"><a href="#Week-1" class="headerlink" title="Week 1"></a>Week 1</h1><h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><h3 id="What-is-a-KG"><a href="#What-is-a-KG" class="headerlink" title="What is a KG?"></a>What is a KG?</h3><p>KG is the Knowledge in graph form, it captures entities, attributes, and relationships. In KG, nodes are entities and they are labeled with attributes. Edges between two nodes capture a relationship between entities</p><p>Knowledge Graphs: is a directed heterogeneous multigraph whose node and relation types have domain-specific semantics</p><h3 id="Why-KGs"><a href="#Why-KGs" class="headerlink" title="Why KGs?"></a>Why KGs?</h3><p>From humanâ€™s perspective, KG helps combat information overload. It also helps explore via intuitive structure. It is also a tool for supporting knowledge-driven tasks.<br>From AIâ€™s perspective, KGâ€™s content is the key ingredient for many AI tasks. It bridges from data to human semantics and people can use decades of work on graph analysis via KG.</p><h3 id="How-are-KGs-used"><a href="#How-are-KGs-used" class="headerlink" title="How are KGs used?"></a>How are KGs used?</h3><p>QA/Agents: By extracting suitable candidates (entities, relations or literals) from the KG<br>Decision Support: By reasoning over the KG<br>Fueling Discovery: By reasoning over the KG, By extracting and suggesting suitable candidates in the KG, By matching and analyzing patterns in the KG</p><h3 id="Where-do-KGs-come-from"><a href="#Where-do-KGs-come-from" class="headerlink" title="Where do KGs come from?"></a>Where do KGs come from?</h3><p>Structured Text (Wikipedia Infoboxes, tables, databases, social nets)<br>Unstructured Text (WWW, news, social media, reference articles)<br>Images<br>Video (YouTube, video feeds)</p><h2 id="Crawling-the-Web-amp-Intellectual-Property"><a href="#Crawling-the-Web-amp-Intellectual-Property" class="headerlink" title="Crawling the Web &amp; Intellectual Property"></a>Crawling the Web &amp; Intellectual Property</h2><h3 id="Surface-web-vs-deep-web-vs-dark-web"><a href="#Surface-web-vs-deep-web-vs-dark-web" class="headerlink" title="Surface web vs. deep web vs. dark web"></a>Surface web vs. deep web vs. dark web</h3><p>Surface web:  Pages reachable by following links from static pages, people can access these pages directly<br>Deep Web: Pages reachable only via web forms , for example: email information, databases<br>Dark Web: Pages reachable only via Tor or equivalent or other specific tools.</p><h3 id="What-are-the-challenges"><a href="#What-are-the-challenges" class="headerlink" title="What are the challenges?"></a>What are the challenges?</h3><p>scale<br>deduplication<br>cost (fetching, parsing/extracting, memory/disk * speed)<br>errors, redirects<br>freshness<br>deep web, forms<br>counter-crawling/access (login, captchas, traps, fake errors, banning)<br>localization<br>dynamic pages<br>infinite scrolling<br>archiving</p><h3 id="What-is-the-basic-architecture-of-a-crawler"><a href="#What-is-the-basic-architecture-of-a-crawler" class="headerlink" title="What is the basic architecture of a crawler?"></a>What is the basic architecture of a crawler?</h3><p>Basically, a crawler can be split into four parts: Scheduler, Queue, Multi-thread downloader, Storage. The procedure of the crawler is : first a user providers a list of web pages(URLS) to Scheduler. Then Scheduler shedules these URLs by putting them into Queue accoring to certain rules. Then Scheduler assigns the different URLs in Queue to  Multi-thread downloader to let the downloader automatically crawls the information. After information is downloaded, content will be parsed and content will be extracted. There might be some urls extracted, the Scheduler will review thses urls and and the worthy ones to Queue again. Target data(Text and metadata) will be storeed into Storages. The crawler will end if there is no url to crawl of the user terminate it. </p><h3 id="What-mechanisms-exist-to-protect-intellectual-property"><a href="#What-mechanisms-exist-to-protect-intellectual-property" class="headerlink" title="What mechanisms exist to protect intellectual property?"></a>What mechanisms exist to protect intellectual property?</h3><p>Patents<br>Copyrights<br>Trademarks<br>Trade Secrets<br>Software Licenses</p><h3 id="What-are-the-requirements-for-a-patent"><a href="#What-are-the-requirements-for-a-patent" class="headerlink" title="What are the requirements for a patent?"></a>What are the requirements for a patent?</h3><p>Patent can be split into 3 main types.<br>Utility patents protect useful processes, machines, articles of manufacture, and compositions of matter.<br>Design patents guard the unauthorized use of new, original, and ornamental designs for articles of manufacture.<br>Plant patents are the way we protect invented or discovered, asexually reproduced plant varieties<br>Patents provide rights for up to 20 years for inventions</p><h3 id="What-can-be-copyrighted-and-what-is-the-difference-in-CC-licenses"><a href="#What-can-be-copyrighted-and-what-is-the-difference-in-CC-licenses" class="headerlink" title="What can be copyrighted, and what is the difference in CC licenses?"></a>What can be copyrighted, and what is the difference in CC licenses?</h3><p>COPYRIGHTS protect works of authorship, such as writings, music, and works of art that have been tangibly expressed. So basically, these creative following works can be copyrighted:<br>Literary, musical and dramatic works.<br>Pantomimes and choreographic works.<br>Pictorial, graphic and sculptural works.<br>Sound recordings.<br>Motion pictures and other AV works.<br>Computer programs.<br>Compilations of works and derivative works.<br>Architectural works. </p><p>Attribution: Licensees may copy, distribute, display and perform the work only if they give owner the credits<br>Noncommercial: Licensees may copy, distribute, etc. the work only for noncommercial purpose<br>No Derivative Works: Licensees may copy, distribute, etc. the work, not derivatives based on it.<br>ShareAlike: Licensees may distribute derivative works only under a license identical to the license that governs the original work.</p><h1 id="Week-2"><a href="#Week-2" class="headerlink" title="Week 2"></a>Week 2</h1><h2 id="Information-Extraction"><a href="#Information-Extraction" class="headerlink" title="Information Extraction"></a>Information Extraction</h2><h3 id="What-are-some-typical-IE-tasks"><a href="#What-are-some-typical-IE-tasks" class="headerlink" title="What are some typical IE tasks?"></a>What are some typical IE tasks?</h3><p>sentence:<br>Part of speech tagging<br>Dependency Parsing<br>Named entity recognition </p><p>document:<br>Coreference Resolution </p><p>documents:<br>Entity resolution<br>Entity linking<br>Relation extraction </p><h3 id="What-are-the-three-components-to-IE"><a href="#What-are-the-three-components-to-IE" class="headerlink" title="What are the three components to IE?"></a>What are the three components to IE?</h3><p>Defining domain<br>Learning extractors<br>Scoring the facts</p><h3 id="What-are-the-possible-levels-of-supervision-for-each-component"><a href="#What-are-the-possible-levels-of-supervision-for-each-component" class="headerlink" title="What are the possible levels of supervision for each component?"></a>What are the possible levels of supervision for each component?</h3><p>Supervised<br>Semi-supervised<br>Unsupervised</p><h3 id="Real-world-O-IE-systems"><a href="#Real-world-O-IE-systems" class="headerlink" title="Real-world (O)IE systems"></a>Real-world (O)IE systems</h3><p>Open domain IE:<br>Defining domain: Unsupervised<br>Learning extractors: Unsupervised<br>Scoring candidate facts: Semi-supervised</p><h2 id="Knowledge-Representation"><a href="#Knowledge-Representation" class="headerlink" title="Knowledge Representation"></a>Knowledge Representation</h2><h3 id="What-are-the-basic-elements-of-RDF"><a href="#What-are-the-basic-elements-of-RDF" class="headerlink" title="What are the basic elements of RDF?"></a>What are the basic elements of RDF?</h3><p>S(subject)P(predicate)O(object)</p><h3 id="What-are-the-different-syntaxes-for-RDF"><a href="#What-are-the-different-syntaxes-for-RDF" class="headerlink" title="What are the different syntaxes for RDF?"></a>What are the different syntaxes for RDF?</h3><p>XML, N3 Turtle, N-Triples, RDFa, JSON-LD</p><h3 id="What-is-RDF-Schema"><a href="#What-is-RDF-Schema" class="headerlink" title="What is RDF Schema?"></a>What is RDF Schema?</h3><p>RDF Schema is the language for defining RDF vocabularies.<br>It specifies the RDF inference rules: the triples that are implied by the triples you have.</p><h3 id="Degree-of-semantics-in-graphs"><a href="#Degree-of-semantics-in-graphs" class="headerlink" title="Degree of semantics in graphs"></a>Degree of semantics in graphs</h3><p>????</p><h1 id="Week-3"><a href="#Week-3" class="headerlink" title="Week 3"></a>Week 3</h1><h2 id="Entity-Resolution"><a href="#Entity-Resolution" class="headerlink" title="Entity Resolution"></a>Entity Resolution</h2><h3 id="Which-ER-variants-exist"><a href="#Which-ER-variants-exist" class="headerlink" title="Which ER variants exist?"></a>Which ER variants exist?</h3><p>Ambiguity: Entities with the same name<br>Variance: Different names for the same entity</p><h3 id="What-are-the-three-basic-steps-of-ER"><a href="#What-are-the-three-basic-steps-of-ER" class="headerlink" title="What are the three basic steps of ER?"></a>What are the three basic steps of ER?</h3><p>ï¼Ÿï¼Ÿï¼Ÿ</p><h3 id="How-do-we-evaluate-blocking"><a href="#How-do-we-evaluate-blocking" class="headerlink" title="How do we evaluate blocking?"></a>How do we evaluate blocking?</h3><p>Efficiency = num of pairs compared / total number of pairs in RxR<br>Recall = num of true matches compared / num of true matches in RxR<br>Precision = um of true matches compared / num of matches compared<br>Max canopy size: the size of the largest block</p><h3 id="What-are-real-world-examples-of-these-ER-settings"><a href="#What-are-real-world-examples-of-these-ER-settings" class="headerlink" title="What are real-world examples of these ER settings?"></a>What are real-world examples of these ER settings?</h3><p>text -&gt; text ?<br>text -&gt; KG ?<br>KG -&gt; KG ?<br>KG1 -&gt; KG2 ?</p><h1 id="Week-4"><a href="#Week-4" class="headerlink" title="Week 4"></a>Week 4</h1><h2 id="Queries-amp-KGs"><a href="#Queries-amp-KGs" class="headerlink" title="Queries &amp; KGs"></a>Queries &amp; KGs</h2><h3 id="RDF-vs-Property-Graphs"><a href="#RDF-vs-Property-Graphs" class="headerlink" title="RDF vs. Property Graphs"></a>RDF vs. Property Graphs</h3><p>Similarity:<br>Both represent directed graphs as a basic data structure;<br>Both have associated graph-oriented query languages;<br>In practice, both are used as â€œgraph storesâ€, accessible via HTTP and/or various API-s;</p><p>Differences:<br>RDF has an emphasis on OWA, and is rooted in the Web via URL-s. Not the case for PG, PG node is oblivious to what it â€œcontainsâ€: can be a URL, can be a literal; (nodeä¸ä¸€å®šæ˜¯uri)<br>PG includes the possibility to add simple key/value pairs to â€œrelationshipsâ€ (i.e., RDF predicates) ï¼ˆå…³ç³»ä¸­å¯ä»¥å¸¦å±æ€§ï¼‰</p><h3 id="RDF-triple-stores-vs-Graph-DBs"><a href="#RDF-triple-stores-vs-Graph-DBs" class="headerlink" title="RDF triple-stores vs. Graph DBs"></a>RDF triple-stores vs. Graph DBs</h3><p>In RDF triple-stores everything is expressed in terms of SPO and its predicates canâ€™t have attributes;<br>In Graph DBs predicates can have attributes;<br>Fair to say that RDF triple-stores are a kind of Graph DB;</p><h3 id="SPARQL-syntax-Graph-Patterns-Aggregation-etcâ€¦"><a href="#SPARQL-syntax-Graph-Patterns-Aggregation-etcâ€¦" class="headerlink" title="SPARQL: syntax, Graph Patterns, Aggregation, etcâ€¦"></a>SPARQL: syntax, Graph Patterns, Aggregation, etcâ€¦</h3><h3 id="SPARQL-vs-Cypher"><a href="#SPARQL-vs-Cypher" class="headerlink" title="SPARQL vs. Cypher"></a>SPARQL vs. Cypher</h3><p>SPARQL Protocol and RDF Query Language , this is RDFâ€™s QUERY LANGUAGE<br>Neo4jâ€™s QUERY LANGUAGE</p><h2 id="Special-Topics-KG-Use-Cases"><a href="#Special-Topics-KG-Use-Cases" class="headerlink" title="Special Topics: KG Use Cases"></a>Special Topics: KG Use Cases</h2><h3 id="Wikidata-data-model"><a href="#Wikidata-data-model" class="headerlink" title="Wikidata data model"></a>Wikidata data model</h3><p>Model using statements Subject, property, value, Qualifiers, references</p><h3 id="Challenges-and-methods-for-building-KGs-in-real-applications"><a href="#Challenges-and-methods-for-building-KGs-in-real-applications" class="headerlink" title="Challenges and methods for building KGs in real applications"></a>Challenges and methods for building KGs in real applications</h3><p>challenge: make the annotations easy to use<br>hundreds of millions of sex ads on the open internetâ€¦many trafficking related<br>Data obfuscation makes even simple questions hard to automatically answer</p><p>solution:<br>USE KG in tsv format<br>Knowledge Graph Is A TSV File<br>easy to process </p><h1 id="Week-5"><a href="#Week-5" class="headerlink" title="Week 5"></a>Week 5</h1><h2 id="Large-KGs-amp-Entity-Linking"><a href="#Large-KGs-amp-Entity-Linking" class="headerlink" title="Large KGs &amp; Entity Linking"></a>Large KGs &amp; Entity Linking</h2><h3 id="Which-kinds-of-large-KGs-exist"><a href="#Which-kinds-of-large-KGs-exist" class="headerlink" title="Which (kinds of) large KGs exist?"></a>Which (kinds of) large KGs exist?</h3><p>DBpedia, YAGO, Wikidata, Freebase, ConceptNet, NELL, OpenIE</p><h3 id="How-is-Wikidata-different-from-other-large-KGs"><a href="#How-is-Wikidata-different-from-other-large-KGs" class="headerlink" title="How is Wikidata different from other large KGs?"></a>How is Wikidata different from other large KGs?</h3><p>???</p><h3 id="What-are-the-different-methods-to-get-data-from-large-KGs"><a href="#What-are-the-different-methods-to-get-data-from-large-KGs" class="headerlink" title="What are the different methods to get data from large KGs?"></a>What are the different methods to get data from large KGs?</h3><p>??? </p><h3 id="What-is-entity-linking-from-text-and-why-is-it-hard"><a href="#What-is-entity-linking-from-text-and-why-is-it-hard" class="headerlink" title="What is entity linking (from text) and why is it hard?"></a>What is entity linking (from text) and why is it hard?</h3><p>Establishing the identity of the entity in a given reference<br>database (text-&gt;KG).<br>name ambiguity: Entities with the same name<br>name variation: Different names for the same entity<br>Missing (NIL) entities</p><h3 id="What-is-the-basic-architecture-of-entity-linkers"><a href="#What-is-the-basic-architecture-of-entity-linkers" class="headerlink" title="What is the basic architecture of entity linkers?"></a>What is the basic architecture of entity linkers?</h3><p>mention detection -&gt; candidate selection -&gt; Disambiguation -&gt; entity annotatiton</p><h3 id="What-are-some-methods-for-disambiguation"><a href="#What-are-some-methods-for-disambiguation" class="headerlink" title="What are some methods for disambiguation?"></a>What are some methods for disambiguation?</h3><p>Word-based methods: DBpedia Spotlight: Compute cosine similarity between the text paragraph with an entity mention and Wikipedia descriptions of each candidate.Decide for one mention at a time. The linking can be restricted to certain types or even to a custom set of entities.<br>Graph-based methods: AIDA and AGDISTIS: 1. construct a subgraph that contains all entity candidates with some facts from a KB. 2. find the best connected candidates per mention.</p><h2 id="String-Similarity"><a href="#String-Similarity" class="headerlink" title="String Similarity"></a>String Similarity</h2><h3 id="Which-similarity-families-exist-and-what-is-the-main-idea-of-each"><a href="#Which-similarity-families-exist-and-what-is-the-main-idea-of-each" class="headerlink" title="Which similarity families exist and what is the main idea of each?"></a>Which similarity families exist and what is the main idea of each?</h3><h3 id="What-are-the-strengths-and-weaknesses-of-each-method"><a href="#What-are-the-strengths-and-weaknesses-of-each-method" class="headerlink" title="What are the strengths and weaknesses of each method?"></a>What are the strengths and weaknesses of each method?</h3><h3 id="How-do-hybrid-methods-work"><a href="#How-do-hybrid-methods-work" class="headerlink" title="How do hybrid methods work?"></a>How do hybrid methods work?</h3><h1 id="Week-6"><a href="#Week-6" class="headerlink" title="Week 6"></a>Week 6</h1><h2 id="Information-Extraction-1"><a href="#Information-Extraction-1" class="headerlink" title="Information Extraction"></a>Information Extraction</h2><h3 id="What-are-labeling-functions-Snorkel-What-makes-them-good"><a href="#What-are-labeling-functions-Snorkel-What-makes-them-good" class="headerlink" title="What are labeling functions (Snorkel)? What makes them good?"></a>What are labeling functions (Snorkel)? What makes them good?</h3><p>Labeling functions (LFs) help users encode domain knowledge and other supervision sources programmatically, it is a function desgined by human to help label data points.<br>Instead of poeple manually labeling the points, people can write heuristics to noisily label data! Human can leverage real-world knowledge, context, and common-sense heuristics to make labeling decisions. This help quick and low cost labeling.</p><h3 id="What-does-the-generative-model-do"><a href="#What-does-the-generative-model-do" class="headerlink" title="What does the generative model do?"></a>What does the generative model do?</h3><p>LFs have different latent accuracies, Snorkel wants to learn these latent accuracies without labeled data by leveraging overlap and conflict of LFs.</p><p>Snorkel creates a generative model to maximize the marginal likelihood of the LFs to learn parameters Intuitively, compares their agreements and disagreements, and detect correlations and other dependencies among LFs to correct their accuracies.</p><h3 id="What-is-the-purpose-of-the-discriminative-model"><a href="#What-is-the-purpose-of-the-discriminative-model" class="headerlink" title="What is the purpose of the discriminative model?"></a>What is the purpose of the discriminative model?</h3><p>Compiling Rules into Features.</p><p>The output of the generative model is a set of probabilistic training labels<br>Snorkel wants to use these labels to train final discriminative model. The discriminative model learns a feature representation of our LFs. </p><p>The discriminative model aims to be able to generalize beyond the noisy LFs. The more unlabeled data we train with Snorkel, the better is the predictive performance of the discriminatory model.</p><h1 id="Week-7"><a href="#Week-7" class="headerlink" title="Week 7"></a>Week 7</h1>]]></content>
    
    
    
    <tags>
      
      <tag>Knowledge Graph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>çŸ¥è¯†å›¾è°±é”®è¿æ•°æ®ä¸è¯­ä¹‰ç½‘ç»œ</title>
    <link href="/2020/12/03/558ld-sw/"/>
    <url>/2020/12/03/558ld-sw/</url>
    
    <content type="html"><![CDATA[<h2 id="Web-of-documents-vs-Web-of-data"><a href="#Web-of-documents-vs-Web-of-data" class="headerlink" title="Web of documents vs. Web of data"></a>Web of documents vs. Web of data</h2><p>Web of Document: æ•°æ®ä¹‹é—´å…³è”å°‘<br>Analogy: a global filesystem<br>Primary objects: documents<br>Links between: documents (or sub-parts of)<br>Degree of structure in objects: fairly low<br>Semantics of content and links: implicit<br>Designed for: human consumption</p><p>Web of Data<br>Analogy:  a global database<br>Primary objects: things (or descriptions of things)<br>Links between: things (including documents)<br>Degree of structure in objects: high<br>Semantics of content and links: explicit<br>Designed for: machines first, humans later</p><h2 id="é”®è¿æ•°æ®-Linked-data"><a href="#é”®è¿æ•°æ®-Linked-data" class="headerlink" title="é”®è¿æ•°æ® (Linked data)"></a>é”®è¿æ•°æ® (Linked data)</h2><p>å®šä¹‰: A method of publishing structured data so that it can be<br>interlinked and become more useful</p><p>é”®è¿èµ„æ–™æ˜¯è¯­ä¹‰ç½‘çš„ä¸»é¢˜ä¹‹ä¸€ï¼Œæè¿°äº†é€šè¿‡å¯é“¾æ¥çš„URIæ–¹å¼æ¥å‘å¸ƒã€åˆ†äº«ã€è¿æ¥Webä¸­å„ç±»èµ„æºçš„æ–¹æ³•ã€‚æ˜¯ä¸€ç³»åˆ—åˆ©ç”¨Web åœ¨ä¸åŒæ•°æ®æºä¹‹é—´åˆ›å»ºè¯­ä¹‰å…³è”çš„æ–¹æ³•ã€‚</p><p>Web technologies: HTTP,URIs,RDF to share information processed automatically by computers</p><h3 id="Linked-Data-Principles"><a href="#Linked-Data-Principles" class="headerlink" title="Linked Data Principles"></a>Linked Data Principles</h3><ol><li>Use URIs as names for things</li><li>Use HTTP URIs so that people can look up those names</li><li>When someone looks up a URI, provide useful RDF information</li><li>Include RDF statements that link to other URIs so that they can discover more things</li></ol><h3 id="å­˜åœ¨é—®é¢˜"><a href="#å­˜åœ¨é—®é¢˜" class="headerlink" title="å­˜åœ¨é—®é¢˜"></a>å­˜åœ¨é—®é¢˜</h3><ul><li>Different URIs For the Same Thing</li><li>Timeliness ï¼ˆnot up to dateï¼‰</li><li>Provenance</li><li>Tools</li></ul><h3 id="Linked-data-è¯„çº§"><a href="#Linked-data-è¯„çº§" class="headerlink" title="Linked data è¯„çº§"></a>Linked data è¯„çº§</h3><p><img src="/image/linkdata.png"></p><h2 id="Semantic-Web"><a href="#Semantic-Web" class="headerlink" title="Semantic Web"></a>Semantic Web</h2><p>æ ¸å¿ƒ:é€šè¿‡ç»™ä¸‡ç»´ç½‘ä¸Šçš„æ–‡æ¡£æ·»åŠ èƒ½å¤Ÿè¢«è®¡ç®—æœºæ‰€ç†è§£çš„è¯­ä¹‰ï¼Œä»è€Œä½¿æ•´ä¸ªäº’è”ç½‘æˆä¸ºä¸€ä¸ªé€šç”¨çš„ä¿¡æ¯äº¤æ¢ä»‹è´¨</p><h2 id="Webä¸­çš„Thingä¸Document"><a href="#Webä¸­çš„Thingä¸Document" class="headerlink" title="Webä¸­çš„Thingä¸Document"></a>Webä¸­çš„Thingä¸Document</h2><h3 id="Web-document"><a href="#Web-document" class="headerlink" title="Web document"></a>Web document</h3><p>å®šä¹‰: A Web document is defined as something that has a URI and can return representations (responses in a format such as HTML or JPEG or RDF) of the identified resource in response to HTTP requests.</p><blockquote><p>An HTML document is not a representation of a person. It is a representation of a Web document.</p></blockquote><h3 id="å†…å®¹åå•†-Content-Negotiation"><a href="#å†…å®¹åå•†-Content-Negotiation" class="headerlink" title="å†…å®¹åå•†(Content Negotiation)"></a>å†…å®¹åå•†(Content Negotiation)</h3><p>å®šä¹‰: è¶…æ–‡æœ¬ä¼ è¾“åè®®ä¸­å®šä¹‰çš„ä¸€ä¸ªæœºåˆ¶ï¼Œå®ƒä½¿åŒä¸€ä¸ªç»Ÿä¸€èµ„æºæ ‡å¿—ç¬¦ä¸Šçš„æ–‡æ¡£å¯ä»¥æ ¹æ®ç”¨æˆ·ä»£ç†ä¸­æŒ‡å®šçš„é€‚ç”¨ä¿¡æ¯æä¾›ä¸åŒçš„ç‰ˆæœ¬<br><img src="/image/cn.png"></p><h3 id="Web-Thing"><a href="#Web-Thing" class="headerlink" title="Web Thing"></a>Web Thing</h3><blockquote><p>We use  need different URIs for Things and Web documents<br>è¿™é‡Œçš„Thingå…¶å®ä¹Ÿå°±æ˜¯çŸ¥è¯†å›¾è°±ä¸­çš„entity</p></blockquote><p><img src="/image/thing&web.png"><br>ä»è¿™ä¸ªä¾‹å­ä¸­ä¹Ÿå¯ä»¥å‘ç°ï¼ŒæŸä¸€ä¸ªå®ä½“çš„web documentå¯ä»¥æ˜¯è¯¥å®ä½“çš„ä¸€ä¸ªå±æ€§</p><h3 id="303-é‡å®šå‘"><a href="#303-é‡å®šå‘" class="headerlink" title="303 é‡å®šå‘"></a>303 é‡å®šå‘</h3><p>è§£å†³é—®é¢˜: two documents donâ€™t contain the same content</p><p><img src="/image/303.png"></p><h3 id="ä¸‰ä¸ªURIå…³ç³»"><a href="#ä¸‰ä¸ªURIå…³ç³»" class="headerlink" title="ä¸‰ä¸ªURIå…³ç³»"></a>ä¸‰ä¸ªURIå…³ç³»</h3><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs crystal">&lt;<span class="hljs-symbol">http:</span>/<span class="hljs-regexp">/ex.com/id</span><span class="hljs-regexp">/alice&gt;</span><br><span class="hljs-regexp">  foaf:page &lt;http:/</span><span class="hljs-regexp">/ex.com/people</span><span class="hljs-regexp">/alice&gt; ; </span><br><span class="hljs-regexp">  rdfs:isDefinedBy &lt;http:/</span><span class="hljs-regexp">/ex.com/data</span><span class="hljs-regexp">/alice&gt; ;</span><br><span class="hljs-regexp">  a foaf:Person ;</span><br><span class="hljs-regexp">  foaf:name &quot;Aliceâ€ ;</span><br><span class="hljs-regexp">  foaf:mbox &lt;mailto:alice@example.com&gt; ; ...</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Knowledge Graph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>çŸ¥è¯†å›¾è°±å›¾åˆ†æ&amp;é—®é¢˜å›ç­”</title>
    <link href="/2020/12/03/558kg-ga-qs/"/>
    <url>/2020/12/03/558kg-ga-qs/</url>
    
    <content type="html"><![CDATA[<h2 id="å›¾åˆ†æ"><a href="#å›¾åˆ†æ" class="headerlink" title="å›¾åˆ†æ"></a>å›¾åˆ†æ</h2><p>å›¾åˆ†æç®—æ³•</p><p>Pathfinding and Search: Djikstraâ€™s algorithm<br>Matching and coloring: k-coloring, graph equivalence<br>Centrality: Degree centrality, page-rank, betweenness centrality, closeness centrality<br>Clustering and Community Detection: Connected components, clustering coefficient</p><p>Matching: a set of edges that do not have a set of common vertices.</p><p>Coloring: Assignment of labels traditionally called â€œcolorsâ€ to elements of a graph subject to certain constraints.</p><h3 id="Centrality"><a href="#Centrality" class="headerlink" title="Centrality"></a>Centrality</h3><p>Eccentricity: Maximum of minimum distances of a node to other nodes in the graph ï¼ˆæŸä¸ªç‚¹çš„åå¿ƒç‡ä¹Ÿå°±æ˜¯è¯´è¿æ¥è¯¥ç‚¹åˆ°å›¾ä¸­å…¶ä»–ç‚¹çš„æœ€å¤§è·ç¦»ï¼‰<br>Central point: node with lowest eccentricity<br>Radius: distance: central pointâ€™s eccentricity (lowest max-distance)<br>Diameter: largest eccentricity (highest max-distance)</p><p>Degree Centrality: Nodes with maximum in-degree or out-degree<br>Betweenness Centrality: Number of all-pairs shortest paths a node participates<br>in<br>Closeness (Harmonic) Centrality: Inverse average of distance (or average inverse distance) to all other nodes</p><h3 id="Clustering"><a href="#Clustering" class="headerlink" title="Clustering"></a>Clustering</h3><p>Connected components: Set of nodes where each node is reachable from all other nodes<br>Clustering Coefficient</p><h2 id="é—®ç­”ç³»ç»Ÿ"><a href="#é—®ç­”ç³»ç»Ÿ" class="headerlink" title="é—®ç­”ç³»ç»Ÿ"></a>é—®ç­”ç³»ç»Ÿ</h2><p>å­ä»»åŠ¡:<br>â€¢ Entity Linking<br>â€¢ Relation Linking<br>â€¢ Query Structure Discovery<br>â€¢ Identifying Logical Operators</p><h3 id="æŒ‘æˆ˜"><a href="#æŒ‘æˆ˜" class="headerlink" title="æŒ‘æˆ˜"></a>æŒ‘æˆ˜</h3><ul><li><p>Lexical Gap between ontology and language:</p><ul><li>String normalization â€“ different forms of the same word</li><li>Query expansion â€“ adding additional terms</li><li>Pattern libraries â€“ translating complex phrasal structure into properties</li><li>Entailment â€“ using previous answers + reasoning to fill in missing facts</li></ul></li><li><p>Ambiguity of questions and concepts</p><ul><li>Context-based or corpus-based filtering</li><li>Constraints between concepts in the question</li><li>Coherence models across ontologies and concept hierarchies</li></ul></li><li><p>Multilingualism</p></li><li><p>Complexity of queries</p><ul><li>Multiple levels of indirection</li><li>Aggregation, logical comparisons, quantifiers</li><li>Indirect references to prior answers, nested queries</li><li>Constraints on the answers</li></ul></li><li><p>Distributed Knowledge across several KGs</p><ul><li>Identifying the right KG with the answer</li><li>Understanding entity links between KGs</li><li>Predicting missing links</li></ul></li><li><p>Procedural, Spatial, &amp; Temporal QA</p><ul><li>Answering tasks may require different types of knowledge</li><li>Answer may not be an entity (e.g., â€œHow do you make a sandwich?â€</li><li>Event-based questions require knowledge of â€œbeforeâ€ â€œafterâ€ â€œcausesâ€</li><li>Questions may use geo-coodinates, spatial relationships, containment</li></ul></li><li><p>Template(-free) questions</p><ul><li>Question may not match existing structural patterns</li><li>Question might require multiple structural schemas</li><li>May require aggregation of answers from different query types and knowledge sources</li></ul></li></ul><h3 id="è§£å†³æ–¹æ¡ˆ"><a href="#è§£å†³æ–¹æ¡ˆ" class="headerlink" title="è§£å†³æ–¹æ¡ˆ"></a>è§£å†³æ–¹æ¡ˆ</h3><p><img src="/image/sol_qa.png"></p>]]></content>
    
    
    
    <tags>
      
      <tag>Knowledge Graph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>çŸ¥è¯†å›¾è°±å›¾åµŒå…¥</title>
    <link href="/2020/12/03/558kg-emb/"/>
    <url>/2020/12/03/558kg-emb/</url>
    
    <content type="html"><![CDATA[<h2 id="åŸºç¡€çŸ¥è¯†"><a href="#åŸºç¡€çŸ¥è¯†" class="headerlink" title="åŸºç¡€çŸ¥è¯†"></a>åŸºç¡€çŸ¥è¯†</h2><h3 id="æ•°æ®çš„è¡¨ç¤º"><a href="#æ•°æ®çš„è¡¨ç¤º" class="headerlink" title="æ•°æ®çš„è¡¨ç¤º"></a>æ•°æ®çš„è¡¨ç¤º</h3><p>Scalar: a  æ ‡é‡ï¼Œ0ç»´<br>Vector: a[i]ï¼Œ å‘é‡ï¼Œ1ç»´<br>Matrix: a[i,j]ï¼Œ çŸ©é˜µï¼Œ2ç»´<br>Tensor: a[i,j,k]ï¼Œ å¼ é‡ï¼Œå¤šç»´</p><p>Tensorå’Œ Graphçš„å…³ç³»:<br>Graphs over time -&gt; 3rd order tensors</p><p>Knowledge Graphs:  a directed heterogeneous multigraph whose node and relation types have domain-specific semantics ï¼ˆVertices: Entities, Edges: Predicatesï¼‰<br>æœ‰å‘ã€å¼‚æºã€å¯¹å…³ç³»å›¾</p><h3 id="ä¸ºä»€ä¹ˆè¦è¿›è¡ŒåµŒå…¥ï¼Ÿ"><a href="#ä¸ºä»€ä¹ˆè¦è¿›è¡ŒåµŒå…¥ï¼Ÿ" class="headerlink" title="ä¸ºä»€ä¹ˆè¦è¿›è¡ŒåµŒå…¥ï¼Ÿ"></a>ä¸ºä»€ä¹ˆè¦è¿›è¡ŒåµŒå…¥ï¼Ÿ</h3><p>Meaningful non-numerical representations are highly important, e.g., languages with discrete representations, graphs, shapes</p><p>But, Most inference models, e.g., SVM, NN, Reg., etc., are designed for vector-space representable quantities<br>=&gt;<br>To benefits from these models, we need to convert non-numeric representations to numeric representations</p><p>ç®€å•çš„è¯´ï¼Œå°±æ˜¯å°†é«˜ç»´çš„ç¦»æ•£ä¿¡æ¯è½¬åŒ–ä¸ºä½ç»´çš„è¿ç»­æ•°æ®ï¼Œå¹¶ä¸”ä¿æŒå…¶ä¿¡æ¯çš„å®Œæ•´æ€§ï¼Œç”¨äºåç»­çš„å»ºæ¨¡åˆ†æã€‚</p><h3 id="åµŒå…¥"><a href="#åµŒå…¥" class="headerlink" title="åµŒå…¥"></a>åµŒå…¥</h3><p>å®šä¹‰:<br>Mapping of a discrete variable to a vector of continuous numbers such that semantic/abstract similarities are encoded in terms of geometric distances</p><p>â€¢ Low-dimensional -&gt; Mitigate redundancy, curse of dimensionality(é¿å…ç»´åº¦ç¾éš¾)<br>â€¢ Embeddings provide a generalizable context about the overall<br>graph that can be used for interference, e.g., relations.</p><h3 id="å›¾åµŒå…¥"><a href="#å›¾åµŒå…¥" class="headerlink" title="å›¾åµŒå…¥"></a>å›¾åµŒå…¥</h3><p>Given entities &amp; predicates, find mappings for entities and links (predicate (s,r,t))<br>å°±æ˜¯å°†å®ä½“æˆ–è€…å…³ç³»ä»¥å‘é‡çš„å½¢å¼è¡¨è¾¾ã€‚</p><h2 id="å›¾åµŒå…¥æ–¹æ³•"><a href="#å›¾åµŒå…¥æ–¹æ³•" class="headerlink" title="å›¾åµŒå…¥æ–¹æ³•"></a>å›¾åµŒå…¥æ–¹æ³•</h2><h3 id="SVD"><a href="#SVD" class="headerlink" title="SVD"></a>SVD</h3><ul><li>Decomposition in terms of singular values</li><li>V, U: orthogonal matrices</li></ul><h3 id="Deep-Graph-Embeddings"><a href="#Deep-Graph-Embeddings" class="headerlink" title="Deep Graph Embeddings"></a>Deep Graph Embeddings</h3><p>Skip-gram: DeepWalk, Node2Vec<br>æ€æƒ³:<br>Sample a set of paths with random walk from node ğ‘£i<br>Adjacent Nodes are Similar and should have similar embeddings. The frequency of co-occurrence in random walks is an indicator of node similarity.</p><ul><li>Hierarchical Softmax (DeepWalk)</li><li>Negative Sampling (Node2Vec)</li></ul><p>å…¶ä»–ç®—æ³•</p><p>Metapath2Vec: heterogenous graph<br>LINE: 1st order + 2nd order proximity<br>UltimateWalk: closed form, unifies DeepWalk and Node2Vec reconstruct W,<br>AutoEncoder: similar to SVD<br>Struc2Vec: focuses on structural similarity<br>GCN: interesting! borrowed the idea from CNN</p><h2 id="å›¾åµŒå…¥åº”ç”¨"><a href="#å›¾åµŒå…¥åº”ç”¨" class="headerlink" title="å›¾åµŒå…¥åº”ç”¨"></a>å›¾åµŒå…¥åº”ç”¨</h2><p>â€¢ Reconstruction / Fact checking: Triples completion: (s,?,t)<br>â€¢ Classification: Triples classification: (s,r,t)<br>â€¢ Featurizing: Link prediction, Recommendation</p><h2 id="Tensorä¸å›¾åµŒå…¥"><a href="#Tensorä¸å›¾åµŒå…¥" class="headerlink" title="Tensorä¸å›¾åµŒå…¥"></a>Tensorä¸å›¾åµŒå…¥</h2><p><img src="/image/kg_tensor.png"></p><h3 id="PARAFAC"><a href="#PARAFAC" class="headerlink" title="PARAFAC"></a>PARAFAC</h3><p>é’ˆå¯¹å›¾å¼ é‡çš„åˆ†è§£<br><img src="/image/PARAFAC.png"></p><h2 id="çŸ¥è¯†å›¾è°±åµŒå…¥"><a href="#çŸ¥è¯†å›¾è°±åµŒå…¥" class="headerlink" title="çŸ¥è¯†å›¾è°±åµŒå…¥"></a>çŸ¥è¯†å›¾è°±åµŒå…¥</h2><p>Problem statement:<br>How to enforce KG structures on the embedding representations?</p><p>Solution: Triple scoring</p><p>Loss: what shall we optimize?</p><h3 id="Triple-Scoring"><a href="#Triple-Scoring" class="headerlink" title="Triple Scoring"></a>Triple Scoring</h3><p>What is the relationship among sub (h), pred (r), and obj (t)? â€¢ Addition: h + r =?= t<br>è¡¨ç¤ºå®ä½“å…³ç³»å‘é‡é—´çš„å…³ç³»ã€‚</p><ol><li>Addition: h + r =?= t</li><li>Multiplication: h âš¬ r =?= t</li></ol><h4 id="Addition"><a href="#Addition" class="headerlink" title="Addition"></a>Addition</h4><p>æŸ¥çœ‹ h + r æ˜¯å¦ = t</p><p>TransEç®—æ³•:<br>score(h,r,t) = â€“ ||h+r-t||   è¿”å›ç»“æœäºŒèŒƒå¼çš„è´Ÿå€¼</p><figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs angelscript">â€˜Merkelâ€™: h=(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>)<br>â€˜Beatlesâ€™: t =(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br>â€˜plays_bassâ€™: r =(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>) <br>score(h,r,t)=- ||h+ tâˆ’ r|| = <span class="hljs-number">-1</span><br></code></pre></td></tr></table></figure><p>ç¼ºé™·:<br>ä»å…¬å¼å°±å¯ä»¥çœ‹å‡ºï¼Œè¯¥ç®—æ³•ä¸é€‚ç”¨äºä¸€å¯¹å¤šçš„å…³ç³»</p><p>TransH:<br>Project to relation-specific hyperplanes</p><p>TransR:<br>Translate to relation-specific space</p><h4 id="Multiplication"><a href="#Multiplication" class="headerlink" title="Multiplication"></a>Multiplication</h4><p>æŸ¥çœ‹ h âš¬ r æ˜¯å¦ =  t</p><p>RESCALç®—æ³•, score(h,r,t) = h.T âš¬ Wr âš¬ t<br>ç¼ºé™·: Too many parameters </p><p>DistMultç®—æ³•, score(h,r,t) = h.T âš¬ diag(Wr) âš¬ t<br>å¥½å¤„: Simplify RESCAL by using a diagonal matrix<br>ç¼ºé™·: Cannot deal with asymmetric relations!</p><p>ComplExç®—æ³•: score(h,r,t) = Re(h.T âš¬ diag(Wr) âš¬ t)<br>Extend DistMult by introducing complex value embedding, so can handle asymmetric relations</p><h3 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h3><p>Closed world assumption: square loss</p>]]></content>
    
    
    
    <tags>
      
      <tag>Knowledge Graph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>çŸ¥è¯†å›¾è°±è¡¨æ ¼ç†è§£</title>
    <link href="/2020/12/03/558-table-und/"/>
    <url>/2020/12/03/558-table-und/</url>
    
    <content type="html"><![CDATA[<h2 id="æ•°æ®ç±»å‹"><a href="#æ•°æ®ç±»å‹" class="headerlink" title="æ•°æ®ç±»å‹"></a>æ•°æ®ç±»å‹</h2><ul><li>Structured Data<ul><li>Knowledge Graphs</li><li>The Semantic Web</li><li>Databases</li><li>Structured files (CSV, XML, XLS)</li><li>Structures in HTML, e.g. tables  -&gt; æœ¬ç« å…³æ³¨</li></ul></li><li>Unstructured Data</li></ul><h2 id="Webä¸­çš„ç»“æ„åŒ–è¡¨æ ¼-Structured-Tables-on-the-Web"><a href="#Webä¸­çš„ç»“æ„åŒ–è¡¨æ ¼-Structured-Tables-on-the-Web" class="headerlink" title="Webä¸­çš„ç»“æ„åŒ–è¡¨æ ¼ (Structured Tables on the Web)"></a>Webä¸­çš„ç»“æ„åŒ–è¡¨æ ¼ (Structured Tables on the Web)</h2><p>Tables contain really useful data<br>Vast Amount of Data in Tabular Form</p><h2 id="è¡¨æ ¼ç±»å‹"><a href="#è¡¨æ ¼ç±»å‹" class="headerlink" title="è¡¨æ ¼ç±»å‹"></a>è¡¨æ ¼ç±»å‹</h2><p><img src="/image/table_type.png"></p><h3 id="Listing"><a href="#Listing" class="headerlink" title="Listing"></a>Listing</h3><p>Horizontal Listings; -&gt; ç±»ä¼¼äºexcelè¡¨æ ¼çš„å½¢å¼ï¼Œæ¯ä¸€è¡Œè¡¨ç¤ºæŸä¸ªitemçš„ä¿¡æ¯<br>Vertical Listings; -&gt; ç±»ä¼¼äºDellã€Appleå•†å“å±•ç°çš„å½¢å¼ï¼Œæ¯ä¸€åˆ—è¡¨ç¤ºæŸä¸ªitemçš„ä¿¡æ¯</p><h3 id="Attribute-Value-Tables"><a href="#Attribute-Value-Tables" class="headerlink" title="Attribute/Value Tables"></a>Attribute/Value Tables</h3><p>ç±»ä¼¼äºWikipediaçš„å±•ç°å½¢å¼ï¼Œå…¶æœ¬è´¨å°±æ˜¯ä¸€ä¸ªk-vçš„å­—å…¸</p><h3 id="Matrix"><a href="#Matrix" class="headerlink" title="Matrix"></a>Matrix</h3><p>äºŒç»´è¡¨æ ¼ï¼Œç¬¬ä¸€è¡Œå’Œç¬¬ä¸€åˆ—éƒ½æè¿°äº†å…ƒä¿¡æ¯<br>same value type for any cell</p><h3 id="Enumeration"><a href="#Enumeration" class="headerlink" title="Enumeration"></a>Enumeration</h3><p>list series of objects with the same ontological relation;<br>major challenge: discovery of the predicate;<br>æœ¬è´¨ä¸Šå°±æ˜¯ä¸€ä¸ªlistï¼Œç„¶åå…¶ä¸­åŒ…å«äº†æŸä¸€ä¸ªå±æ€§ä¸‹çš„åˆ—è¡¨ä¿¡æ¯ã€‚</p><h3 id="Form"><a href="#Form" class="headerlink" title="Form"></a>Form</h3><p>like attribute-value;<br>with missing values;<br>which are filled by a user</p><p>ä¹Ÿå°±æ˜¯æ—¥å¸¸è§åˆ°çš„è¡¨å•</p><h3 id="Navigational"><a href="#Navigational" class="headerlink" title="Navigational"></a>Navigational</h3><p>purpose: navigate within or outside of a site<br>no clear relations between the cells</p><p>ä¹Ÿå°±æ˜¯ç½‘ç«™ä¸Šå¸¸è§åˆ°ä¸€ç³»åˆ—å¯ä»¥ç‚¹å‡»çš„ç½‘é¡µé“¾æ¥æ”¾åœ¨ä¸€å—çš„å±•ç¤º<br><img src="/image/nva.png"></p><h3 id="Formatting"><a href="#Formatting" class="headerlink" title="Formatting"></a>Formatting</h3><p>purpose: organize data visually</p><p>ä¸»è¦æ˜¯ä¸€äº›å¸ƒå±€å±•ç¤º</p><h2 id="è¡¨æ ¼çš„å±æ€§"><a href="#è¡¨æ ¼çš„å±æ€§" class="headerlink" title="è¡¨æ ¼çš„å±æ€§"></a>è¡¨æ ¼çš„å±æ€§</h2><p>Global Layout features<br>â€¢ #rows, #cols, max cell length</p><p>Layout features (per row/column)<br>â€¢ cell length, length variance, ratio in col/rowspan</p><p>HTML features (content)<br>â€¢ unique tags, ratio of th/anchor/img/input/br/fontâ€¦</p><p>Cell features (content)<br>â€¢ unique strings, end-with-colon, is/contains number, non- blank</p><h2 id="æå–å…³ç³»æ•°æ®-Extracting-Relational-Data"><a href="#æå–å…³ç³»æ•°æ®-Extracting-Relational-Data" class="headerlink" title="æå–å…³ç³»æ•°æ® (Extracting Relational Data)"></a>æå–å…³ç³»æ•°æ® (Extracting Relational Data)</h2><p>ç›®æ ‡:<br>æ‰¾åˆ°è¡¨æ ¼ä¸­çš„ç»“æ„åŒ–å…³ç³»<br>æå–å‡ºè¡¨æ ¼ä¸‹çš„RDFä¸‰å…ƒç»„</p><p>å…³é”®:<br>â€¢ What is the semantic type of each column? â€¢ Semantic Labeling  åˆ—çš„å«ä¹‰<br>â€¢ What is the subject of the table? â€¢ Entity Linking è¡¨æ ¼ä¸­ä¸»ä½“å¯»æ‰¾<br>â€¢ What predicates describe the relationships in the table? â€¢ Semantic Modeling å•å…ƒæ ¼çš„å…³ç³»å»ºç«‹</p><h2 id="æå–å®šé‡æ•°æ®-Extracting-Quantitative-Data"><a href="#æå–å®šé‡æ•°æ®-Extracting-Quantitative-Data" class="headerlink" title="æå–å®šé‡æ•°æ® (Extracting Quantitative Data)"></a>æå–å®šé‡æ•°æ® (Extracting Quantitative Data)</h2><p>â€¢ What is quantitative data?<br>â€¢ How is it harder than relational data?<br>â€¢ How is it easier than relational data?<br>â€¢ What is important to represent about this data?</p><h3 id="Quantitative-data"><a href="#Quantitative-data" class="headerlink" title="Quantitative data"></a>Quantitative data</h3><p>Quantitative data is defined as the value of data in the form of counts or numbers where each data-set has an unique numerical value associated with it.</p><p>Key idea:</p><p>â€¢ Measure: the thing we want to measure<br>â€¢ Attributes: help us understand what weâ€™re measuring<br>â€¢ Dimensions: values that are varied across measurements<br>â€¢ Observation: The actual value we measured</p><p>Measureè¡¨ç¤ºæˆ‘ä»¬éœ€è¦è¡¡é‡ä»€ä¹ˆï¼Œæ¯”å¦‚è¯´æ¸©åº¦<br>Attributesè¡¨ç¤ºæˆ‘ä»¬è¡¡é‡çš„è¿™ä¸ªä¸œè¥¿å…·æœ‰çš„å±æ€§ï¼Œæ¯”å¦‚è¯´é‚£ä¸€å¤©çš„æ¸©åº¦ã€é‚£ä¸ªæµ·æ‹”é«˜åº¦çš„æ¸©åº¦ã€æ¸©åº¦çš„å•ä½<br>Dimensionsè¡¨ç¤ºéšç€è¿™ä¸ªä¸œè¥¿çš„æ”¹å˜ï¼Œè¡¡é‡çš„å€¼ä¼šä¸åŒï¼Œæ¯”å¦‚è¯´åœ°ç‚¹<br>Observationè¡¨ç¤ºå°±æ˜¯è§‚æµ‹å€¼ï¼Œæ¯”å¦‚è¯´30åº¦</p><h3 id="æŒ‘æˆ˜"><a href="#æŒ‘æˆ˜" class="headerlink" title="æŒ‘æˆ˜"></a>æŒ‘æˆ˜</h3><p>Attributesæœ‰å“ªäº›ï¼Ÿ<br>Dimensionsæœ‰å“ªäº›ï¼Ÿ<br>Valueæ˜¯ä»€ä¹ˆï¼Ÿ</p><p>éœ€è¦åšå¾ˆå¤šæ“ä½œï¼Œä¾‹å¦‚<br>Metadata Detection, Separation between header and values, Detecting layouts, Detecting dependent rows/columns, Filling the implicit values, Recognizing null values â€¦.</p><h3 id="æ ¸å¿ƒä»»åŠ¡"><a href="#æ ¸å¿ƒä»»åŠ¡" class="headerlink" title="æ ¸å¿ƒä»»åŠ¡"></a>æ ¸å¿ƒä»»åŠ¡</h3><p>Three core tasks across all table understanding tools:<br>Classify Cell Type;<br>Identify Blocks;<br>Detect Layout;<br><img src="/image/tbl_und.png"></p>]]></content>
    
    
    
    <tags>
      
      <tag>Knowledge Graph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>çŸ¥è¯†å›¾è°±RDFa</title>
    <link href="/2020/12/03/558rdfa/"/>
    <url>/2020/12/03/558rdfa/</url>
    
    <content type="html"><![CDATA[<h2 id="RDFa"><a href="#RDFa" class="headerlink" title="RDFa"></a>RDFa</h2><p>Resource Description Framework  in  attributes</p><p>å®šä¹‰:<br>RDFaæ˜¯ä¸€ä¸ªW3Cæ¨èæ ‡å‡†ã€‚å®ƒæ‰©å±•äº†XHTMLçš„å‡ ä¸ªå±æ€§ï¼Œç½‘é¡µåˆ¶ä½œè€…å¯ä»¥åˆ©ç”¨è¿™äº›å±æ€§åœ¨ç½‘é¡µä¸­æ·»åŠ å¯ä¾›æœºå™¨è¯»å–çš„åè®¾èµ„æ–™ã€‚ä¸RDFèµ„æ–™æ¨¡å‹çš„å¯¹åº”å…³ç³»ä½¿å¾—RDFaå¯ä»¥å°†RDFçš„ä¸‰å…ƒç»„åµŒå…¥åœ¨XHTMLæ–‡æ¡£ä¸­ï¼Œå®ƒä¹Ÿä½¿å¾—ç¬¦åˆæ ‡å‡†çš„ä½¿ç”¨ç«¯å¯ä»¥ä»RDFaæ–‡ä»¶ä¸­æå–å‡ºè¿™äº›RDFä¸‰å…ƒç»„æ¥ã€‚</p><p>ç®€å•çš„è¯´ï¼šRDFaå°±æ˜¯åœ¨htmlä¸­åµŒå…¥rdfä¿¡æ¯ã€‚</p><h2 id="RDFa-åµŒå…¥"><a href="#RDFa-åµŒå…¥" class="headerlink" title="RDFa åµŒå…¥"></a>RDFa åµŒå…¥</h2><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs vim">&lt;<span class="hljs-keyword">p</span> xmln<span class="hljs-variable">s:dc</span>=<span class="hljs-comment">&quot;http://purl.org/dc/elements/1.1/â€   -- Namespace å£°æ˜</span><br>about=<span class="hljs-string">&quot;http://www.example.com/books/wikinomics&quot;</span>&gt; -- Resource å£°æ˜<br>In <span class="hljs-keyword">his</span> latest book<br>&lt;cite property=<span class="hljs-string">&quot;dc:title&quot;</span> &gt;Wikinomics&lt;/cite&gt;,   -- å±æ€§å£°æ˜<br><span class="hljs-symbol">&lt;span&gt;</span>Don Tapscott&lt;/span&gt;<br>explains deep <span class="hljs-keyword">changes</span> in technology, demographics <span class="hljs-built_in">and</span> business.<br>The book <span class="hljs-keyword">is</span> due <span class="hljs-keyword">to</span> <span class="hljs-keyword">be</span> published in <span class="hljs-symbol">&lt;span&gt;</span>October <span class="hljs-number">2006</span>&lt;/span&gt;.<br>&lt;/<span class="hljs-keyword">p</span>&gt;<br></code></pre></td></tr></table></figure><p>SPO =&gt;<br><a href="http://www.example.com/books/wikinomics">http://www.example.com/books/wikinomics</a>  dc:title  â€œWikinomicsâ€</p><p>åµŒå…¥RDFaçš„å¥½å¤„:<br>Not only human can Look Up the Meaning on the Web, but computers Can Look It Up Too.æœºå™¨ä¹Ÿå¯ä»¥å»ç†è§£è¯­ä¹‰äº†ã€‚</p><p>ä¾‹å­:<br><img src="/image/rdfa.png"></p><h2 id="RDFa-é—®é¢˜ä¸è§£å†³"><a href="#RDFa-é—®é¢˜ä¸è§£å†³" class="headerlink" title="RDFa é—®é¢˜ä¸è§£å†³"></a>RDFa é—®é¢˜ä¸è§£å†³</h2><ol><li>æ ¼å¼é—®é¢˜<br><code>&lt;span property=&quot;dc:dateâ€&gt;October 2006&lt;/span&gt;. åœ¨è¿™é‡Œçš„è¯ï¼ŒOctober 2006 is not a computer understandable date e.g., an xsd:date</code><br>è§£å†³: ä½¿ç”¨ Content Attribute<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">span</span> </span><br><span class="hljs-tag"><span class="hljs-attr">property</span>=<span class="hljs-string">&quot;dc:dateâ€</span></span><br><span class="hljs-tag"><span class="hljs-string">content=&quot;</span><span class="hljs-attr">2006-10-01</span>â€ </span><br><span class="hljs-tag"><span class="hljs-attr">datatype</span>=<span class="hljs-string">â€œxsd:dateâ€</span>&gt;</span> October 2006<span class="hljs-tag">&lt;/<span class="hljs-name">span</span>&gt;</span>.<br></code></pre></td></tr></table></figure>åªè¦htmlæ ‡ç­¾ä¸­å­˜åœ¨contentçš„å±æ€§ï¼Œé‚£ä¹ˆRDFå®¢æˆ·ç«¯åœ¨è¯»å–æ•°æ®æ—¶è‡ªåŠ¨ä¼šå°†contentçš„å†…å®¹æ¥ä»£æ›¿å®é™…æ–‡æœ¬å†…å®¹</li></ol><h2 id="RDFa-ä¾‹å­"><a href="#RDFa-ä¾‹å­" class="headerlink" title="RDFa ä¾‹å­"></a>RDFa ä¾‹å­</h2><h3 id="RDFa-vocab-and-typeof"><a href="#RDFa-vocab-and-typeof" class="headerlink" title="RDFa: vocab and typeof"></a>RDFa: vocab and typeof</h3><p>vocab: Define default vocabulary for an HTML element ç›¸å½“äºä¸€ä¸ªè¯æ±‡è¡¨<br>typeof: Declare the type of this property</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">vocab</span>=<span class="hljs-string">&quot;http://xmlns.com/foaf/0.1/&quot;</span>&gt;</span>   -&gt; è¿™é‡Œå£°æ˜äº†ä¸€ä¸ªvocabï¼Œåç»­çš„æ ‡ç­¾ä¸­å¯ä»¥ä½¿ç”¨è¯¥è¯æ±‡è¡¨ä¸­çš„æœ¯è¯­<br><br><span class="hljs-tag">&lt;<span class="hljs-name">li</span> <span class="hljs-attr">typeof</span>=<span class="hljs-string">&quot;Person&quot;</span>&gt;</span>ã€‚ --&gt; è¿™é‡Œçš„Personè¡¨ç¤ºçš„æ˜¯foaf:personçš„å«ä¹‰ï¼Œä¸éœ€è¦ä½¿ç”¨uriæ˜¾ç¤ºè¡¨ç¤º<br><span class="hljs-tag">&lt;<span class="hljs-name">a</span> <span class="hljs-attr">href</span>=<span class="hljs-string">&quot;http://example.com/eve/&quot;</span>&gt;</span>Eve<span class="hljs-tag">&lt;/<span class="hljs-name">a</span>&gt;</span> <br><span class="hljs-tag">&lt;/<span class="hljs-name">li</span>&gt;</span><br></code></pre></td></tr></table></figure><h3 id="RDFa-property-and-href"><a href="#RDFa-property-and-href" class="headerlink" title="RDFa: property and href"></a>RDFa: property and href</h3><p>When href is present, it supplies the value for the property.  ä¹Ÿå°±æ˜¯è¯´ï¼Œè¿™é‡Œçš„hrefçš„å€¼è¡¨ç¤ºäº†SPOä¸­çš„O</p><p><code>&lt;a property=â€œhomepageâ€ href=&quot;http://example.com/bob/&quot;&gt;Bob&lt;/a&gt;</code></p><p><img src="/image/ex_rdfa.png"></p>]]></content>
    
    
    
    <tags>
      
      <tag>Knowledge Graph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>çŸ¥è¯†å›¾è°±æœ¬ä½“ä¸æ¨ç†</title>
    <link href="/2020/12/03/558ont-rea/"/>
    <url>/2020/12/03/558ont-rea/</url>
    
    <content type="html"><![CDATA[<h2 id="æœ¬ä½“-Ontology"><a href="#æœ¬ä½“-Ontology" class="headerlink" title="æœ¬ä½“ Ontology"></a>æœ¬ä½“ Ontology</h2><h3 id="ä»ä¸€ä¸ªä¾‹å­è®²èµ·"><a href="#ä»ä¸€ä¸ªä¾‹å­è®²èµ·" class="headerlink" title="ä»ä¸€ä¸ªä¾‹å­è®²èµ·"></a>ä»ä¸€ä¸ªä¾‹å­è®²èµ·</h3><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs properties"><span class="hljs-attr">name</span>  <span class="hljs-string">rank</span><br><span class="hljs-attr">Bob</span>   <span class="hljs-string">Captain</span><br><span class="hljs-attr">Sue</span>   <span class="hljs-string">Sargent</span><br><span class="hljs-attr">Mary</span>  <span class="hljs-string">Admiral</span><br><span class="hljs-attr">Joe</span>   <span class="hljs-string">Sargent</span><br></code></pre></td></tr></table></figure><p>select ?x  { ?x rank â€œSargentâ€ }<br>select ?x  { ?x a Person }<br>select ?x  { ?x a MilitaryPerson }</p><p>å¦‚ä½•è¿›è¡Œinference?<br>Tell the computer some triples it infers more triples  + RDFSè¾…åŠ©</p><p>=&gt; RDFSchema OWL</p><h3 id="OWL-Web-Ontology-Language"><a href="#OWL-Web-Ontology-Language" class="headerlink" title="OWL (Web Ontology Language)"></a>OWL (Web Ontology Language)</h3><p>åŸºæœ¬æ€æƒ³:<br>I state a few OWL axioms;<br>I load lots of triples;<br>The system infers lots of new triples.</p><p>æ„å»ºæ¨¡å—:<br>Classes   â€“ ç±»<br>Properties â€“ å±æ€§<br>Individuals â€“ å•ä¸ªä¸ªä½“ï¼Œç±»ä¼¼äºinstance</p><h3 id="OWLä¸­çš„å‡è®¾"><a href="#OWLä¸­çš„å‡è®¾" class="headerlink" title="OWLä¸­çš„å‡è®¾"></a>OWLä¸­çš„å‡è®¾</h3><ol><li>Unique Name Assumption <figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-tag">bob</span> <span class="hljs-selector-tag">a</span> <span class="hljs-selector-tag">foaf</span><span class="hljs-selector-pseudo">:Person</span>; <br><span class="hljs-selector-tag">foaf</span><span class="hljs-selector-pseudo">:name</span> â€œ<span class="hljs-selector-tag">Bob</span>â€;<br><span class="hljs-selector-tag">ex</span><span class="hljs-selector-pseudo">:rank</span> â€œ<span class="hljs-selector-tag">Captain</span>â€ .<br><br><br><span class="hljs-selector-tag">sue</span> <span class="hljs-selector-tag">a</span> <span class="hljs-selector-tag">foaf</span><span class="hljs-selector-pseudo">:Person</span>; <br><span class="hljs-selector-tag">foaf</span><span class="hljs-selector-pseudo">:name</span> &quot;<span class="hljs-selector-tag">Sue</span>&quot;;<br><span class="hljs-selector-tag">ex</span><span class="hljs-selector-pseudo">:rank</span> <span class="hljs-selector-tag">Sargent</span> .<br></code></pre></td></tr></table></figure>Unique Name Assumption = TRUE:<br>=&gt; bob and sue refer to different individuals in the world</li></ol><p>Unique Name Assumption = FALSE:<br>=&gt; bob and sue may refer to the same individual in the world</p><p>OWLä½¿ç”¨çš„å‡è®¾: Unique Name Assumption = FALSE</p><ol start="2"><li>Open World or Closed World</li></ol><p>Closed World: if I donâ€™t tell it something, assume itâ€™s false, æ²¡æåˆ°å°±æ˜¯false<br>Open World: if I donâ€™t tell it something, donâ€™t assume anything I might tell it later that it is true, æ²¡æåˆ°å¯èƒ½æ˜¯å¯¹çš„</p><h3 id="Class"><a href="#Class" class="headerlink" title="Class"></a>Class</h3><p>owl: Thing æ‰€æœ‰çš„invidualå‡å±äºowl:Thingç±»</p>]]></content>
    
    
    
    <tags>
      
      <tag>Knowledge Graph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>çŸ¥è¯†å›¾è°±Blocking&amp;å…³ç³»å‹å®ä½“è§£æ</title>
    <link href="/2020/12/02/558blk-RER/"/>
    <url>/2020/12/02/558blk-RER/</url>
    
    <content type="html"><![CDATA[<h2 id="å®ä½“è§£æå›é¡¾"><a href="#å®ä½“è§£æå›é¡¾" class="headerlink" title="å®ä½“è§£æå›é¡¾"></a>å®ä½“è§£æå›é¡¾</h2><p>Deduplication: Merging Ambiguous Entities (KG-&gt;KG)<br>Record Linkage: Combining KGs (KG1-&gt;KG2)<br>Entity Mapping/Linking: Integrating New Candidates (text -&gt; KG)</p><h2 id="Blocking"><a href="#Blocking" class="headerlink" title="Blocking"></a>Blocking</h2><p>ç®€å•åŒ¹é…çš„é—®é¢˜: Comparing each entity with all other entities is too computationally demanding â€“ O(N2)</p><p>è§£å†³:  Partition entities into â€blocksâ€ â€“  O(N) blocks<br>Make only within block comparisons [so if largest block is log N in size â€“ O(N log N2)]</p><p>Problem statment:<br>Input: Set of records R  Output: Set of blocks/canopies<br><img src="/image/blk.png"></p><p>Variants:<br>Disjoint Blocking: Each mention appears in one block. (=Set Partition)<br>Non-disjoint Blocking: Mentions can appear in more than one block.</p><h3 id="Blocking-åœºæ™¯"><a href="#Blocking-åœºæ™¯" class="headerlink" title="Blocking åœºæ™¯"></a>Blocking åœºæ™¯</h3><p>Ideal scenario<br><img src="/image/ideal_blk.png"></p><p>Worst scenario<br><img src="/image/worst_blk.png"></p><p>Practical Scenario<br><img src="/image/prac_blk.png"></p><h3 id="è¯„ä¼°æŒ‡æ ‡"><a href="#è¯„ä¼°æŒ‡æ ‡" class="headerlink" title="è¯„ä¼°æŒ‡æ ‡"></a>è¯„ä¼°æŒ‡æ ‡</h3><p>Efficiency  = num of pairs compared / total number of pairs in RxR<br>Recall  = num of true matches compared / num of true matches in RxR<br>Precision = um of true matches compared / num of matches compared<br>Max Canopy Sizeï¼š max|Ci|</p><h3 id="Blocking-æ–¹å¼"><a href="#Blocking-æ–¹å¼" class="headerlink" title="Blocking æ–¹å¼"></a>Blocking æ–¹å¼</h3><ul><li>Feature-based blocking keys</li><li>Clustering or sorting</li><li>Hashing</li></ul><h4 id="Feature-based-blocking"><a href="#Feature-based-blocking" class="headerlink" title="Feature-based blocking"></a>Feature-based blocking</h4><p>æ€æƒ³:<br>Pick a key: an attribute or feature of each entity<br>Put all entities with that key in the same block<br>Perform entity resolution within each block</p><p>Keyçš„é€‰æ‹©è€ƒé‡:<br>Learn the keys, or use expert knowledge/heuristics<br>Schema awareness<br>Key type<br>Redundancy</p><p>Keyé€‰æ‹©æ‰©å±•:<br>Frequency limits<br>Adaptive keys based on frequency<br>Learning keys based on data</p><h4 id="Sort-or-cluster-based-blocking"><a href="#Sort-or-cluster-based-blocking" class="headerlink" title="Sort or cluster-based blocking"></a>Sort or cluster-based blocking</h4><p>æ€æƒ³:<br>Pick an attribute<br>Sort all entities based on that attribute<br>Use a sliding window of |K| entities and compare all pairs.</p><p>Canopy Clustering [McCallum et al KDDâ€™00]<br>Input:</p><ul><li>Mentions M (a set of entities that are needed to be cluster), x is an random chosen entity from M.</li><li>d(x,y), a distance metric</li><li>Two thresholds T1 and T2, where T1 &gt; T2</li></ul><p>Algorithm:</p><ul><li>ä»Mä¸­é€‰æ‹©ä¸€ä¸ªéšæœºçš„x</li><li>ä¸ºxç”Ÿæˆä¸€ä¸ªblockï¼Œå…¶ä¸­çš„ç‚¹æ»¡è¶³d(x,y) &lt; T1</li><li>ä¸ºxä¸­è¿™ä¸ªblockï¼Œåˆ é™¤ç¬¦åˆd(x,y)&lt;T2çš„ç‚¹ (it means that we are finishing assigning cluster labels to y) </li><li>è¿”å›ç¬¬ä¸€æ­¥ (repeat until all entities in M are assigned to at least one cluster)</li></ul><h4 id="Hash-based-blocking"><a href="#Hash-based-blocking" class="headerlink" title="Hash-based blocking"></a>Hash-based blocking</h4><p>æ€æƒ³:<br>Each block Ci is associated with a hash key hi.<br>Mention x is hashed to Ci if hash(x) = hi.<br>Within a block, all pairs are compared.<br>Each hash function results in disjoint blocks.</p><p>minhash<br>â€¦</p><h2 id="Collective-Relational-Entity-Resolution"><a href="#Collective-Relational-Entity-Resolution" class="headerlink" title="Collective Relational Entity Resolution"></a>Collective Relational Entity Resolution</h2><p>ç­–ç•¥:<br>Using PSL for collective KG ER</p><p>Encode ER dependencies in a set of rules;<br>Use soft-logic values to capture similarities;<br>Use logic to capture the constraints;</p><p>Local vs. Collective<br><img src="/image/loca_colle.png"></p><h3 id="Basic"><a href="#Basic" class="headerlink" title="Basic"></a>Basic</h3><p>Â¬SAME(E1,E2)<br>CANDSAME(E1,E2) =&gt; SAME(E1,E2)<br>CANDSAME(E1,E2) âˆ§ SIM(E1,E2)  =&gt; SAME(E1,E2)</p><h3 id="Collective"><a href="#Collective" class="headerlink" title="Collective"></a>Collective</h3><p>Symmetry: If M1 matches with M2, then M2 must match with M1<br>Transitivity: If M1 and M2 match, M2 and M3 match, then M1 and M3 match<br>Sparsity: If M1 matches with M2, then M1 cannot match with M3</p><p>example:<br>SAME(E1,E2) =&gt; SAME(E2,E1)<br>CANDSAME(A,B) âˆ§ CANDSAME(B,C) âˆ§ CANDSAME(A,C) âˆ§ SAME(A,B) âˆ§ SAME(B,C) =&gt; SAME(A,C)<br>CANDSAME(A,B) âˆ§ CANDSAME(B,C) âˆ§ SAME(A,B) =&gt; Â¬SAME(A,C)</p><h3 id="New-entity-rules"><a href="#New-entity-rules" class="headerlink" title="New entity rules"></a>New entity rules</h3><ol><li>Linking to new entities CANDSAME(E1,E2) âˆ§ NEWENTITY(E1) =&gt; SAME(E1,E2)</li><li>Avoiding new Entities   SAME(E1,E2) âˆ§ CANDSAME(E1,E3) âˆ§ NEWENTITY(E3) =&gt; Â¬SAME(E1,E3)</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Knowledge Graph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>çŸ¥è¯†å›¾è°±ä¿¡æ¯æå–-Snorkel</title>
    <link href="/2020/12/02/558snorkel/"/>
    <url>/2020/12/02/558snorkel/</url>
    
    <content type="html"><![CDATA[<h2 id="Dark-Data-Extraction"><a href="#Dark-Data-Extraction" class="headerlink" title="Dark Data Extraction"></a>Dark Data Extraction</h2><p>Structured Data(4%): Data easy to process by machines<br>Dark Data(96%): Valuable &amp; hard to process. (å æ®çš„webä¿¡æ¯çš„ç»å¤§éƒ¨åˆ†)<br>example: Scientific articles &amp; government reportsï¼ŒMedical Images</p><p>DDE:  Dark Data(Text, Tables, Images, Diagrams, etc)  =&gt; Structured Data (Enables analyses, interfaces etc.)</p><h3 id="DDE-ä¼ ç»Ÿæµç¨‹"><a href="#DDE-ä¼ ç»Ÿæµç¨‹" class="headerlink" title="DDE ä¼ ç»Ÿæµç¨‹"></a>DDE ä¼ ç»Ÿæµç¨‹</h3><p>1.Candidate Extraction =&gt; 2.Training Set  =&gt; 3.Feature Extraction =&gt; 4.Learning &amp; Inference</p><p>Example: Chemical-Disease Relation Extraction from Text<br>æ–¹å¼1: Human defines candidate entity mentions to populate a relational schema with relation mentions ï¼ˆè´¹äº‹è´¹åŠ›ï¼Œéœ€è¦domain expertisï¼‰<br>æ–¹å¼2: Relation Extraction with Machine Learning (Feature engineering is the bottleneck,however this bottleneck is solved by deep learning) è§£å†³3ï¼Œä½†æ˜¯2æ²¡è¢«è§£å†³</p><blockquote><p> Training data is THE ML dev bottleneck today.</p></blockquote><h3 id="DDEæŒ‘æˆ˜"><a href="#DDEæŒ‘æˆ˜" class="headerlink" title="DDEæŒ‘æˆ˜"></a>DDEæŒ‘æˆ˜</h3><p>Dark data extraction systems still take months or years to build using state-of-the-art machine learning (ML) systems<br>æ—¶é—´å¤ªä¹…ï¼Œæˆæœ¬å¤ªé«˜ã€‚</p><p>Training Data Creation: $$$, Slow, Static æˆæœ¬é«˜ï¼Œè€—æ—¶é•¿ï¼Œçµæ´»æ€§å·®</p><ul><li>Expensive &amp; Slow: Especially when domain expertise needed</li><li>Static: Real-world problems change but hand-labeled training data does not.</li></ul><h2 id="Snorkel"><a href="#Snorkel" class="headerlink" title="Snorkel"></a>Snorkel</h2><blockquote><p>Motiviton: Can we use noisier training data and still train high-performance models?</p></blockquote><p>Snorkel: A System for Rapidly Generating Training Data with Weak Supervision<br>ç®€å•çš„è¯´ï¼Œè¿™æ˜¯ä¸€ä¸ªç”Ÿæˆè®­ç»ƒé›†çš„æ¡†æ¶ã€‚</p><p><img src="/image/snorkel.png"></p><h2 id="Snorkel-Pipeline-æ¦‚æ‹¬"><a href="#Snorkel-Pipeline-æ¦‚æ‹¬" class="headerlink" title="Snorkel Pipeline æ¦‚æ‹¬"></a>Snorkel Pipeline æ¦‚æ‹¬</h2><ul><li>Users write labeling functions to generate noisy labels</li><li>Snorkel models and combine these labels</li><li>We use the resulting probabilistic training labels to train a model<br><img src="/image/pipeline_snorkel.png"></li></ul><h3 id="Labeling-Functions"><a href="#Labeling-Functions" class="headerlink" title="Labeling Functions"></a>Labeling Functions</h3><p>Users give Snorkel labeling functions that label data points<br>ç®€ç­”çš„è¯´ï¼Œè¿™ä¸ªLabeling functionçš„èµ·åˆ°çš„ä½œç”¨å’Œhuman expertiseç±»ä¼¼ï¼Œç”¨äºè§„å®šä¸€äº›è§„åˆ™æ¥è®©snorkelåç»­è¿‡ç¨‹ä¸­å‘ç°texté‡Œä¸å…¶åŒ¹é…çš„æ¨¡å¼æ¥å¯¹æå–çš„ä¿¡æ¯ä¿¡æ¯æ ‡æ³¨ã€‚</p><p>å› æ­¤ï¼Œç”¨æˆ·å¯ä»¥ä¹¦å†™å°½å¯èƒ½å¤šçš„Labeling Functionsæ¥æé«˜å‡†ç¡®æ€§ï¼Œå¹¶ä¸”Labeling Functionsä¹‹é—´å¯ä»¥æœ‰å†²çªï¼Œå› ä¸ºåç»­ç”¨åˆ°çš„æ˜¯æ¦‚ç‡æ¥ç¡®å®šç»“æœã€‚</p><h3 id="Model-Combine-Iterate"><a href="#Model-Combine-Iterate" class="headerlink" title="Model, Combine, Iterate"></a>Model, Combine, Iterate</h3><p>Snorkel models and combine these labels</p><p>è¿™é‡Œsnorklæ ¹æ®ç”¨æˆ·ä¹¦å†™çš„Labeling functionsè¿›è¡Œå»ºæ¨¡ï¼Œå¹¶è¿­ä»£è¿è¡Œæ¨¡å‹ï¼Œå¾—åˆ°ä¸€ä¸ªprobabilistic training labels </p><h3 id="Train-End-Model"><a href="#Train-End-Model" class="headerlink" title="Train End Model"></a>Train End Model</h3><p>Use the resulting probabilistic training labels to train a model</p><h2 id="Snorkel-challenge-Step2"><a href="#Snorkel-challenge-Step2" class="headerlink" title="Snorkel challenge - Step2:"></a>Snorkel challenge - Step2:</h2><blockquote><p>How do we model and combine LFs? How to best reweight and combine the noisy supervision signal?</p></blockquote><p>è§£å†³æ–¹å¼: A Generative Model of the Training Data Labeling Process<br>ä½¿ç”¨ç”Ÿæˆå¼æ¨¡å‹åæ˜ å„ä¸ªLFå¾—åˆ°çš„æ ‡æ³¨ç»“æœ<br><img src="/image/GM_s.png"></p><p><img src="/image/example_snorkel.png"></p><p>ä»ä¸­ä¹Ÿå¯ä»¥å‘ç°ï¼ŒLFå¯ä»¥å­˜åœ¨å†²çªï¼Œå¹¶ä¸”å¯¹ä»–å­˜åœ¨ç›¸å…³è”çš„LFå»ºæ¨¡åˆ†æä¹Ÿèƒ½å¤Ÿæé«˜ç²¾åº¦ã€‚ï¼ˆ We can learn dependency structure using statistical and/or static analysis techniques [ICML â€™17, NIPS â€˜17]ï¼‰</p><h2 id="Snorkel-Pipeline-ç»†èŠ‚"><a href="#Snorkel-Pipeline-ç»†èŠ‚" class="headerlink" title="Snorkel Pipeline ç»†èŠ‚"></a>Snorkel Pipeline ç»†èŠ‚</h2><h3 id="Designing-Labeling-Functions-LFs"><a href="#Designing-Labeling-Functions-LFs" class="headerlink" title="Designing Labeling Functions (LFs)"></a>Designing Labeling Functions (LFs)</h3><p>Write heuristics to noisily label data! åŒºåˆ«äºäººå·¥æ‰‹åŠ¨æ ‡è®°ï¼Œè¿™é‡Œsnorkelå†™label functionçš„ç›®çš„æ˜¯ä¸ºäº†åç»­çš„Programmatically generate training data</p><p>å¦‚ä½•è®¾è®¡Labeling function:<br>Human annotators leverage real-world knowledge, context, and common-sense heuristics to make labeling decisions</p><p>Labeling function ç»“æœ:<br>{-1, 0, 1} =&gt; {Negative, Abstain, Positive}</p><p>æµç¨‹:<br>textä¸­æå–candidatesï¼Œcandidatesä¸­åŒ…å«trueå’Œfalseçš„instancesï¼Œä½¿ç”¨è®¾è®¡çš„Labeling functionæ¥åˆ¤æ–­candidateä¸ºtrueæˆ–false</p><p>ç›®æ ‡:<br>Apply labeling functions to all candidates to predict both positive and negative labels</p><p>Tip:<br>Labeling functions can be noisyï¼Œæ¯•ç«Ÿæ— æ³•æ¶µç›–æ‰€æœ‰èŒƒå›´ï¼Œæ‰€æœ‰è¯­å¢ƒã€‚</p><p>è®¾è®¡ç­–ç•¥:</p><ol><li><p>Pattern-based Labeling Functions<br> Common sense patterns or keywords<br> String matching via regular expressions and other heuristics</p></li><li><p>Distant Supervision Labeling Functions<br> Use an existing database of known facts to generate noisy labels</p></li></ol><p>LFè¯„ä»·æŒ‡æ ‡:<br>Accuracy: percentage of candidates a labeling function labels correctly<br>Coverage: percentage of all candidates that are labeled by &gt;= 1 LFs<br>Conflict: percentage of candidates with &gt;1 labels that disagree</p><p>LFé€‰æ‹©æ ‡å‡†:<br>We want high-coverage, high-accuracy LFs<br>LFs need to label with probability better than random chance<br>Conflict is actually good â€” it allows our algorithm to learn information about the LF</p><h3 id="Build-Generative-Model-Unifying-Supervision"><a href="#Build-Generative-Model-Unifying-Supervision" class="headerlink" title="Build Generative Model: Unifying Supervision"></a>Build Generative Model: Unifying Supervision</h3><p>Simple Baseline: Majority Vote<br>Automatically Learning LF Accuracies<br>LF Dependency Learning</p><h3 id="Build-Discriminative-Model-â€œCompilingâ€-Rules-into-Features"><a href="#Build-Discriminative-Model-â€œCompilingâ€-Rules-into-Features" class="headerlink" title="Build Discriminative Model: â€œCompilingâ€ Rules into Features"></a>Build Discriminative Model: â€œCompilingâ€ Rules into Features</h3><p>Training with Probabilistic Labels<br>The Death of Manual Feature Engineering<br>Why Do We Need the Discriminative Model?</p>]]></content>
    
    
    
    <tags>
      
      <tag>Knowledge Graph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>çŸ¥è¯†å›¾è°±å­—ç¬¦ä¸²åŒ¹é…</title>
    <link href="/2020/12/01/558str-match/"/>
    <url>/2020/12/01/558str-match/</url>
    
    <content type="html"><![CDATA[<h2 id="å­—ç¬¦ä¸²åŒ¹é…é—®é¢˜"><a href="#å­—ç¬¦ä¸²åŒ¹é…é—®é¢˜" class="headerlink" title="å­—ç¬¦ä¸²åŒ¹é…é—®é¢˜"></a>å­—ç¬¦ä¸²åŒ¹é…é—®é¢˜</h2><h3 id="Problem-Statement"><a href="#Problem-Statement" class="headerlink" title="Problem Statement:"></a>Problem Statement:</h3><p>Given X and Y sets of strings, Find pairs (x, y) such that both x and y refer to the same real world entity. </p><p>Then use precision(fraction of pairs found that are correct) and recall(fraction of pairs found) to evaluate algorithms</p><h3 id="Why-canâ€™t-match-perfectly"><a href="#Why-canâ€™t-match-perfectly" class="headerlink" title="Why canâ€™t match perfectly"></a>Why canâ€™t match perfectly</h3><p>Typos    â€œJohâ€ vs. â€œJhonâ€<br>OCR errors â€œJ0hnâ€ vs â€œJohnâ€<br>Formatting conventions â€03/17â€ vs â€œMarch 17â€<br>Abbreviations â€œJ. S. Sargentâ€ vs â€œJohn Singer Sargentâ€<br>Nick name â€Johnâ€ vs â€œJockâ€<br>Word order â€œSargent, John S.â€ vs â€œJohn S. Sargentâ€</p><p>å› æ­¤ï¼Œè½¬è€Œè®¡ç®—å­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦</p><h2 id="Similiarity-Measure"><a href="#Similiarity-Measure" class="headerlink" title="Similiarity Measure"></a>Similiarity Measure</h2><p>Similarity(x, y) in [0, 1] is better than distance(x, y) in [0, âˆ)</p><p>Types of Similarity Metrics:</p><ul><li>Sequence based</li><li>Set based</li><li>Hybrid</li><li>Phonetic</li></ul><h2 id="Sequence-Based-Metrics"><a href="#Sequence-Based-Metrics" class="headerlink" title="Sequence Based Metrics"></a>Sequence Based Metrics</h2><h3 id="Edit-Distance-Levenshtein-Distance"><a href="#Edit-Distance-Levenshtein-Distance" class="headerlink" title="Edit Distance/Levenshtein Distance"></a>Edit Distance/Levenshtein Distance</h3><p>Online calculator: <a href="http://planetcalc.com/1721/">http://planetcalc.com/1721/</a></p><p>lev(x, y) is the minimum cost to transform x to y(insert,delete,substitute)</p><p>åŸç†ï¼š åŠ¨æ€è§„åˆ’ d(i,j)<br>case1: xi  = yj  =&gt; d(i,j) = d(i-1,j-1)<br>case2: xi != yj  =&gt; d(i,j) = min(  d(i-1,j) + 1 , d(i,j-1) + 1 , d(i-1,j-1) + 1)</p><p>ç¼ºé™·:<br>Too high a cost for deleting a sequence of characters, so it is not suitable for abbreviation cases (example: lev(John Singer Sargent,John S. Sargent ) = 5, lev(John Singer Sargent,John Klinger Sargent ) = 5 )</p><h3 id="Needleman-Wunch-Measure"><a href="#Needleman-Wunch-Measure" class="headerlink" title="Needleman-Wunch Measure"></a>Needleman-Wunch Measure</h3><p>Generalization of levenstein(x, y), ä¸ºäº†è§£å†³levå¸¦æ¥çš„ç¼©å†™é—®é¢˜çš„ä¸€ç§æ–°çš„åº¦é‡æ–¹å¼<br>å¾—åˆ°çš„ç»“æœæ˜¯ä¸¤ä¸ªstringç›¸ä¼¼çš„è¯„åˆ†ï¼Œè€Œä¸æ˜¯è·ç¦»</p><p><img src="/image/NW.png"></p><p>ç¼ºé™·:<br>Longer gaps are penalized more, bad for names (example:nw(John Singer Sargent,John S.     Sargent) = 25, nw(John Stanislaus Sargent,John S.         Sargent)</p><h3 id="Affine-Gap-Measure"><a href="#Affine-Gap-Measure" class="headerlink" title="Affine Gap Measure"></a>Affine Gap Measure</h3><p>Generalization of needleman-wunch(x, y),ä¸ºäº†è§£å†³Needleman-Wunchå¸¦æ¥çš„é•¿gapé—®é¢˜<br>Intuition: two small gaps are worse than one large one<br><img src="/image/Afm.png"></p><h3 id="Smith-Waterman"><a href="#Smith-Waterman" class="headerlink" title="Smith-Waterman"></a>Smith-Waterman</h3><p>å¯ä»¥è¯´æ˜¯Needleman-Wunchçš„localç‰ˆæœ¬</p><p>Needleman-Wunch: Fully align sequences, opening gaps as needed,ä¹Ÿå°±æ˜¯è¯´ä¸¤è¾¹ç©ºæ ¼éƒ½è¢«è€ƒè™‘è¿›å»äº†çš„<br><img src="/image/smith-waterman.png"></p><h3 id="Jaro-Similarity-Measure"><a href="#Jaro-Similarity-Measure" class="headerlink" title="Jaro Similarity Measure"></a>Jaro Similarity Measure</h3><p>Get points for having characters in common<br>â€¢ but only if they are â€œclose byâ€<br>Get points for common characters in the same order<br>â€¢ lose points for transpositions<br><img src="/image/Jaro-sim.png"><br>ï¼Ÿï¼Ÿï¼Ÿ</p><h3 id="Jaro-Winkler-Measure"><a href="#Jaro-Winkler-Measure" class="headerlink" title="Jaro-Winkler Measure"></a>Jaro-Winkler Measure</h3><p>ï¼Ÿï¼Ÿï¼Ÿï¼Ÿ</p><h2 id="Set-Based-Metrics"><a href="#Set-Based-Metrics" class="headerlink" title="Set-Based Metrics"></a>Set-Based Metrics</h2><p>Generate set of tokens from the strings and then measure similarity between the sets of tokens</p><h3 id="Jaccard-Measure"><a href="#Jaccard-Measure" class="headerlink" title="Jaccard Measure"></a>Jaccard Measure</h3><h3 id="TF-IDF-Measure"><a href="#TF-IDF-Measure" class="headerlink" title="TF-IDF Measure"></a>TF-IDF Measure</h3><h2 id="Hybrid-Similarity-Measures"><a href="#Hybrid-Similarity-Measures" class="headerlink" title="Hybrid Similarity Measures"></a>Hybrid Similarity Measures</h2><p>Do the set-based thing but use a similiarity metric for each element of the set</p><h3 id="Generalized-Jaccard-Measure"><a href="#Generalized-Jaccard-Measure" class="headerlink" title="Generalized Jaccard Measure"></a>Generalized Jaccard Measure</h3><h3 id="The-Soft-TF-IDF-Measure"><a href="#The-Soft-TF-IDF-Measure" class="headerlink" title="The Soft TF/IDF Measure"></a>The Soft TF/IDF Measure</h3><h3 id="Monge-Elkan-Measure"><a href="#Monge-Elkan-Measure" class="headerlink" title="Monge-Elkan Measure"></a>Monge-Elkan Measure</h3><h2 id="Phonetic-Similarity"><a href="#Phonetic-Similarity" class="headerlink" title="Phonetic Similarity"></a>Phonetic Similarity</h2><h3 id="Soundex"><a href="#Soundex" class="headerlink" title="Soundex"></a>Soundex</h3>]]></content>
    
    
    
    <tags>
      
      <tag>Knowledge Graph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>çŸ¥è¯†å›¾è°±å®ä½“é“¾æ¥</title>
    <link href="/2020/12/01/558ent-link/"/>
    <url>/2020/12/01/558ent-link/</url>
    
    <content type="html"><![CDATA[<h2 id="NLPä¸­çš„å®ä½“ä»»åŠ¡"><a href="#NLPä¸­çš„å®ä½“ä»»åŠ¡" class="headerlink" title="NLPä¸­çš„å®ä½“ä»»åŠ¡"></a>NLPä¸­çš„å®ä½“ä»»åŠ¡</h2><ul><li>NER (Recognition): detecting the phrase that is the name of an entity å®ä½“å‘ç°</li><li>NEC (Classification): assigning an entity type to the phrase å®ä½“ç±»å‹åˆ†ç±»</li><li>NEL (Linking): establishing the identity of the entity in a given reference<br>database (Wikipedia, DBpedia, YAGO) å®ä½“é“¾æ¥</li><li>Coreference: any phrase that makes reference to an entity instance, including<br>pronouns, noun phrases, abbreviations, acronyms, etcâ€¦ å®ä½“æŒ‡ä»£</li></ul><h3 id="Named-Entity-Linking-ï¼ˆNELï¼‰"><a href="#Named-Entity-Linking-ï¼ˆNELï¼‰" class="headerlink" title="Named Entity Linking ï¼ˆNELï¼‰"></a>Named Entity Linking ï¼ˆNELï¼‰</h3><p>Problem statement:<br>Potentially ambiguous entity mention (â€œParisâ€) needs to be linked to a canonical identifier/instance (<a href="http://dbpedia.org/resource/Paris">http://dbpedia.org/resource/Paris</a>) that fits the intended referent in the context of the text</p><p>entity linking (text -&gt; KG)</p><h3 id="Named-Entity-Recognition-and-Disambiguation-NERD"><a href="#Named-Entity-Recognition-and-Disambiguation-NERD" class="headerlink" title="Named Entity Recognition and Disambiguation (NERD)"></a>Named Entity Recognition and Disambiguation (NERD)</h3><p>å‡è®¾: the mentions are already recognized in text</p><p>Combine recognition and disambiguation/linking -&gt; NERD<br>NERC + NED = NERD</p><h2 id="Knowledge-bases"><a href="#Knowledge-bases" class="headerlink" title="Knowledge bases"></a>Knowledge bases</h2><p>A catalog of things, usually entities. Each one has:<br>one or more names;<br>other attributes;<br>Connections to other entities<br>Textual description;</p><p>Knowledge bases are also connected to each other</p><p>Example:<br>Structured knowledge bases: DBpedia &amp; Wikidata<br>Unstructured knowledge bases: Wikipedia</p><h2 id="å®ä½“é“¾æ¥çš„å¥½å¤„"><a href="#å®ä½“é“¾æ¥çš„å¥½å¤„" class="headerlink" title="å®ä½“é“¾æ¥çš„å¥½å¤„"></a>å®ä½“é“¾æ¥çš„å¥½å¤„</h2><p>Benefits of connecting text and knowledge bases:<br>Automatic knowledge base construction (AKBC) / Knowledge base completion (KBC)å¸®åŠ©KBçš„å®Œå–„</p><h2 id="å®ä½“é“¾æ¥çš„æŒ‘æˆ˜"><a href="#å®ä½“é“¾æ¥çš„æŒ‘æˆ˜" class="headerlink" title="å®ä½“é“¾æ¥çš„æŒ‘æˆ˜"></a>å®ä½“é“¾æ¥çš„æŒ‘æˆ˜</h2><ol><li>name ambiguity: Entities with the same name</li><li>name variation: Different names for the same entity</li><li>Missing (NIL) entities</li></ol><h2 id="å®ä½“é“¾æ¥æ¡†æ¶"><a href="#å®ä½“é“¾æ¥æ¡†æ¶" class="headerlink" title="å®ä½“é“¾æ¥æ¡†æ¶"></a>å®ä½“é“¾æ¥æ¡†æ¶</h2><p><img src="/image/EL.png"></p><h3 id="Mention-Detection-NER"><a href="#Mention-Detection-NER" class="headerlink" title="Mention Detection (NER)"></a>Mention Detection (NER)</h3><p>åœ¨æ–‡æ¡£ä¸­è¯†åˆ«å‡ºæ½œåœ¨çš„å®ä½“</p><h3 id="Candidate-generation-selection"><a href="#Candidate-generation-selection" class="headerlink" title="Candidate generation/selection"></a>Candidate generation/selection</h3><p>Balance between generating too many candidates (too much â€˜noiseâ€™) and generating too little candidates (missing the correct one)<br>Trade-off between precision and recall -&gt;  an art by itself!<br>In practice, something like 30 candidates per mention is usually enough</p><p>å¦‚ä½•é€‰æ‹©top30?<br>commonness: for a given mention, how relatively often it refers to some instance in Wikipedia.<br>Also, observe dominance within a form and topical bias</p><h3 id="Disambiguation"><a href="#Disambiguation" class="headerlink" title="Disambiguation"></a>Disambiguation</h3><p>Goal: decide which of the candidates (or none) is the correct referent.</p><p>æ–¹æ³•:</p><ol><li><p>Word-based methods: DBpedia Spotlight<br>Compute cosine similarity between the text paragraph with an entity mention and Wikipedia descriptions of each candidate</p></li><li><p>Graph-based methods: AIDA and AGDISTIS<br>Construct a subgraph that contains all entity candidates with some facts from a KB, then find the best connected candidates per mention.</p></li></ol><h2 id="å®ä½“é“¾æ¥çš„è¯„ä¼°"><a href="#å®ä½“é“¾æ¥çš„è¯„ä¼°" class="headerlink" title="å®ä½“é“¾æ¥çš„è¯„ä¼°"></a>å®ä½“é“¾æ¥çš„è¯„ä¼°</h2><ol><li>Assign a true positive (TP), false positive (FP), and/or false negative (FN) per mention occurrence</li><li>Count the TPs, FPs, and FNs across all mentions</li><li>Compute precision, recall, and F1-scores once on top of these</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Knowledge Graph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>çŸ¥è¯†å›¾è°±æŸ¥è¯¢</title>
    <link href="/2020/12/01/558query-kg/"/>
    <url>/2020/12/01/558query-kg/</url>
    
    <content type="html"><![CDATA[<h2 id="Property-Graphs"><a href="#Property-Graphs" class="headerlink" title="Property Graphs"></a>Property Graphs</h2><h3 id="å®šä¹‰"><a href="#å®šä¹‰" class="headerlink" title="å®šä¹‰"></a>å®šä¹‰</h3><p>Also called Labeled Property Graphs (LPG)</p><p>It is a framework for representing data and metadata with a graph of nodes and links</p><ul><li>both nodes and links may have additional key/value pairs (â€œpropertiesâ€) </li><li>nodes are â€œjustâ€ nodes, not necessarily URLs</li></ul><p>Link annotations are very useful to assign temporal, spatial, provenance, etc.</p><p><img src="/image/LPG.png"></p><h3 id="LPG-vs-RDF"><a href="#LPG-vs-RDF" class="headerlink" title="LPG vs. RDF"></a>LPG vs. RDF</h3><p>Similarity:<br>Both represent directed graphs as a basic data structure;<br>Both have associated graph-oriented query languages;<br>In practice, both are used as â€œgraph storesâ€, accessible via HTTP and/or various API-s;</p><p>Differences:<br>RDF has an emphasis on OWA, and is rooted in the Web via URL-s. Not the case for PG, PG node is oblivious to what it â€œcontainsâ€: can be a URL, can be a literal;  (nodeä¸ä¸€å®šæ˜¯uri)<br>PG includes the possibility to add simple key/value pairs to â€œrelationshipsâ€ (i.e., RDF predicates) ï¼ˆå…³ç³»ä¸­å¯ä»¥å¸¦å±æ€§ï¼‰</p><h3 id="RDF-triple-stores-vs-Graph-DBs"><a href="#RDF-triple-stores-vs-Graph-DBs" class="headerlink" title="RDF triple-stores vs. Graph DBs"></a>RDF triple-stores vs. Graph DBs</h3><p>In RDF triple-stores everything is expressed in terms of SPO and its predicates canâ€™t have attributes;<br>In Graph DBs predicates can have attributes;<br>Fair to say that RDF triple-stores are a kind of Graph DB;</p><p><img src="/image/rdf-gdb.png"></p><h2 id="SPARQL-SPARQL-Protocol-and-RDF-Query-Language"><a href="#SPARQL-SPARQL-Protocol-and-RDF-Query-Language" class="headerlink" title="SPARQL (SPARQL Protocol and RDF Query Language)"></a>SPARQL (SPARQL Protocol and RDF Query Language)</h2><p>SELECT/ASK/CONSTRUCT/DESCRIBE</p><p>Main idea:  Pattern matching (æƒ³åƒæˆå¯¹å›¾è¿›è¡Œæœç´¢)</p><p>Queries describe sub-graphs of the queried graph;<br>Graph patterns are RDF graphs specified in Turtle syntax, which contain variables (prefixed by either â€œ?â€ or â€œ$â€);<br>Sub-graphs that match the graph patterns yield a result</p><h3 id="å›¾æ¨¡å¼-Graph-Pattern"><a href="#å›¾æ¨¡å¼-Graph-Pattern" class="headerlink" title="å›¾æ¨¡å¼ Graph Pattern"></a>å›¾æ¨¡å¼ Graph Pattern</h3><p>åŸºæœ¬åŒ¹é…: Where a set of triple patterns must match<br>é›†åˆåŒ¹é… {}: Where a set of graph patterns must all match<br>å¯é€‰åŒ¹é… OPTIONAL: Where additional patterns may extend the solution =&gt; ç®€å•ç†è§£å°±æ˜¯è¿™ä¸ªèŠ‚ç‚¹æœ‰å±æ€§åˆ™åŠ ï¼Œæ— åˆ™çœç•¥<br>é™„åŠ åŒ¹é… UNION: Where two or more possible patterns are tried<br>å‘½åå›¾ GRAPH: Where patterns are matched against named graphs</p><h3 id="FILTER-NOT-EXISTS-vs-MINUS"><a href="#FILTER-NOT-EXISTS-vs-MINUS" class="headerlink" title="FILTER NOT EXISTS vs. MINUS"></a>FILTER NOT EXISTS vs. MINUS</h3><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs asciidoc">Data<br>@prefix  :       &lt;http://example/&gt; .<br>@prefix  rdf:    &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; .<br>@prefix  foaf:   &lt;http://xmlns.com/foaf/0.1/&gt; .<br><br><span class="hljs-meta">:alice  rdf:type</span>   foaf:Person .<br><span class="hljs-meta">:alice  foaf:name</span>  &quot;Alice&quot; .<br><span class="hljs-meta">:bob    rdf:type</span>   foaf:Person . <br><br>Query:<br>PREFIX  rdf:    &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt; <br>PREFIX  foaf:   &lt;http://xmlns.com/foaf/0.1/&gt; <br><br>SELECT ?person<br>WHERE <br>&#123;<br><span class="hljs-code">    ?person rdf:type  foaf:Person .</span><br><span class="hljs-code">    FILTER NOT EXISTS &#123; ?person foaf:name ?name &#125; # =&gt; ç­›é€‰å‡ºæ²¡æœ‰è¿™æ¡è¾¹çš„ç‚¹</span><br>&#125; <br><br>Result<br>person<br>&lt;http://example/bob&gt;<br><br><br>Data:<br>@prefix :       &lt;http://example/&gt; .<br>@prefix foaf:   &lt;http://xmlns.com/foaf/0.1/&gt; .<br><br><span class="hljs-meta">:alice  foaf:givenName</span> &quot;Alice&quot; ;<br><span class="hljs-code">        foaf:familyName &quot;Smith&quot; .</span><br><span class="hljs-meta">:bob    foaf:givenName</span> &quot;Bob&quot; ;<br><span class="hljs-code">        foaf:familyName &quot;Jones&quot; .</span><br><span class="hljs-meta">:carol  foaf:givenName</span> &quot;Carol&quot; ;<br><span class="hljs-code">        foaf:familyName &quot;Smith&quot; </span><br><br>Query:<br>PREFIX :     &lt;http://example/&gt;<br>PREFIX foaf: &lt;http://xmlns.com/foaf/0.1/&gt;<br><br>SELECT DISTINCT ?s<br>WHERE &#123;<br><span class="hljs-code">   ?s ?p ?o .</span><br><span class="hljs-code">   MINUS &#123;</span><br><span class="hljs-code">      ?s foaf:givenName &quot;Bob&quot; .</span><br><span class="hljs-code">   &#125;</span><br>&#125;<br><br>Result:<br>s<br>&lt;http://example/carol&gt;<br>&lt;http://example/alice&gt;<br></code></pre></td></tr></table></figure><p>ç®€å•çš„è¯´, FILTER å…±äº«å¯¹è±¡å¼•ç”¨ MINUS ä¸å…±äº«, ä¾‹å­</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs ruby"><span class="hljs-symbol">Data:</span> <br>@prefix : &lt;<span class="hljs-symbol">http:</span>/<span class="hljs-regexp">/example/</span>&gt; .<br><span class="hljs-symbol">:a</span> <span class="hljs-symbol">:b</span> <span class="hljs-symbol">:c</span> .<br><br><span class="hljs-symbol">Query:</span><br>SELECT *<br>&#123; <br>  <span class="hljs-string">?s</span> <span class="hljs-string">?p</span> <span class="hljs-string">?o</span><br>  FILTER NOT EXISTS &#123; <span class="hljs-string">?x</span> <span class="hljs-string">?y</span> <span class="hljs-string">?z</span> &#125; <span class="hljs-comment"># =&gt; è¿™é‡Œ  ?s = ?x</span><br>&#125;<br><br><span class="hljs-symbol">Result:</span><br>Null<br><br><br><span class="hljs-symbol">Data:</span> <br>@prefix : &lt;<span class="hljs-symbol">http:</span>/<span class="hljs-regexp">/example/</span>&gt; .<br><span class="hljs-symbol">:a</span> <span class="hljs-symbol">:b</span> <span class="hljs-symbol">:c</span> .<br><br><span class="hljs-symbol">Query:</span><br>SELECT *<br>&#123; <br>   <span class="hljs-string">?s</span> <span class="hljs-string">?p</span> <span class="hljs-string">?o</span> <br>   MINUS <br>     &#123; <span class="hljs-string">?x</span> <span class="hljs-string">?y</span> <span class="hljs-string">?z</span> &#125;  <span class="hljs-comment"># =&gt; è¿™é‡Œ ?s != ?x</span><br>&#125;<br><br>Result<br>s                        p                  o<br>&lt;<span class="hljs-symbol">http:</span>/<span class="hljs-regexp">/example/a</span>&gt; &lt;<span class="hljs-symbol">http:</span>/<span class="hljs-regexp">/example/b</span>&gt; &lt;<span class="hljs-symbol">http:</span>/<span class="hljs-regexp">/example/c</span>&gt;<br><br><br></code></pre></td></tr></table></figure><h3 id="Aggregation"><a href="#Aggregation" class="headerlink" title="Aggregation"></a>Aggregation</h3><p>SELECT (SUM(?lprice) AS ?totalPrice)<br>GROUP BY ?org<br>GROUP BY ?a ?b ?c<br>HAVING (SUM(?lprice) &gt; 10)</p><h3 id="Subqueries"><a href="#Subqueries" class="headerlink" title="Subqueries"></a>Subqueries</h3><p>åŸåˆ™: å…ˆè®¡ç®—å†…éƒ¨ï¼Œåœ¨ç®—å¤–éƒ¨çš„</p><h3 id="RDF-Dataset"><a href="#RDF-Dataset" class="headerlink" title="RDF Dataset"></a>RDF Dataset</h3><p>RDF Dataset =<br>    default graph<br>    + named graph 1<br>    + named graph 2<br>    + â€¦</p><p>Separate graphs enable you to reason about who said what and when</p><h3 id="å¸¸ç”¨SPARQLè¯­å¥"><a href="#å¸¸ç”¨SPARQLè¯­å¥" class="headerlink" title="å¸¸ç”¨SPARQLè¯­å¥"></a>å¸¸ç”¨SPARQLè¯­å¥</h3><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs groovy"><span class="hljs-attr">Data:</span><br><span class="hljs-meta">@prefix</span> <span class="hljs-attr">foaf:</span>  &lt;<span class="hljs-attr">http:</span><span class="hljs-comment">//xmlns.com/foaf/0.1/&gt; .</span><br>          <br><span class="hljs-attr">_:</span>a  <span class="hljs-attr">foaf:</span>givenName   <span class="hljs-string">&quot;John&quot;</span> .<br><span class="hljs-attr">_:</span>a  <span class="hljs-attr">foaf:</span>surname  <span class="hljs-string">&quot;Doe&quot;</span> .<br><br><span class="hljs-attr">Query:</span><br>PREFIX <span class="hljs-attr">foaf:</span>   &lt;<span class="hljs-attr">http:</span><span class="hljs-comment">//xmlns.com/foaf/0.1/&gt;</span><br>SELECT ?name<br>WHERE  &#123; <br>   ?P foaf:givenName ?G ; <br>      foaf:surname ?S <br>   BIND(CONCAT(?G, <span class="hljs-string">&quot; &quot;</span>, ?S) AS ?name)  # =&gt; Creating Values with Expressions<br><br>&#125;<br><br>Result:<br>name<br>â€œJohn Doeâ€<br><br><br>Data:<br>@prefix dc:   &lt;http:<span class="hljs-comment">//purl.org/dc/elements/1.1/&gt; .</span><br>@prefix :     &lt;<span class="hljs-attr">http:</span><span class="hljs-comment">//example.org/book/&gt; .</span><br><span class="hljs-meta">@prefix</span> <span class="hljs-attr">ns:</span>   &lt;<span class="hljs-attr">http:</span><span class="hljs-comment">//example.org/ns#&gt; .</span><br><br>:book1  <span class="hljs-attr">dc:</span>title  <span class="hljs-string">&quot;SPARQL Tutorial&quot;</span> .<br>:book1  <span class="hljs-attr">ns:</span>price  <span class="hljs-number">42</span> .<br>:book2  <span class="hljs-attr">dc:</span>title  <span class="hljs-string">&quot;The Semantic Web&quot;</span> .<br>:book2  <span class="hljs-attr">ns:</span>price  <span class="hljs-number">23</span> .<br><br><span class="hljs-attr">Query:</span><br>PREFIX <span class="hljs-attr">foaf:</span>   &lt;<span class="hljs-attr">http:</span><span class="hljs-comment">//xmlns.com/foaf/0.1/&gt;</span><br>PREFIX  <span class="hljs-attr">dc:</span>  &lt;<span class="hljs-attr">http:</span><span class="hljs-comment">//purl.org/dc/elements/1.1/&gt;</span><br>SELECT  ?title<br>WHERE   &#123; ?x dc:title ?title <br>          FILTER regex(?title, <span class="hljs-string">&quot;^SPARQL&quot;</span>)  # =&gt; Restricting the Value of <br>          Strings<br>          # FILTER (?price &lt; <span class="hljs-number">30.5</span>)<br>        &#125;<br><br>Result:<br>title<br><span class="hljs-string">&quot;SPARQL Tutorial&quot;</span><br><br><br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Knowledge Graph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>çŸ¥è¯†å›¾è°±å®ä½“è§£æ</title>
    <link href="/2020/12/01/558ent-res/"/>
    <url>/2020/12/01/558ent-res/</url>
    
    <content type="html"><![CDATA[<h2 id="ä¸ºä»€ä¹ˆéœ€è¦å®ä½“è§£æï¼Ÿ"><a href="#ä¸ºä»€ä¹ˆéœ€è¦å®ä½“è§£æï¼Ÿ" class="headerlink" title="ä¸ºä»€ä¹ˆéœ€è¦å®ä½“è§£æï¼Ÿ"></a>ä¸ºä»€ä¹ˆéœ€è¦å®ä½“è§£æï¼Ÿ</h2><p>Ambiguity: Entities with the same name<br>Variance: Different names for the same entity</p><p>è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨record/mentionæ¥è¡¨ç¤ºæ•°å­—ä¸–ç•Œä¸­çš„ä¸€ä¸ªå®ä½“</p><h2 id="ä»€ä¹ˆæ˜¯å®ä½“è§£æï¼Ÿ"><a href="#ä»€ä¹ˆæ˜¯å®ä½“è§£æï¼Ÿ" class="headerlink" title="ä»€ä¹ˆæ˜¯å®ä½“è§£æï¼Ÿ"></a>ä»€ä¹ˆæ˜¯å®ä½“è§£æï¼Ÿ</h2><p>The task of disambiguating records that correspond to real world entities across and within datasets.</p><h2 id="å®ä½“è§£æçš„å››ä¸ªæ–¹é¢"><a href="#å®ä½“è§£æçš„å››ä¸ªæ–¹é¢" class="headerlink" title="å®ä½“è§£æçš„å››ä¸ªæ–¹é¢"></a>å®ä½“è§£æçš„å››ä¸ªæ–¹é¢</h2><p>Coreference: Unifying mentions of the same entity in a single document (text-&gt;text)<br>Entity Linking: Mapping mentions from text to the canonical entity in a KG (text-&gt;KG)<br>Deduplication: Unifying mentions within a KG into a single view (KG-&gt;KG)<br>Record Linkage: Matching enentites across two different KGs (KG1 -&gt; KG2)</p><h3 id="Coreference"><a href="#Coreference" class="headerlink" title="Coreference"></a>Coreference</h3><p>ä¸¾ä¸ªä¾‹å­ï¼Œä¸€ç¯‡æ–‡æ¡£ä¸­æœ‰è®¸å¤šçš„ä»£è¯ï¼Œéœ€è¦å°†è¿™äº›ä»£è¯ä¸ä¹‹å‰æåˆ°çš„åè¯è¿›è¡ŒæŒ‡ä»£</p><h3 id="Entity-Linking"><a href="#Entity-Linking" class="headerlink" title="Entity Linking"></a>Entity Linking</h3><p>ä¸¾ä¸ªä¾‹å­ï¼Œä¸€ç¯‡æ–‡æ¡£å‡ºç°è¯¸å¤šå®ä½“ï¼Œéœ€è¦å°†è¿™äº›å®ä½“ä¸å·²æœ‰çš„çŸ¥è¯†å›¾è°±ä¸­çš„å®ä½“è¿›è¡Œå…³è”</p><h3 id="Deduplication"><a href="#Deduplication" class="headerlink" title="Deduplication"></a>Deduplication</h3><p>ä¸¾ä¸ªä¾‹å­ï¼Œä¸€ä¸ªçŸ¥è¯†å›¾è°±ä¸­å­˜åœ¨çš„å®ä½“å¯èƒ½æ˜¯ç›¸åŒæˆ–è€…å¾ˆç›¸ä¼¼çš„ï¼Œè¿™ä¸ªæ—¶å€™å¯ä»¥å¯¹å…¶è¿›è¡Œèšç±»ï¼Œä½¿å¾—ä¸€ç±»çš„mentionè¡¨ç¤ºåŒä¸€ä¸ªå®ä½“ã€‚</p><h3 id="Record-Linkage"><a href="#Record-Linkage" class="headerlink" title="Record Linkage"></a>Record Linkage</h3><p>ä¸¾ä¸ªä¾‹å­ï¼Œå¯¹å¤šä¸ªä¸åŒçš„çŸ¥è¯†å›¾è°±ä¹‹é—´çš„ç›¸åŒçš„å®ä½“è¿›è¡Œå…³è”ã€‚</p><h2 id="å¦‚ä½•è¿›è¡Œå®ä½“è§£æï¼Ÿ"><a href="#å¦‚ä½•è¿›è¡Œå®ä½“è§£æï¼Ÿ" class="headerlink" title="å¦‚ä½•è¿›è¡Œå®ä½“è§£æï¼Ÿ"></a>å¦‚ä½•è¿›è¡Œå®ä½“è§£æï¼Ÿ</h2><p>Assumption:<br>Each record/mention is associated with a single real world entity.<br>If two records/mentions are identical, then they are true matches.</p><h3 id="Clustering"><a href="#Clustering" class="headerlink" title="Clustering"></a>Clustering</h3><p>ä»ä¸€ç³»åˆ—records/mentionsä¸­è®¡ç®—å®ä½“æ˜¯ä¸€ä¸ªèšç±»é—®é¢˜<br>ER vs (Multi-relational) Clustering</p><ul><li>In typical clustering algorithms (k-means, LDA, etc.) number of clusters is a constant or sublinear in R.</li><li>In ER: number of clusters is linear in R, and average cluster size is a constant. Significant fraction of clusters are singletons.</li></ul><h2 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h2><p>å¯¹ä¸€å¯¹å®ä½“ç¡®å®šåŒ¹é…æˆ–éåŒ¹é…æ˜¯ä¸€ä¸ªåˆ†ç±»é—®é¢˜</p><p>Imbalanced: typically O(R) matches, O(R^2) non-matches</p><h2 id="å®ä½“è§£æç›¸å…³æ¨¡å‹"><a href="#å®ä½“è§£æç›¸å…³æ¨¡å‹" class="headerlink" title="å®ä½“è§£æç›¸å…³æ¨¡å‹"></a>å®ä½“è§£æç›¸å…³æ¨¡å‹</h2><h3 id="Blocking"><a href="#Blocking" class="headerlink" title="Blocking"></a>Blocking</h3><p>ç›®çš„: ä¸ºäº†å‡å°‘åŒ¹é…æ¬¡æ•°<br>Naive pairwise: |R|2 pairwise comparisons<br>example:1000 business listings each from 1,000 different cities across the<br>world =&gt; 1M listings in total =&gt; 1 trillion comparisons<br>If we use Blocking Criterion: City =&gt; 1 billion comparisons</p><p>Problem Statement:<br>Input: Set of records R<br>Output: Set of blocks/canopies</p><p>Variants:<br>Disjoint Blocking<br>Non-disjoint Blocking</p><p>Evalution Metrics:<br>Efficiency  = num of pairs compared / total number of pairs in RxR<br>Recall  = num of true matches compared / num of true matches in RxR<br>Precision = um of true matches compared / num of matches compared<br>Max canopy size: the size of the largest block </p><p>Blockingæ–¹å¼:<br>Blocking predicates (keys), e.g. First three characters of last name, City + State + Zip ;<br>è¯¥æ–¹å¼å­˜åœ¨çš„é—®é¢˜: Using one or more blocking predicates may be insufficient, ä¹Ÿå°±æ˜¯è¯´æ ¹æ®keyæ¥blockingçš„è¯ï¼Œå¾ˆæœ‰å¯èƒ½å‡ºç°ä¸¤ç§ç»“æœï¼Œ1æ˜¯æœ‰äº›keyä¸‹çš„blockè¿˜æ˜¯æœ‰å¾ˆå¤šçš„record, 2æ˜¯NULL values may create large blocks.<br>è§£å†³æ–¹å¼ï¼š Construct blocking predicates by combining simple predicates</p><h3 id="Matching"><a href="#Matching" class="headerlink" title="Matching"></a>Matching</h3><p>Use pairwise predictor to resolve co-referent mentions</p><p>Problem Statement: Given a vector of component-wise similarities for a pair of records (x,y), compute P(x and y match)</p><p>Type I Error =&gt; False Positive<br>Type II Error =&gt; False Negative</p><p>ML Pairwise Approaches:<br>Supervised machine learning algorithms:<br>Decision trees<br>Support vector machines<br>Ensembles of classifiers<br>Conditional Random Fields (CRF)<br>â€¦</p><p>å­˜åœ¨çš„é—®é¢˜:<br>Training set generation<br>Imbalanced classes â€“ many more negatives than positives<br>Misclassification cost</p><h3 id="Validation"><a href="#Validation" class="headerlink" title="Validation"></a>Validation</h3><p>Apply constraints like 1-1 matching, identify canonical form</p><p>Important forms of constraints:<br>â€¢ Exclusivity: If M1 matches with M2, then M3 cannot match with M2<br>â€¢ Transitivity: If M1 and M2 match, M2 and M3 match, then M1 and M3 match<br>â€¢ Functional Dependency: If M1 and M2 match, then M3 and M4 must match</p><h2 id="String-matching-problem"><a href="#String-matching-problem" class="headerlink" title="String matching problem"></a>String matching problem</h2><p>Problem Statement:<br>Given X and Y sets of strings, Find pairs (x, y) such that both x and y refer to the same real world entity</p><h3 id="ä¸ºä»€ä¹ˆå­—ç¬¦ä¸²ä¸èƒ½å®Œç¾åŒ¹é…ï¼Ÿ"><a href="#ä¸ºä»€ä¹ˆå­—ç¬¦ä¸²ä¸èƒ½å®Œç¾åŒ¹é…ï¼Ÿ" class="headerlink" title="ä¸ºä»€ä¹ˆå­—ç¬¦ä¸²ä¸èƒ½å®Œç¾åŒ¹é…ï¼Ÿ"></a>ä¸ºä»€ä¹ˆå­—ç¬¦ä¸²ä¸èƒ½å®Œç¾åŒ¹é…ï¼Ÿ</h3><p>typos, OCR errors, formatting conventions, abbreviations, nick names, word order</p><h3 id="è¯„ä»·å­—ç¬¦ä¸²ç›¸ä¼¼çš„æŒ‡æ ‡"><a href="#è¯„ä»·å­—ç¬¦ä¸²ç›¸ä¼¼çš„æŒ‡æ ‡" class="headerlink" title="è¯„ä»·å­—ç¬¦ä¸²ç›¸ä¼¼çš„æŒ‡æ ‡"></a>è¯„ä»·å­—ç¬¦ä¸²ç›¸ä¼¼çš„æŒ‡æ ‡</h3><h4 id="Sequence-based-Measures"><a href="#Sequence-based-Measures" class="headerlink" title="Sequence based Measures"></a>Sequence based Measures</h4><ul><li>Edit Distance/Levenshtein Distance<br>lev(x, y) is the minimum cost to transform x to y<br>Online calculator: <a href="http://planetcalc.com/1721/">http://planetcalc.com/1721/</a></li></ul><h4 id="Set-Based-Measures"><a href="#Set-Based-Measures" class="headerlink" title="Set-Based Measures"></a>Set-Based Measures</h4><p>æ–¹å¼: Generate set of tokens from the strings and measure similarity between the sets of tokens</p><p>tokenize a string =&gt; â€œdavid smithâ€ 3-grams </p><ul><li>Jaccard Measure</li><li>TF/IDF Measure: distinguishing term should carry more weight</li></ul><h4 id="Hybrid-Measures"><a href="#Hybrid-Measures" class="headerlink" title="Hybrid Measures"></a>Hybrid Measures</h4><p>Do the set-based thing but use a similiarity metric for each element of the set</p><h4 id="Phonetic-Similarity-Measures"><a href="#Phonetic-Similarity-Measures" class="headerlink" title="Phonetic Similarity Measures"></a>Phonetic Similarity Measures</h4>]]></content>
    
    
    
    <tags>
      
      <tag>Knowledge Graph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>çŸ¥è¯†å›¾è°±è¡¨ç¤º</title>
    <link href="/2020/12/01/558kg-rep/"/>
    <url>/2020/12/01/558kg-rep/</url>
    
    <content type="html"><![CDATA[<p>æœ¬ç« å…³æ³¨:<br><img src="/image/semantic_web.png"></p><h2 id="Webä¿¡æ¯è¡¨è¾¾"><a href="#Webä¿¡æ¯è¡¨è¾¾" class="headerlink" title="Webä¿¡æ¯è¡¨è¾¾"></a>Webä¿¡æ¯è¡¨è¾¾</h2><h3 id="ç¼–ç è§„èŒƒ"><a href="#ç¼–ç è§„èŒƒ" class="headerlink" title="ç¼–ç è§„èŒƒ"></a>ç¼–ç è§„èŒƒ</h3><p>Unicode: a computing industry standard for the consistent encoding, representation and handling of text expressed in most of the worldâ€™s writing systems.</p><h3 id="Webèµ„æºåœ°å€"><a href="#Webèµ„æºåœ°å€" class="headerlink" title="Webèµ„æºåœ°å€"></a>Webèµ„æºåœ°å€</h3><p>URL(Uniform Resource Locator):A reference to an Internet resource<br>URL vs URI<br>URI = URL + URN</p><p>ä¸ºä»€ä¹ˆä½¿ç”¨URI?<br>URIs look cool;<br>Precisely identify resources(Avoid confusion among different subjects);<br>Precisely identify properties;<br>Provide information about properties;<br>Look them up on the web</p><h2 id="RDF-Resource-Description-Framework"><a href="#RDF-Resource-Description-Framework" class="headerlink" title="RDF (Resource Description Framework)"></a>RDF (Resource Description Framework)</h2><p>The Resource Description Framework (RDF) is a language for representing information about resources in the World Wide Web</p><p>Intention: Intended for representing metadata about Web resources, such as the title, author, and modification date of a Web documentï¼ˆä¸ºäº†æè¿°webä¸­èµ„æºçš„å…ƒæ•°æ®ä¿¡æ¯ï¼‰<br>=&gt; also be used to represent information about things that can be identified on the Web, even when they cannot be directly retrieved on the Web</p><h3 id="Triples"><a href="#Triples" class="headerlink" title="Triples"></a>Triples</h3><p>Represent Information as Triples, (Subject,Predicate,Object)<br>Subject: The resource being described<br>Predicate: A property of the resource<br>Object: The value of the property</p><p>é€šè¿‡ä¸‰å…ƒç»„çš„å½¢å¼ï¼Œå¾ˆè‡ªç„¶çš„å½¢æˆäº†ä¸€æ¡æœ‰å‘è¾¹çš„è¡¨è¾¾æ–¹å¼ã€‚</p><h3 id="Namespaces"><a href="#Namespaces" class="headerlink" title="Namespaces"></a>Namespaces</h3><p>å‘½åç©ºé—´ï¼Œç”¨äºç®€åŒ–URIçš„ä¹¦å†™ï¼Œå…¶ä¸­å­˜å‚¨äº†ä¸€ç³»åˆ—subjectæˆ–è€…predicateçš„ä¿¡æ¯<br><a href="http://xmlns.com/foaf/0.1/firstName">http://xmlns.com/foaf/0.1/firstName</a> =&gt;  foaf:firstName</p><h3 id="RDF-Syntaxes"><a href="#RDF-Syntaxes" class="headerlink" title="RDF Syntaxes"></a>RDF Syntaxes</h3><p>XML, N3 Turtle, N-Triples, RDFa, JSON-LD</p><h3 id="Represent-nested-structures"><a href="#Represent-nested-structures" class="headerlink" title="Represent nested structures"></a>Represent nested structures</h3><p><code>usc:isi   schema:address  â€œ4676 Admiralty Way, Marina del Rey, CA 90292â€ .</code><br>é—®é¢˜:  In what city is USC/ISI located?</p><p>ä½¿ç”¨åµŒå¥—èŠ‚ç‚¹</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-tag">usc</span><span class="hljs-selector-pseudo">:isi</span> <span class="hljs-selector-tag">schema</span><span class="hljs-selector-pseudo">:address</span> <span class="hljs-selector-tag">usc</span><span class="hljs-selector-pseudo">:isi-address</span> .<br><br><span class="hljs-selector-tag">usc</span><span class="hljs-selector-pseudo">:isi-address</span><br>  <span class="hljs-selector-tag">schema</span><span class="hljs-selector-pseudo">:addressCountry</span> â€œ<span class="hljs-selector-tag">USA</span>â€ ;<br>  <span class="hljs-selector-tag">schema</span><span class="hljs-selector-pseudo">:addressRegion</span> â€œ<span class="hljs-selector-tag">CA</span>â€;<br>  <span class="hljs-selector-tag">schema</span><span class="hljs-selector-pseudo">:addressLocality</span> â€œ<span class="hljs-selector-tag">Marina</span> <span class="hljs-selector-tag">del</span> <span class="hljs-selector-tag">Rey</span>â€ ; <br>  <span class="hljs-selector-tag">schema</span><span class="hljs-selector-pseudo">:postalCode</span> â€œ90292â€ ;<br>  <span class="hljs-selector-tag">schema</span><span class="hljs-selector-pseudo">:streetAddress</span> â€œ4676 <span class="hljs-selector-tag">Admiralty</span> <span class="hljs-selector-tag">Way</span>â€ . <br></code></pre></td></tr></table></figure><p>We minted a URI for USC/ISIâ€™s address, but sometimes we donâ€™t want to mint URIs =&gt; BNode<br>åœ¨è¿™é‡Œå¯ä»¥å‘ç°åµŒå¥—èŠ‚ç‚¹usc:isi-addressä¹Ÿæœ‰å…·ä½“çš„URIæ¥è¡¨ç¤ºï¼Œä½†æ˜¯è¯¥èŠ‚ç‚¹çš„URIæ²¡æœ‰ä»€ä¹ˆå…¶ä»–çš„ä½œç”¨ï¼Œæ‰€ä»¥ä½¿ç”¨ç©ºèŠ‚ç‚¹æ¥è¡¨ç¤º, å‰ç¼€ä¸º_</p><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs css"><span class="hljs-selector-tag">usc</span><span class="hljs-selector-pseudo">:isi</span> <span class="hljs-selector-tag">schema</span><span class="hljs-selector-pseudo">:address</span> _<span class="hljs-selector-pseudo">:isi-address</span> .<br><br>_<span class="hljs-selector-pseudo">:isi-address</span> .<br>  <span class="hljs-selector-tag">schema</span><span class="hljs-selector-pseudo">:addressCountry</span> â€œ<span class="hljs-selector-tag">USA</span>â€ ;<br>  <span class="hljs-selector-tag">schema</span><span class="hljs-selector-pseudo">:addressRegion</span> â€œ<span class="hljs-selector-tag">CA</span>â€;<br>  <span class="hljs-selector-tag">schema</span><span class="hljs-selector-pseudo">:addressLocality</span> â€œ<span class="hljs-selector-tag">Marina</span> <span class="hljs-selector-tag">del</span> <span class="hljs-selector-tag">Rey</span>â€ ; <br>  <span class="hljs-selector-tag">schema</span><span class="hljs-selector-pseudo">:postalCode</span> â€œ90292â€ ;<br>  <span class="hljs-selector-tag">schema</span><span class="hljs-selector-pseudo">:streetAddress</span> â€œ4676 <span class="hljs-selector-tag">Admiralty</span> <span class="hljs-selector-tag">Way</span>â€ . <br></code></pre></td></tr></table></figure><h3 id="å­—é¢å€¼çš„ç±»å‹ï¼ˆTyped-Literalsï¼‰"><a href="#å­—é¢å€¼çš„ç±»å‹ï¼ˆTyped-Literalsï¼‰" class="headerlink" title="å­—é¢å€¼çš„ç±»å‹ï¼ˆTyped Literalsï¼‰"></a>å­—é¢å€¼çš„ç±»å‹ï¼ˆTyped Literalsï¼‰</h3><p>åœ¨objectåé¢æ·»åŠ ç±»å‹ä¿¡æ¯ã€‚<br>example: weather:date â€2012-06-18â€^^xsd:date ;</p><h3 id="Reification"><a href="#Reification" class="headerlink" title="Reification"></a>Reification</h3><p>RDF applications sometimes need to describe other RDF statements using RDF, for instance, to record information about when statements were made, who made them, or other similar information (this is sometimes referred to as â€œprovenanceâ€ information). </p><p>ä¸¾ä¸ªä¾‹å­ï¼š ä»–è¯´äº†xxx<br>â€œOn June 19 2012, Claudia said that Samâ€™s email address is <a href="mailto:&#x53;&#97;&#109;&#x40;&#x67;&#109;&#97;&#105;&#x6c;&#x2e;&#x63;&#111;&#x6d;">&#x53;&#97;&#109;&#x40;&#x67;&#109;&#97;&#105;&#x6c;&#x2e;&#x63;&#111;&#x6d;</a>â€</p><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs groovy"><span class="hljs-attr">_:</span>s <span class="hljs-attr">rdf:</span>type        <span class="hljs-attr">rdf:</span>Statement .<br><span class="hljs-attr">_:</span>s <span class="hljs-attr">rdf:</span>subject     &lt;<span class="hljs-attr">http:</span><span class="hljs-comment">//szekelys.com/family#sam&gt; .    </span><br><span class="hljs-attr">_:</span>s <span class="hljs-attr">rdf:</span>predicate   <span class="hljs-attr">foaf:</span>mbox .<br><span class="hljs-attr">_:</span>s <span class="hljs-attr">rdf:</span>object      &lt;Sam<span class="hljs-meta">@gmail</span>.com&gt;<br><br><span class="hljs-attr">_:</span>s <span class="hljs-attr">dcterms:</span>date     â€œ<span class="hljs-number">2012</span><span class="hljs-number">-06</span><span class="hljs-number">-19</span>â€^^<span class="hljs-attr">xsd:</span>date .<br><span class="hljs-attr">_:</span>s <span class="hljs-attr">dcterms:</span>creator  &lt;<span class="hljs-attr">http:</span><span class="hljs-comment">//uniandes.edu.co/faculty#claudiaj&gt; .</span><br></code></pre></td></tr></table></figure><h3 id="RDF-syntax-in-turtle"><a href="#RDF-syntax-in-turtle" class="headerlink" title="RDF syntax in turtle"></a>RDF syntax in turtle</h3><ul><li><p>URIs are in &lt;&gt;</p></li><li><p>Prefix:<br>  @prefix foo: <a href="http://example.org/ns#">http://example.org/ns#</a> .<br>  @prefix : <a href="http://other.example.org/ns#">http://other.example.org/ns#</a> . &lt;- ç©ºå‘½åç©ºé—´<br>  foo:bar foo: : . ç­‰ä»·äº<br>  <a href="http://example.org/ns#bar">http://example.org/ns#bar</a> <a href="http://example.org/ns">http://example.org/ns</a> <a href="http://other.example.org/ns">http://other.example.org/ns</a>.</p></li><li><p>Turtle Literals</p><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs lasso"><span class="hljs-keyword">Type</span> of literals: <br>  untyped (â€œLondonâ€ equivalent <span class="hljs-keyword">to</span> â€œLondonâ€^^xsd:<span class="hljs-built_in">string</span>)<br>  language <span class="hljs-built_in">tag</span><br>  <span class="hljs-built_in">data</span> <span class="hljs-keyword">type</span> (<span class="hljs-keyword">with</span> a URI)<br>Example:<br>  Strings <span class="hljs-keyword">in</span> â€œâ€<br>  Language <span class="hljs-built_in">tag</span>: <span class="hljs-string">&quot;That Seventies Show&quot;</span>@en<br>  <span class="hljs-built_in">Data</span> <span class="hljs-keyword">type</span>: <span class="hljs-string">&quot;10&quot;</span>^^xsd:<span class="hljs-built_in">decimal</span><br></code></pre></td></tr></table></figure></li><li><p>Blank Node<br>  _:a<br>  []</p></li><li><p>Turtle Base URI ????</p></li><li><p>å¸¸ç”¨ç¼©å†™<br>  rdf:type  = a<br>  â€œ-5â€^^xsd:integer<br>  â€œtrueâ€^^xds:boolean<br>  â€œ1.3e2â€^^xsd:double</p></li></ul><h2 id="RDF-Schema"><a href="#RDF-Schema" class="headerlink" title="RDF Schema"></a>RDF Schema</h2><p>RDF Schema is the language for defining RDF vocabularies.<br>It specifies the RDF inference rules: the triples that are implied by the triples you have.</p><p>å¸¸ç”¨rdfs:<br><img src="/image/rdfs.png"></p><p>All things described by RDF are called resources, and are instances of the class rdfs:Resource</p>]]></content>
    
    
    
    <tags>
      
      <tag>Knowledge Graph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>çŸ¥è¯†å›¾è°±æ•°æ®æå–</title>
    <link href="/2020/12/01/558info-extra/"/>
    <url>/2020/12/01/558info-extra/</url>
    
    <content type="html"><![CDATA[<blockquote><p>NLPæ˜¯æ•°æ®æå–ä¸­ä¸å¯ç¼ºå°‘çš„å…ƒç´ </p></blockquote><h1 id="NLP-åŸºç¡€"><a href="#NLP-åŸºç¡€" class="headerlink" title="NLP åŸºç¡€"></a>NLP åŸºç¡€</h1><p>ä»€ä¹ˆæ˜¯NLPï¼Ÿ<br>Program computers to process and analyze large amounts of natural language data.</p><p>Unstructuredã€Ambiguousã€Lots and lots of data<br>=&gt; Structuredã€Preciseã€Actionable Specific to the task data<br>By  Information Extraction</p><p>ä»€ä¹ˆæ˜¯ä¿¡æ¯æå–ï¼Ÿ<br>Information extraction is the process of extracting information from unstructured textual sources to enable finding entities as well as classifying and storing them. (<a href="https://www.ontotext.com/knowledgehub/fundamentals/information-extraction/">https://www.ontotext.com/knowledgehub/fundamentals/information-extraction/</a>)</p><h2 id="Information-Extraction-æ€»è§ˆ"><a href="#Information-Extraction-æ€»è§ˆ" class="headerlink" title="Information Extraction æ€»è§ˆ"></a>Information Extraction æ€»è§ˆ</h2><p>ä¿¡æ¯æå–çš„ä¸‰ä¸ªé˜¶æ®µï¼š</p><ol><li>ä»sentenceä¸­æå–<ul><li>Part of speech tagging è¯æ€§æ ‡æ³¨</li><li>Dependency Parsing ä¾å­˜åˆ†æ    </li><li>Named entity recognition å‘½åå®ä½“è¯†åˆ«</li></ul></li><li>ä»documentä¸­æå–<ul><li>Coreference Resolution æŒ‡ä»£æ¶ˆè§£</li></ul></li><li>å¤šä¸ªdocumentæå–<ul><li>Entity resolution å®ä½“è§£æ</li><li>Entity linking å®ä½“é“¾æ¥</li><li>Relation extraction å…³ç³»æå–</li></ul></li></ol><h3 id="ä»sentenceè¯´èµ·"><a href="#ä»sentenceè¯´èµ·" class="headerlink" title="ä»sentenceè¯´èµ·"></a>ä»sentenceè¯´èµ·</h3><p>ä¿¡æ¯ä»å¥å­ä¸­æå–ä¹‹å‰ä¹ˆï¼Œé¦–å…ˆéœ€è¦è¿›è¡ŒTokenization &amp; Sentence Splitting<br><img src="/image/token_ss.png"></p><p>å¯¹äºKnowledge Graphé€ æˆçš„å½±å“:</p><ul><li>Strictly constrains other NLP tasks<ul><li>Parts of Speech</li><li>Dependency Parsing</li></ul></li><li>Directly effects KG nodes/edges<ul><li>Mention boundaries</li><li>Relations within sentences</li></ul></li></ul><h4 id="è¯æ€§æ ‡æ³¨-Tagging-Parts-of-Speech"><a href="#è¯æ€§æ ‡æ³¨-Tagging-Parts-of-Speech" class="headerlink" title="è¯æ€§æ ‡æ³¨(Tagging Parts of Speech)"></a>è¯æ€§æ ‡æ³¨(Tagging Parts of Speech)</h4><p><img src="/image/POS.png"></p><p>Context matters.<br>Label whole sentence together.<br>Using Conditional Random Fields, CNN, LSTM to do such task.</p><p>å¯¹äºKnowledge Graphé€ æˆçš„å½±å“:</p><ul><li>Entities appear as nouns</li><li>Verbs are very useful<ul><li>For identifying relations</li><li>For identifying entity types</li></ul></li><li>Important for downstream NLP (NER, Dependency Parsingâ€¦)</li></ul><h4 id="å®ä½“è¯†åˆ«-Detecting-Named-Entities"><a href="#å®ä½“è¯†åˆ«-Detecting-Named-Entities" class="headerlink" title="å®ä½“è¯†åˆ«(Detecting Named Entities)"></a>å®ä½“è¯†åˆ«(Detecting Named Entities)</h4><p><img src="/image/NER.png"></p><p>Context matters.<br>Label whole sentence together</p><p>å¯¹äºKnowledge Graphé€ æˆçš„å½±å“:</p><ul><li>Mentions describes the nodes</li><li>Types of entities are incredibly important(Often restrict relations).</li></ul><h4 id="ä¾å­˜åˆ†æ-Dependency-Parsing"><a href="#ä¾å­˜åˆ†æ-Dependency-Parsing" class="headerlink" title="ä¾å­˜åˆ†æ(Dependency Parsing)"></a>ä¾å­˜åˆ†æ(Dependency Parsing)</h4><p><img src="/image/DEP.png"></p><p>é€šè¿‡ä½¿ç”¨æ¨¡å‹æ¥å¯¹é¢„æµ‹çš„ä¾å­˜å…³ç³»è¿›è¡Œæ‰“åˆ†æ¥é¢„æµ‹ã€‚</p><p>å¯¹äºKnowledge Graphé€ æˆçš„å½±å“:</p><ul><li>Incredibly useful for relations!</li><li>Incredibly useful for attributes!</li><li>Paths are used as surface relations </li></ul><p>Surface relationï¼š ä»…ä»…æ ¹æ®å¥å­çš„ç»“æ„è€Œä¸å€ŸåŠ©è¯­ä¹‰åˆ†ææ¥åˆ¤å®šå…³ç³»æ¨¡å¼<br><img src="/image/DEP_PATH.png"></p><h3 id="ä¸€ä¸ªDocumentä¸­çš„å¤šä¸ªsentence"><a href="#ä¸€ä¸ªDocumentä¸­çš„å¤šä¸ªsentence" class="headerlink" title="ä¸€ä¸ªDocumentä¸­çš„å¤šä¸ªsentence"></a>ä¸€ä¸ªDocumentä¸­çš„å¤šä¸ªsentence</h3><h4 id="æ–‡æ¡£é—´æŒ‡ä»£-Within-document-Coreference"><a href="#æ–‡æ¡£é—´æŒ‡ä»£-Within-document-Coreference" class="headerlink" title="æ–‡æ¡£é—´æŒ‡ä»£(Within-document Coreference)"></a>æ–‡æ¡£é—´æŒ‡ä»£(Within-document Coreference)</h4><p><img src="/image/Correference.png"></p><p>å®ç°æ–¹å¼:<br>Model: score pairwise links, exmaple: dep path, similarity, representative mention â€¦<br>Prediction: Search over clusterings, example: greedy (left to right), ILP,<br>belief propagation, MCMC â€¦</p><p>å¯¹äºKnowledge Graphé€ æˆçš„å½±å“:<br>More context for each entity!<br>Many relations occur on pronouns.<br>Coref can be used for types.<br>Difficult, so often ignored.</p><h3 id="æ–‡æ¡£é—´ã€ä¸åŒæºé—´çš„ä¿¡æ¯æå–"><a href="#æ–‡æ¡£é—´ã€ä¸åŒæºé—´çš„ä¿¡æ¯æå–" class="headerlink" title="æ–‡æ¡£é—´ã€ä¸åŒæºé—´çš„ä¿¡æ¯æå–"></a>æ–‡æ¡£é—´ã€ä¸åŒæºé—´çš„ä¿¡æ¯æå–</h3><p>=&gt; Information Extraction</p><ul><li>Entity resolution å®ä½“è§£æ</li><li>Entity linking å®ä½“é“¾æ¥</li><li>Relation extraction å…³ç³»æå–</li></ul><p><img src="/image/IE.png"></p><h2 id="Information-Extraction-ç»†èŠ‚"><a href="#Information-Extraction-ç»†èŠ‚" class="headerlink" title="Information Extraction ç»†èŠ‚"></a>Information Extraction ç»†èŠ‚</h2><h3 id="è¡¨é¢æ¨¡å¼-Surface-Patterns"><a href="#è¡¨é¢æ¨¡å¼-Surface-Patterns" class="headerlink" title="è¡¨é¢æ¨¡å¼ Surface Patterns"></a>è¡¨é¢æ¨¡å¼ Surface Patterns</h3><p>Combine tokens, dependency paths, and entity types to define rules.<br>ç®€å•çš„è¯´ï¼Œå°±æ˜¯æ ¹æ®å¥å­ã€æ–‡æ¡£çš„è¯­æ³•ç»“æ„æ¥åˆ¤æ–­åˆ†æå‡ºå®ä½“é—´çš„å…³ç³»æ¨¡å¼ï¼Œè€Œå¿½ç•¥äº†å¥å­çš„è¯­ä¹‰ä¿¡æ¯ã€‚</p><h3 id="Rule-Based-Extraction"><a href="#Rule-Based-Extraction" class="headerlink" title="Rule-Based Extraction"></a>Rule-Based Extraction</h3><p>é€šè¿‡äººä¸ºçš„è§„å®šæŸäº›è¯­æ³•æ¨¡å¼ï¼Œæ ¹æ®å¥å­çš„ç»“æ„æ¥ä¿¡æ¯æå–ã€‚</p><p>æ¥æº:<br>Manually specified, Learned from Data</p><p>æ•ˆæœ:<br>High precision: when it fires, itâ€™s correct Easy to explain predictions. Easy to fix mistakes.<br>Poor recall: Do not generalize! Only work when the rules fire </p><h3 id="Supervised-Extraction"><a href="#Supervised-Extraction" class="headerlink" title="Supervised Extraction"></a>Supervised Extraction</h3><p>é€šè¿‡ä½¿ç”¨æœºå™¨å­¦ä¹ ç®—æ³•æ¥è¿›è¡Œä¿¡æ¯çš„æå–</p><p>Machine Learning: hopefully, generalizes the labels in the right way<br>Use all of NLP as features: words, POS, NER, dependencies, embeddings</p><p>ç¼ºé™·:<br>Requires a lot of labeled data is needed, which is expensive &amp; time consuming.<br>Requires a lot of feature engineering!</p><h3 id="Entity-Resolution-amp-Linking"><a href="#Entity-Resolution-amp-Linking" class="headerlink" title="Entity Resolution &amp; Linking"></a>Entity Resolution &amp; Linking</h3><p>å‘½åå®ä½“å­˜åœ¨çš„é—®é¢˜:</p><ol><li>Different Entities with Same Name</li><li>Different Names for same Entities</li></ol><p>ä¸€èˆ¬æ­¥éª¤ï¼š<br>Candidate Generation =&gt; Entity Types =&gt; Coreference =&gt; Coherence</p><h2 id="Information-Extraction-ä¸‰ä¸ªå­é—®é¢˜åŠè§£å†³æ–¹å¼"><a href="#Information-Extraction-ä¸‰ä¸ªå­é—®é¢˜åŠè§£å†³æ–¹å¼" class="headerlink" title="Information Extraction ä¸‰ä¸ªå­é—®é¢˜åŠè§£å†³æ–¹å¼"></a>Information Extraction ä¸‰ä¸ªå­é—®é¢˜åŠè§£å†³æ–¹å¼</h2><p>3*3 = 9</p><p><img src="/image/IEpro.png"></p><h3 id="Defining-Domain"><a href="#Defining-Domain" class="headerlink" title="Defining Domain"></a>Defining Domain</h3><h4 id="Manual"><a href="#Manual" class="headerlink" title="Manual"></a>Manual</h4><p>Highly semantic ontology;<br>Leads to high precision extraction;<br>Expensive to create;<br>Requires domain experts;</p><h4 id="Semi-automatic"><a href="#Semi-automatic" class="headerlink" title="Semi-automatic"></a>Semi-automatic</h4><p>Subset of types are manually defined;<br>SSL methods discover new types from unlabeled data;</p><p>Easier to derive types using existing resources;<br>Relations are discovered from the corpus;<br>Leads to moderate precision extractions;<br>Partially semantic ontology;</p><p>Example:<br>Assumption:<br>Types and type hierarchy is manually defined (E.g. River, City, Food, Chemical, Disease, Bacteria);<br>Relations are automatically discovered using clustering methods</p><h4 id="Automatic"><a href="#Automatic" class="headerlink" title="Automatic"></a>Automatic</h4><p>Any noun phrase is a candidate entity<br>Any verb phrase is a candidate relation</p><p>Cheapest way to induce types/ relations from corpus;<br>Little expert annotations needed;<br>Limited semantics;<br>Leads to noisy extractions;</p><h3 id="Learning-extractors"><a href="#Learning-extractors" class="headerlink" title="Learning extractors"></a>Learning extractors</h3><h4 id="Manual-1"><a href="#Manual-1" class="headerlink" title="Manual"></a>Manual</h4><p>Human defined high-precision extraction patterns for each relation</p><h4 id="Semi-supervised"><a href="#Semi-supervised" class="headerlink" title="Semi-supervised"></a>Semi-supervised</h4><p>Bootstrapping</p><p><img src="/image/semi-sup.png"><br>ç®€å•çš„è¯´å°±æ˜¯ï¼Œäººä¸ºç»™ä¸€äº›seed instancesç»™æœºå™¨ï¼Œè®©æœºå™¨å»æå–ç¬¦åˆè¿™äº›instanceçš„patternï¼Œç„¶åæ ¹æ®æå–åˆ°çš„patternå»æå–ç¬¦åˆçš„instanceï¼Œé‡å¤æ“ä½œï¼Œè·å–è¶Šæ¥è¶Šå¤šçš„instanceå’Œpattern.</p><p>ç¼ºé™·:Semantic Drift, è¯­ä¹‰æ¼‚ç§»<br>è§£å†³æ–¹å¼: topk, interactive<br><img src="/image/LE-semi.png"></p><h4 id="Unsupervised"><a href="#Unsupervised" class="headerlink" title="Unsupervised"></a>Unsupervised</h4><p>Identify candidate relations: ä¸ºæ¯ä¸ªåŠ¨è¯æ‰¾åˆ°æœ€é•¿çš„å•è¯åºåˆ—<br>Identify arguments for each relation: å¯¹äºæ¯ä¸ªå…³ç³»ï¼Œæ‰¾å…¶å·¦ä¾§å’Œå³ä¾§æ‰¾åˆ°æœ€æ¥è¿‘çš„åè¯çŸ­è¯­</p><h3 id="Scoring-candidate-facts"><a href="#Scoring-candidate-facts" class="headerlink" title="Scoring candidate facts"></a>Scoring candidate facts</h3><h4 id="Manual-2"><a href="#Manual-2" class="headerlink" title="Manual"></a>Manual</h4><p>Human defined scoring function or Scoring function learnt using supervised ML with large amount of training data</p><h4 id="Semi-supervised-1"><a href="#Semi-supervised-1" class="headerlink" title="Semi-supervised"></a>Semi-supervised</h4><p>Small amount of training data is available. Scoring refined over multiple iterations<br>Using both labeled and unlabeled data</p><h4 id="Unsupervised-1"><a href="#Unsupervised-1" class="headerlink" title="Unsupervised"></a>Unsupervised</h4><p>Confidence(extraction pattern) âˆ (#unique instances it could extract)<br>Score(candidate fact) âˆ (#distinct extraction patterns that support it)</p><h2 id="Information-Extraction-æŠ€æœ¯ç±»åˆ«"><a href="#Information-Extraction-æŠ€æœ¯ç±»åˆ«" class="headerlink" title="Information Extraction æŠ€æœ¯ç±»åˆ«"></a>Information Extraction æŠ€æœ¯ç±»åˆ«</h2><h3 id="Narrow-domain-patterns"><a href="#Narrow-domain-patterns" class="headerlink" title="Narrow domain patterns"></a>Narrow domain patterns</h3><p>Defining domain: Manual<br>Learning extractors:  Manual<br>Scoring candidate facts: Manual</p><h3 id="Ontology-based-extraction"><a href="#Ontology-based-extraction" class="headerlink" title="Ontology based extraction"></a>Ontology based extraction</h3><p>Defining domain: Manual<br>Learning extractors:  Semi-supervised<br>Scoring candidate facts: Unsupervised</p><h3 id="Interactive-extraction"><a href="#Interactive-extraction" class="headerlink" title="Interactive extraction"></a>Interactive extraction</h3><p>Defining domain: Manual<br>Learning extractors:  Semi-supervised<br>Scoring candidate facts: Semi-supervised</p><h3 id="Open-domain-IE"><a href="#Open-domain-IE" class="headerlink" title="Open domain IE"></a>Open domain IE</h3><p>Defining domain: Unsupervised<br>Learning extractors:  Unsupervised<br>Scoring candidate facts: Semi-supervised</p><h3 id="Hybrid-approach-Adding-structure-to-OpenIE-KB"><a href="#Hybrid-approach-Adding-structure-to-OpenIE-KB" class="headerlink" title="Hybrid approach (Adding structure to OpenIE KB)"></a>Hybrid approach (Adding structure to OpenIE KB)</h3><p>Defining domain: Semi-supervised =&gt; Distant supervision to add structure<br>Learning extractors:  Unsupervised<br>Scoring candidate facts: Semi-supervised</p><h2 id="Knowledge-fusion"><a href="#Knowledge-fusion" class="headerlink" title="Knowledge fusion"></a>Knowledge fusion</h2><p>èåˆå¤šç§Learning extractorsæ¥æé«˜æå–å‡†ç¡®åº¦</p><p>Knowledge fusion schemes:</p><ul><li>Voting (AND vs OR of extractors)</li><li>Co-training (multiple extraction methods)</li><li>Multi-view learning (multiple data sources)</li><li>Classification</li></ul><h2 id="IE-systems-in-practice"><a href="#IE-systems-in-practice" class="headerlink" title="IE systems in practice"></a>IE systems in practice</h2><ul><li>Conceptnet</li><li>NELL (Never Ending Language Learning )</li><li>Knowledge vault</li><li>Open IE</li></ul><p><img src="/image/IE_sys.png"></p>]]></content>
    
    
    
    <tags>
      
      <tag>Knowledge Graph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>çŸ¥è¯†å›¾è°±æ•°æ®è·å–ä¸çŸ¥è¯†äº§æƒ</title>
    <link href="/2020/12/01/558data-acq/"/>
    <url>/2020/12/01/558data-acq/</url>
    
    <content type="html"><![CDATA[<blockquote><p>Tim Berners-Lee published the first-ever website in August 6, 1991<br>Knowledge Graphçš„æ•°æ®å¤§éƒ¨åˆ†æ¥æºäºWeb</p></blockquote><h1 id="WebåŸºæœ¬ä¿¡æ¯"><a href="#WebåŸºæœ¬ä¿¡æ¯" class="headerlink" title="WebåŸºæœ¬ä¿¡æ¯"></a>WebåŸºæœ¬ä¿¡æ¯</h1><h2 id="Webç»“æ„"><a href="#Webç»“æ„" class="headerlink" title="Webç»“æ„"></a>Webç»“æ„</h2><ul><li>Surface Web: Pages reachable by following links from static pages ï¼ˆè¡¨å±‚ç½‘ç»œï¼Œå¯ä»¥ç›´æ¥åœ¨ä¸‡ç»´ç½‘æµè§ˆçš„å†…å®¹ï¼‰</li><li>Deep Web: Pages reachable only via web forms ï¼ˆä¸èƒ½è¢«wwwç›´æ¥è®¿é—®åˆ°ï¼Œéœ€è¦è´¦å·å¯†ç ï¼Œè®¿é—®æƒé™ç­‰æ‰èƒ½è¿›å…¥ï¼Œä¾‹å¦‚é‚®ç®±ã€æ•°æ®åº“ï¼‰</li><li>Dark Web: Pages reachable only via Tor or equivalent ï¼ˆé€šè¿‡ç‰¹å®šçš„æµè§ˆå™¨ã€ç‰¹æ®Šæˆæƒæˆ–è€…ç‰¹æ®Šè®¾ç½®æ‰èƒ½é“¾æ¥ä¸Šçš„ç½‘ç»œï¼‰</li></ul><p><img src="/image/web_struc.jpg"></p><h2 id="Webçš„Bowtieæ¨¡å‹"><a href="#Webçš„Bowtieæ¨¡å‹" class="headerlink" title="Webçš„Bowtieæ¨¡å‹"></a>Webçš„Bowtieæ¨¡å‹</h2><p>Strongly Connected Component â€“ 27.5%<br>IN and OUT â€“ 21.5%<br>Tendrils and tubes â€“ 21.5%<br>Disconnected â€“ 8%</p><p><img src="/image/bowtie.png"></p><h2 id="Web-æ•°æ®è·å–é€”å¾„-Crawler"><a href="#Web-æ•°æ®è·å–é€”å¾„-Crawler" class="headerlink" title="Web æ•°æ®è·å–é€”å¾„ - Crawler"></a>Web æ•°æ®è·å–é€”å¾„ - Crawler</h2><p>Web Crawlerå®šä¹‰: Software that automatically browses the web and downloads content<br>Crawler ç”¨é€”: Building search engines, Study the web/internet, Archive the web, Analyze web sites, <u><b>Download content(çŸ¥è¯†å›¾è°±æ•°æ®è·å–)</b></u><br>Crawler åŸºæœ¬æ¡†æ¶: è°ƒåº¦å™¨è°ƒåº¦çˆ¬å–é¡µé¢ï¼Œä¸‹è½½å™¨å¤šçº¿ç¨‹ä¸‹è½½ã€‚<br><img src="/image/crawler_stru.png"><br>Queue: one per web site<br>Scheduler: breath first or depth first ?<br>Multithreaded Downloader: take Politeness and Latency into account<br>After download: Parse -&gt; Extract Content -&gt; Extract URLs -&gt;Add To Queue</p><p>Crawlerå¸¸ç”¨å·¥å…·ï¼šScrapy, bs4, import.io parsehub<br>Crawler æŒ‘æˆ˜: scaleã€deduplicationã€costã€errorã€freshnessã€counter-crawling/access â€¦<br>Crawler è¦æ±‚: robustnessã€ politenessã€robots.txt</p><h1 id="Webä¸‹çš„çŸ¥è¯†äº§æƒ-Intellectual-Property"><a href="#Webä¸‹çš„çŸ¥è¯†äº§æƒ-Intellectual-Property" class="headerlink" title="Webä¸‹çš„çŸ¥è¯†äº§æƒ(Intellectual Property)"></a>Webä¸‹çš„çŸ¥è¯†äº§æƒ(Intellectual Property)</h1><p>Intellectual property (IP) is an intangible creative work. It is not the physical form on which it is stored or delivered. IP can be protected through the use of patents, copyrights, trademarks, and trade secret laws.</p><h2 id="ä¸“åˆ©-Patents"><a href="#ä¸“åˆ©-Patents" class="headerlink" title="ä¸“åˆ©(Patents)"></a>ä¸“åˆ©(Patents)</h2><p>PATENTS provide rights for up to 20 years for inventions in three broad categories:  </p><ol><li><p>Utility patents: protect useful processes, machines, articles of manufacture, and compositions of matter (å®ç”¨ä¸“åˆ©)</p></li><li><p>Design patents guard the unauthorized use of new, original, and ornamental designs for articles of manufacture (è®¾è®¡ä¸“åˆ©)</p></li><li><p>Plant patents are the way we protect invented or discovered, asexually reproduced plant varieties (æ¤ç‰©ä¸“åˆ©)</p></li></ol><h2 id="ç‰ˆæƒ-Copyrights"><a href="#ç‰ˆæƒ-Copyrights" class="headerlink" title="ç‰ˆæƒ(Copyrights)"></a>ç‰ˆæƒ(Copyrights)</h2><p>COPYRIGHTS protect works of authorship, such as writings, music, and works of art that have been tangibly expressed. ï¼ˆæ–‡å­¦é¢†åŸŸï¼Œç‰ˆæƒä¹Ÿç§°ä¸ºè‘—ä½œæƒï¼‰<br>The Library of Congress registers copyrights which last the life of the author plus 70 years. ï¼ˆå»ä¸–å‰+70å¹´ï¼‰<br>Books, albums, movies are all copyrighted.<br>You cannot copyright facts, such as the information in the telephone book. But you can copyright the particular presentation of those facts</p><p>ç‰ˆæƒæ‹¥æœ‰è€…æ‰€æ‹¥æœ‰çš„æƒåˆ©:<br>Make copies of the work;<br>Produce derivative works;<br>Distribute copies;<br>Perform the work in public;<br>Display the work in public;<br>è¿™ä¹Ÿå°±æ„å‘³ç€ï¼Œéç‰ˆæƒæ‹¥æœ‰è€…ä¸èƒ½å¤Ÿäº«æœ‰è¿™äº›æƒåˆ©ã€‚ =&gt; éœ€è¦ç»è¿‡è®¸å¯</p><p>åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œä¸éœ€è¦è®¸å¯ä½¿ç”¨ä½œå“:<br>åˆç†ä½¿ç”¨éœ€è¦è€ƒè™‘çš„å› ç´ : purpose and character of the work, nature of the copyrighted work, amount and substantiality of the portion used in relation to the copyrighted work, effect on the potential market for or value of the copyrighted work<br>ä»¥ä¸‹æƒ…å†µå¯ä»¥ä¸éœ€è¦ç»è¿‡ç‰ˆæƒè®¸å¯ï¼š<br>Use of copyrighted material that contribute to the creation of new work(The new works cannot significantly affect sales of the source material, thus depriving copyright holders of their income)ï¼›<br>Use for some research and educational purposes;<br>Use for news reporting and critiquing;</p><p>ä¸å—ç‰ˆæƒæ³•ä¿æŠ¤çš„ä½œå“ç±»å‹:<br>Works in the public domain are not covered by IP rights;<br>Ideas (e.g., mathematical formulas);<br>Works pre-dating copyright law (e.g., Bible);<br>Expired copyright;<br>Government works;<br>Traditional knowledge, folklore.</p><p>çŸ¥è¯†å…±äº«(Creative Commons (CC))<br>Attribution<br>Noncommercial<br>No Derivative Works<br>ShareAlike</p><h2 id="å•†æ ‡-Trademarks"><a href="#å•†æ ‡-Trademarks" class="headerlink" title="å•†æ ‡(Trademarks)"></a>å•†æ ‡(Trademarks)</h2><p>TRADEMARKS protect words, names, symbols, sounds, or colors that distinguish goods and services from other manufacturerâ€™s products (å•†å“ç¬¦å·)<br>Trademarks, unlike patents, can be renewed forever as long as they are being used in business. (æ— é™æœŸ)<br>No Fair-Use provision in Trademark law</p><p>å•†æ ‡ç§ç±»:<br>â„¢ : unregistered trade mark used to promote or brand goods<br>â„  : unregistered service mark used to promote or brand services<br>Â® : registered trademark</p><h2 id="å•†ä¸šç§˜å¯†-Trade-Secrets"><a href="#å•†ä¸šç§˜å¯†-Trade-Secrets" class="headerlink" title="å•†ä¸šç§˜å¯†(Trade Secrets)"></a>å•†ä¸šç§˜å¯†(Trade Secrets)</h2><p>TRADE SECRETS are information that companies keep secret to give them an advantage over their competitors. example: formula for Coca-Cola<br>Gives owner perpetual monopoly on secret information (æ— é™æœŸ)</p><h2 id="æ•°æ®æ±‡æ€»-Data-Aggregation"><a href="#æ•°æ®æ±‡æ€»-Data-Aggregation" class="headerlink" title="æ•°æ®æ±‡æ€»(Data Aggregation)"></a>æ•°æ®æ±‡æ€»(Data Aggregation)</h2><p>Data aggregation, aka â€œscreen scrapingâ€ or â€œwrappingâ€ is conducted widely today<br>Some of it is on sound legal ground;<br>But some it is has more ambiguous legal standing</p><h2 id="è½¯ä»¶è®¸å¯è¯-Software-Licenses"><a href="#è½¯ä»¶è®¸å¯è¯-Software-Licenses" class="headerlink" title="è½¯ä»¶è®¸å¯è¯(Software Licenses)"></a>è½¯ä»¶è®¸å¯è¯(Software Licenses)</h2><p>Copyleft licenses<br>Permissive licenses</p>]]></content>
    
    
    
    <tags>
      
      <tag>Knowledge Graph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>çŸ¥è¯†å›¾è°±ç®€ä»‹</title>
    <link href="/2020/12/01/558intro/"/>
    <url>/2020/12/01/558intro/</url>
    
    <content type="html"><![CDATA[<h2 id="ä»€ä¹ˆæ˜¯çŸ¥è¯†å›¾è°±ï¼Ÿ"><a href="#ä»€ä¹ˆæ˜¯çŸ¥è¯†å›¾è°±ï¼Ÿ" class="headerlink" title="ä»€ä¹ˆæ˜¯çŸ¥è¯†å›¾è°±ï¼Ÿ"></a>ä»€ä¹ˆæ˜¯çŸ¥è¯†å›¾è°±ï¼Ÿ</h2><ul><li>Knowledge in graph form!</li><li>Captures entities, attributes, and relationships</li><li>Nodes are entities</li><li>Nodes are labeled with attributes (e.g., types)</li><li>Typed edges between two nodes capture a relationship between entities</li></ul><p><img src="/image/kg_overview.png"></p><p>ç®€å•çš„è¯´ï¼ŒçŸ¥è¯†å›¾è°±å°±æ˜¯ä¸€å¼ å›¾ï¼Œç”¨æ¥æè¿°èŠ‚ç‚¹ä¹‹é—´çš„å…³ç³»ã€‚</p><h2 id="çŸ¥è¯†å›¾è°±çš„æ¥æºï¼Ÿ"><a href="#çŸ¥è¯†å›¾è°±çš„æ¥æºï¼Ÿ" class="headerlink" title="çŸ¥è¯†å›¾è°±çš„æ¥æºï¼Ÿ"></a>çŸ¥è¯†å›¾è°±çš„æ¥æºï¼Ÿ</h2><ul><li>Structured Text (Wikipedia Infoboxes, tables, databases, social nets)</li><li>Unstructured Text (WWW, news, social media, reference articles)</li><li>Images</li><li>Video (YouTube, video feeds)</li></ul><h2 id="çŸ¥è¯†å›¾è°±å¦‚ä½•è¢«ä½¿ç”¨ï¼Ÿ"><a href="#çŸ¥è¯†å›¾è°±å¦‚ä½•è¢«ä½¿ç”¨ï¼Ÿ" class="headerlink" title="çŸ¥è¯†å›¾è°±å¦‚ä½•è¢«ä½¿ç”¨ï¼Ÿ"></a>çŸ¥è¯†å›¾è°±å¦‚ä½•è¢«ä½¿ç”¨ï¼Ÿ</h2><p>Human perspective:</p><ul><li>Combat information overload</li><li>Explore via intuitive structure</li><li>Tool for supporting knowledge-driven tasks</li></ul><p>AI perspective:</p><ul><li>Key ingredient for many AI tasks</li><li>Bridge from data to human semantics</li><li>Use decades of work on graph analysis</li></ul><p>å¸¸è§çš„åº”ç”¨:</p><ul><li>QA/Agents</li><li>Decision Support</li><li>Fueling Discovery</li></ul><p>å·¥ä¸šç•Œçš„ä½¿ç”¨åŒ…æ‹¬: Google Knowledge Graph(Google Knowledge Vault), Amazon Product Graph, Facebook Graph API, IBM Watson, Microsoft Satori, LinkedIn Knowledge Graph, Yandex Object Answer, Diffbot, GraphIQ, Maana, ParseHub, Reactor Labs, SpazioDati</p><h2 id="å…¸å‹çš„çŸ¥è¯†å›¾è°±æ¶æ„ï¼Ÿ"><a href="#å…¸å‹çš„çŸ¥è¯†å›¾è°±æ¶æ„ï¼Ÿ" class="headerlink" title="å…¸å‹çš„çŸ¥è¯†å›¾è°±æ¶æ„ï¼Ÿ"></a>å…¸å‹çš„çŸ¥è¯†å›¾è°±æ¶æ„ï¼Ÿ</h2><p>åŸºæœ¬æµç¨‹å¦‚ä¸‹ï¼š</p><ol><li>æ•°æ®è·å–</li><li>ä¿¡æ¯æå–</li><li>æœ¬ä½“æ˜ å°„</li><li>å®ä½“è§£æ</li><li>çŸ¥è¯†å›¾è°±çš„éƒ¨ç½²</li><li>å›¾è°±å…·ä½“åº”ç”¨</li></ol><p><img src="/image/kg_arc.png"></p>]]></content>
    
    
    
    <tags>
      
      <tag>Knowledge Graph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>å‘½ä»¤è¡Œå¤‡å¿˜å½•</title>
    <link href="/2020/12/01/Command-Lib/"/>
    <url>/2020/12/01/Command-Lib/</url>
    
    <content type="html"><![CDATA[<h2 id="1-hexo"><a href="#1-hexo" class="headerlink" title="1. hexo"></a>1. hexo</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">$ hexo new <span class="hljs-string">&#x27;post&#x27;</span> <span class="hljs-comment"># Create a new post</span><br>$ hexo g  <span class="hljs-comment"># Generate static files  </span><br>$ hexo s  <span class="hljs-comment"># Run server</span><br>$ hexo d  <span class="hljs-comment"># Deploy to remote sites</span><br>$ hexo clean <span class="hljs-comment"># Remove cache file (db.json) and static files (public)</span><br></code></pre></td></tr></table></figure><h2 id="2-Conda"><a href="#2-Conda" class="headerlink" title="2. Conda"></a>2. Conda</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">$ conda create -n env_name python=<span class="hljs-number">3.6</span>   <span class="hljs-comment"># åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ</span><br>$ conda activate env_name   <span class="hljs-comment"># æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ</span><br>$ conda deactivate env_name <span class="hljs-comment"># é€€å‡ºè™šæ‹Ÿç¯å¢ƒ</span><br>$ conda env list <span class="hljs-comment"># æŸ¥çœ‹condaç¯å¢ƒ</span><br><br><span class="hljs-comment"># å…³äºåˆ‡æ¢jupyterä¸­æœåŠ¡å†…æ ¸(åœ¨jupyter notebookä¸­ä½¿ç”¨ä¸åŒçš„ç¯å¢ƒ)</span><br><span class="hljs-number">1.</span> $ conda activate env_name <br><span class="hljs-number">2.</span> $ conda install ipykernel<br><span class="hljs-number">3.</span> $ python -m ipykernel install --name env_name<br><span class="hljs-number">4.</span> $ jupyter notebook  æ–°å»ºpython,å‡ºç°å¯¹åº”ç¯å¢ƒæç¤º<br><br><span class="hljs-comment"># ä¿®æ”¹ç¯å¢ƒåç§°ï¼ˆæ— æ³•ä¿®æ”¹ï¼Œåªèƒ½å¤åˆ¶+åˆ é™¤ï¼‰</span><br><span class="hljs-number">1.</span> $ conda create -n new_env --clone old_env<br><span class="hljs-number">2.</span> $ conda remove -n old_env --all<br><br></code></pre></td></tr></table></figure><h2 id="3-Linux"><a href="#3-Linux" class="headerlink" title="3. Linux"></a>3. Linux</h2><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-variable">$</span> du <span class="hljs-literal">-h</span> -<span class="hljs-literal">-max</span><span class="hljs-literal">-depth</span>=<span class="hljs-number">1</span>  <span class="hljs-built_in">dir</span><span class="hljs-literal">-name</span> <span class="hljs-comment"># æŸ¥çœ‹æ–‡ä»¶å¤¹å¤§å°</span><br><span class="hljs-variable">$</span> du <span class="hljs-literal">-sh</span> * <span class="hljs-comment">#æŸ¥çœ‹å½“å‰æ–‡ä»¶ä»¥åŠæ–‡ä»¶å¤¹çš„å¤§å°</span><br><span class="hljs-variable">$</span> htop  <span class="hljs-comment"># æŸ¥çœ‹ç³»ç»Ÿcpuã€memä½¿ç”¨æƒ…å†µ </span><br><span class="hljs-variable">$</span> htop <span class="hljs-literal">-u</span> username <span class="hljs-comment">#æŸ¥çœ‹æŸä¸ªç”¨æˆ·çš„è¿›ç¨‹ä½¿ç”¨</span><br><span class="hljs-variable">$</span> cpulimit <span class="hljs-literal">-l</span> <span class="hljs-number">50</span> <span class="hljs-literal">-p</span> pid <span class="hljs-comment">#é™åˆ¶æŸä¸ªè¿›ç¨‹çš„cpuä½¿ç”¨ç‡ä¸º50%</span><br><span class="hljs-variable">$</span> rclone <span class="hljs-comment"># æœ¬åœ°æ–‡ä»¶ä¸google driveè¿æ¥çš„æ¡¥æ¢</span><br><br><span class="hljs-variable">$</span> <span class="hljs-built_in">ls</span> <span class="hljs-literal">-l</span> | grep <span class="hljs-string">&quot;^-&quot;</span> | wc <span class="hljs-literal">-l</span>   <span class="hljs-comment"># ç»Ÿè®¡å½“å‰æ–‡ä»¶å¤¹ä¸‹æ–‡ä»¶çš„ä¸ªæ•°ï¼ˆä¸åŒ…æ‹¬ç›®å½•ï¼‰</span><br><span class="hljs-variable">$</span> <span class="hljs-built_in">ls</span> <span class="hljs-literal">-lR</span>| grep <span class="hljs-string">&quot;^-&quot;</span> | wc <span class="hljs-literal">-l</span>   <span class="hljs-comment"># ç»Ÿè®¡å½“å‰ç›®å½•ä¸‹æ–‡ä»¶çš„ä¸ªæ•°ï¼ˆåŒ…æ‹¬å­ç›®å½•ï¼‰</span><br><span class="hljs-variable">$</span> <span class="hljs-built_in">ls</span> <span class="hljs-literal">-lR</span>| grep <span class="hljs-string">&quot;^-&quot;</span> | wc <span class="hljs-literal">-l</span>   <span class="hljs-comment"># ç»Ÿè®¡å½“å‰ç›®å½•ä¸‹ç›®å½•çš„ä¸ªæ•°ï¼ˆåŒ…æ‹¬å­ç›®å½•ï¼‰</span><br><br><span class="hljs-variable">$</span> gzip â€“c filename &gt; filename.gz  <span class="hljs-comment"># å‹ç¼©æ–‡ä»¶æˆgzæ–‡ä»¶ï¼ˆä¿ç•™åŸæ–‡ä»¶ï¼‰</span><br><span class="hljs-variable">$</span> gunzip â€“c filename.gz &gt; filename  <span class="hljs-comment"># è§£å‹gzæ–‡ä»¶ï¼ˆä¿ç•™gzæ–‡ä»¶ï¼‰</span><br><br><span class="hljs-variable">$</span> head <span class="hljs-literal">-n</span> <span class="hljs-number">10</span> filename  <span class="hljs-comment"># æŸ¥çœ‹æ–‡ä»¶å‰åè¡Œå†…å®¹</span><br><span class="hljs-variable">$</span> tail <span class="hljs-literal">-n</span> <span class="hljs-number">10</span> filename  <span class="hljs-comment"># æŸ¥çœ‹æ–‡ä»¶ååè¡Œå†…å®¹</span><br></code></pre></td></tr></table></figure><h2 id="4-CPUä¿¡æ¯"><a href="#4-CPUä¿¡æ¯" class="headerlink" title="4. CPUä¿¡æ¯"></a>4. CPUä¿¡æ¯</h2><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs powershell">Mac:<br><span class="hljs-variable">$</span> sysctl machdep.cpu <span class="hljs-comment">#æ‰€æœ‰ä¿¡æ¯</span><br><span class="hljs-variable">$</span> sysctl <span class="hljs-literal">-n</span> machdep.cpu.brand_string    <span class="hljs-comment"># CPUå‹å·</span><br><span class="hljs-variable">$</span> sysctl <span class="hljs-literal">-n</span> machdep.cpu.core_count      <span class="hljs-comment"># CPUæ ¸å¿ƒæ•°</span><br><span class="hljs-variable">$</span> sysctl <span class="hljs-literal">-n</span> machdep.cpu.thread_count    <span class="hljs-comment"># çº¿ç¨‹æ•°</span><br><br>Linux<br><span class="hljs-variable">$</span> grep <span class="hljs-string">&#x27;physical id&#x27;</span> /proc/cpuinfo | <span class="hljs-built_in">sort</span> <span class="hljs-literal">-u</span>  <span class="hljs-comment"># æŸ¥çœ‹ç‰©ç†cpuä¸ªæ•°</span><br><span class="hljs-variable">$</span> grep <span class="hljs-string">&#x27;core id&#x27;</span> /proc/cpuinfo | <span class="hljs-built_in">sort</span> <span class="hljs-literal">-u</span> | wc <span class="hljs-literal">-l</span>  <span class="hljs-comment"># æ ¸å¿ƒæ•°é‡</span><br><span class="hljs-variable">$</span> grep <span class="hljs-string">&#x27;processor&#x27;</span> /proc/cpuinfo | <span class="hljs-built_in">sort</span> <span class="hljs-literal">-u</span> | wc <span class="hljs-literal">-l</span>  <span class="hljs-comment"># çº¿ç¨‹æ•°</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Commands</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>æ•°æ®æŒ–æ˜, MapReduce ä»‹ç»</title>
    <link href="/2020/11/10/553week1/"/>
    <url>/2020/11/10/553week1/</url>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h2 id="Terms"><a href="#Terms" class="headerlink" title="Terms"></a>Terms</h2><ul><li><p>Data mining: Discover patterns and models that are:</p><ul><li>Valid:  hold on new data with some certainty</li><li>Useful:  should be possible to act on the item </li><li>Unexpected:  non-obvious to the system</li><li>Understandable: humans should be able to interpret the pattern</li></ul></li><li><p>DIKW Pyramid: Data, Information, Knowledge and wisdom<br>  <img src="/image/DIKW.png"></p></li><li><p>Data mining task: </p><ul><li>Descriptive Models: Find human-interpretable patterns that describe the data</li><li>Predictive Models: Use some variables to predict unknown or future values of other variables</li></ul></li><li><p>Data science pipeline<br><img src="/image/ds_pro.png"></p></li><li><p>Bonferroniâ€™s principle:(roughly) if you look in more places for interesting patterns than your amount of data will support, you are bound to find crap.(æ•°æ®æ”¯æ’‘çš„å‰ææ˜¯æ•°æ®) </p></li></ul><h2 id="Descriptive-Models"><a href="#Descriptive-Models" class="headerlink" title="Descriptive Models"></a>Descriptive Models</h2><p>Often, especially for ML-type algorithms, the result is a model = a simple representation of the data, typically used for prediction.<br>example: PageRank : representing the â€œimportanceâ€ of the page.</p><h2 id="Predictive-Models"><a href="#Predictive-Models" class="headerlink" title="Predictive Models"></a>Predictive Models</h2><p>In many applications, all we want is an algorithm that will say â€œyesâ€ or â€œnoâ€<br>example: spam email detection</p><h2 id="Thing-will-be-convered"><a href="#Thing-will-be-convered" class="headerlink" title="Thing will be convered"></a>Thing will be convered</h2><p>Data: high dimensionalï½œgraphï½œinfinite/never-ending ï½œ labeled<br>Model: MapReduce ï½œStreams and online algorithms ï½œSingle machine in-memory<br>Real-world problems:  Recommender systems| Market Basket Analysis| Spam detection| Duplicate document detection<br>Theory:</p><ul><li>Linear algebra (SVD, Rec. Sys., Communities)</li><li>Optimization (stochastic gradient descent)</li><li>Dynamic programming (frequent itemsets)</li><li>Hashing (LSH, Bloom filters)</li></ul><p><img src="/image/553overview.png"></p><h2 id="Bonferroniâ€™s-Principle"><a href="#Bonferroniâ€™s-Principle" class="headerlink" title="Bonferroniâ€™s Principle"></a>Bonferroniâ€™s Principle</h2><p>an informal presentation of a statistical theorem:</p><ul><li>that states if your method of finding significant items returns significantly more items that you would expect in the actual population, </li><li>you can assume most of the items you find with it are bogus.</li></ul><p>ç®€å•çš„è¯´å°±æ˜¯FPè¿‡å¤šï¼Œè¯¯è¯Šç‡å¤ªé«˜ã€‚</p><p>example:</p><ol><li>Rhineâ€™s Paradox(è±èŒµæ‚–è®º), çŒœå¡ç‰‡çº¢è“</li><li>Total Information Awareness (TIA)ï¼Œæ ¹æ®ä¿¡æ¯é¢„æµ‹çŠ¯ç½ª, è¿™ä¸ªæŒºæœ‰æ„æ€ã€‚</li></ol><p>TIA:<br>é—®é¢˜å®šä¹‰: â€œevil-doersâ€ periodically gather at a hotel to plot their evil.<br>å‡è®¾: One billion people might be evil-doers; Everyone goes to a hotel one day in 100; A hotel holds 100 people; Examine hotel records for 1000 days;100,000 hotels<br>ç­–ç•¥: look for people who, on two different days, were both at the same hotel.<br>çœŸå®æƒ…å†µ: no evil-doers or few evil-doers(letâ€™s say 10), everyone behaves randomly </p><p>æ ¹æ®å‡è®¾å¾—åˆ°çš„ç»“æœ:<br>Probability that given persons p  and q  will be at the same hotel on given day d :<br>1/100 x 1/100 x 1/100,000 = 10^-9<br>Probability that p  and q  will be at the same hotel on given days d1 and d2:<br>10^-9 * 10^-9 = 10^-18<br>Pairs of days:<br>1000 x 999/2 = 5x10^5(roughly)<br>Probability that p and q will be at the same hotel on some two days:<br>10^-18 x 5x10^5 = = 5 x 10^-13<br>Pairs of people:<br>10^9 x 10^9 /2 = 5 x 10^17 (roughly)<br>Expected number of â€œsuspiciousâ€ pairs of people(æ ¹æ®ç­–ç•¥å¾—åˆ°çš„å¯ç–‘çŠ¯ç½ª):<br>5 x 10^-13  x 5 x 10^17 = 250,000 &gt;&gt; 10</p><h2 id="Moral-DSé“ä¹‰"><a href="#Moral-DSé“ä¹‰" class="headerlink" title="Moral (DSé“ä¹‰)"></a>Moral (DSé“ä¹‰)</h2><p>When looking for a property (e.g., â€œtwo people stayed at the same hotel twiceâ€), make sure that the property does not allow so many possibilities that random data will surely produce facts â€œof interest.â€<br>ç®€å•çš„è¯´ï¼Œå°±æ˜¯éœ€è¦å‘ç°çš„è§„åˆ™ä¸è¦å—åˆ°å¤ªå¤šå› ç´ çš„å½±å“ã€‚</p><h1 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h1><h2 id="Work-flow-of-MapReduce"><a href="#Work-flow-of-MapReduce" class="headerlink" title="Work flow of MapReduce"></a>Work flow of MapReduce</h2><ul><li>Read inputs as a set of key-value-pairs</li><li>Map transforms input kv-pairs into a new set of kâ€™vâ€™-pairs</li><li>Sorts &amp; Shuffles the kâ€™vâ€™-pairs to output nodes</li><li>All kâ€™vâ€™-pairs with a given kâ€™ are sent to the same reduce</li><li>Reduce processes all kâ€™vâ€™-pairs grouped by key into new kâ€™â€™vâ€™â€™-pairs</li><li>Write the resulting pairs to files</li></ul><p>example: documents word count</p><p>Problem: Counting the number of occurrences for each word in a collection of documents<br>Input: A repository of documents, and each document is an element</p><p>Map function:<br>The Map task reads a document and breaks it into its sequence of words w1, w2, . . . , wn.<br>It then emits a sequence of key-value pairs where the value is always 1.   (w1, 1), (w2, 1), . . . ,(wn, 1)<br>When the Reduce function is associative and commutative, we can push some of what the reducers do to the Map tasks:<br>An option, is to combine m key-value pairs (w, 1) into a single pair (w, m).</p><p>Reduce function:<br>The output of a reducer consists of the word and the sum (w, m), where w is a word that appears at least once among.<br>Collects all values and aggregates by key.</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs sql">input format<br><br>Input: a <span class="hljs-keyword">set</span> <span class="hljs-keyword">of</span> <span class="hljs-keyword">key</span>-<span class="hljs-keyword">value</span> pairs<br>Programmer specifies two methods:<br><span class="hljs-keyword">Map</span>(k, v)  -&gt;  &lt;kâ€™, vâ€™&gt;*<br>Takes a <span class="hljs-keyword">key</span>-<span class="hljs-keyword">value</span> pair <span class="hljs-keyword">and</span> outputs a <span class="hljs-keyword">set</span> <span class="hljs-keyword">of</span> <span class="hljs-keyword">key</span>-<span class="hljs-keyword">value</span> pairs<br>E.g., <span class="hljs-keyword">key</span> <span class="hljs-keyword">is</span> the filename, <span class="hljs-keyword">value</span> <span class="hljs-keyword">is</span> a single line <span class="hljs-keyword">in</span> the <span class="hljs-keyword">file</span><br>There <span class="hljs-keyword">is</span> one <span class="hljs-keyword">Map</span> <span class="hljs-keyword">call</span> <span class="hljs-keyword">for</span> every (k,v) pair<br><br>Reduce(kâ€™, &lt;vâ€™&gt;*) -&gt; &lt;kâ€™, vâ€™â€™&gt;*<br><span class="hljs-keyword">All</span> <span class="hljs-keyword">values</span> vâ€™ <span class="hljs-keyword">with</span> same <span class="hljs-keyword">key</span> kâ€™ <span class="hljs-keyword">are</span> <span class="hljs-keyword">reduced</span> together <span class="hljs-keyword">and</span> processed <span class="hljs-keyword">in</span> vâ€™ <span class="hljs-keyword">order</span><br>There <span class="hljs-keyword">is</span> one Reduce <span class="hljs-keyword">function</span> <span class="hljs-keyword">call</span> per <span class="hljs-keyword">unique</span> <span class="hljs-keyword">key</span> kâ€™<br><br></code></pre></td></tr></table></figure><h2 id="MapReduce-Environment"><a href="#MapReduce-Environment" class="headerlink" title="MapReduce Environment"></a>MapReduce Environment</h2><ol><li><code>Partitioning</code> the input data</li><li><code>Scheduling</code> the programâ€™s execution across a set of machines</li><li>Performing the <code>group by key</code> step : In practice this is the bottleneck</li><li>Handling machine <code>failures</code></li><li>Managing required inter-machine: <code>Communication</code></li></ol><h2 id="Dataflow"><a href="#Dataflow" class="headerlink" title="Dataflow"></a>Dataflow</h2><ul><li>Input and final output are stored on a distributed file system (HDFS): Scheduler tries to schedule map tasks â€œcloseâ€ to physical storage location of input data</li><li>Intermediate results are stored on local FS of Map and Reduce workers</li><li>Output is often input to another MapReduce task.</li></ul><h2 id="Grouping-by-Key"><a href="#Grouping-by-Key" class="headerlink" title="Grouping by Key"></a>Grouping by Key</h2><ul><li><p>After all Map tasks have all completed successfully:Key-value pairs are grouped by key(Values associated with each key are formed into a list of values)</p></li><li><p>Grouping is performed by the system, regardless of what the Map and Reduce tasks do</p></li><li><p>The master controller typically applies a hash function to keys and produces a bucket number from 0 to r-1</p></li><li><p>Each key that is output by a Map task is hashed and its key-value pair is put in one of r local files</p></li><li><p>Each file is sent to one of the Reduce tasks.</p></li></ul><h2 id="æŠ€å·§"><a href="#æŠ€å·§" class="headerlink" title="æŠ€å·§"></a>æŠ€å·§</h2><p>Why perform task in the Map task rather than the Reduce task? Reduce communication: send less data over network; Perform logic in the Map where possible without introducing errors.</p><h1 id="Reference-book"><a href="#Reference-book" class="headerlink" title="Reference book"></a>Reference book</h1><p>Mining of Massive Datasets: <a href="http://infolab.stanford.edu/~ullman/mmds/book.pdf">http://infolab.stanford.edu/~ullman/mmds/book.pdf</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>Data Mining</tag>
      
      <tag>Big Data</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch-BigGraph è¯„ä¼°</title>
    <link href="/2020/11/04/PBG-Evaluation/"/>
    <url>/2020/11/04/PBG-Evaluation/</url>
    
    <content type="html"><![CDATA[<h1 id="PyTorch-BigGraph-è¯„ä¼°"><a href="#PyTorch-BigGraph-è¯„ä¼°" class="headerlink" title="PyTorch-BigGraph è¯„ä¼°"></a>PyTorch-BigGraph è¯„ä¼°</h1><p>During training, the average loss is reported for each edge bucket at each pass. Evaluation metrics can be computed on held-out data during or after training to measure the quality of trained embeddings.<br>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæ¯ä¸€æ¬¡epochä¸­çš„æ¯ä¸€ä¸ªæ¡¶çš„çš„å¹³å‡æŸå¤±ä¼šè¢«æ±‡æŠ¥ã€‚å¯ä»¥åœ¨è®­ç»ƒæœŸé—´æˆ–ä¹‹åæ ¹æ®ä¿ç•™çš„æ•°æ®è®¡ç®—è¯„ä¼°æŒ‡æ ‡ï¼Œä»¥æµ‹é‡è®­ç»ƒååµŒå…¥çš„è´¨é‡ã€‚</p><h2 id="Offline-evaluationÂ¶"><a href="#Offline-evaluationÂ¶" class="headerlink" title="Offline evaluationÂ¶"></a>Offline evaluationÂ¶</h2><p>The torchbiggraph_eval command will perform an offline evaluation of trained PBG embeddings on a validation dataset. This dataset should contain held-out data not included in the training dataset. It is invoked in the same way as the training command and takes the same arguments.<br>torchbiggraph_evalå‘½ä»¤å°†ä¼šå¯¹éªŒè¯æ•°æ®é›†æ‰§è¡Œè®­ç»ƒååµŒå…¥çš„ç¦»çº¿è¯„ä¼°ã€‚è¯¥æ•°æ®é›†åº”åŒ…å«è®­ç»ƒæ•°æ®é›†ä¸­æœªåŒ…å«çš„ä¿ç•™æ•°æ®ã€‚å®ƒä»¥ä¸è®­ç»ƒå‘½ä»¤ç›¸åŒçš„æ–¹å¼è°ƒç”¨ï¼Œå¹¶é‡‡ç”¨ç›¸åŒçš„å‚æ•°ã€‚</p><p>It is generally advisable to have two versions of the config file, one for training and one for evaluation, with the same parameters except for the edge paths, in order to evaluate a separate (and often smaller) set of edges. (Itâ€™s also possible to use a single config file and have it produce different output based on environment variables or other context). Training-specific config parameters (e.g., the learning rate, loss function, â€¦) will be ignored during evaluation.<br>é€šå¸¸å»ºè®®é…ç½®æ–‡ä»¶æœ‰ä¸¤ä¸ªç‰ˆæœ¬ï¼Œä¸€ä¸ªç”¨äºè®­ç»ƒï¼Œä¸€ä¸ªç”¨äºè¯„ä¼°ï¼Œé™¤äº†edge pathså‚æ•°å¤–ï¼Œå®ƒä»¬å…·æœ‰ç›¸åŒçš„å‚æ•°ï¼Œä»¥ä¾¿è¯„ä¼°ä¸€ç»„å•ç‹¬çš„ï¼ˆé€šå¸¸æ˜¯è¾ƒå°çš„ï¼‰è¾¹ã€‚ï¼ˆä¹Ÿå¯ä»¥ä½¿ç”¨å•ä¸ªé…ç½®æ–‡ä»¶ï¼Œå¹¶æ ¹æ®ç¯å¢ƒå˜é‡æˆ–å…¶ä»–ä¸Šä¸‹æ–‡äº§ç”Ÿä¸åŒçš„è¾“å‡ºï¼‰ã€‚ è¯„ä¼°è¿‡ç¨‹ä¸­å°†å¿½ç•¥è®­ç»ƒä¸“ç”¨çš„é…ç½®å‚æ•°ï¼ˆä¾‹å¦‚ï¼Œå­¦ä¹ ç‡ï¼ŒæŸå¤±å‡½æ•°ç­‰ï¼‰ã€‚</p><p>The metrics are first reported on each bucket, and a global average is computed at the end. (If multiple edge paths are in use, metrics are computed separately for each of them but still ultimately averaged).<br>é¦–å…ˆåœ¨æ¯ä¸ªå­˜å‚¨æ¡¶ä¸ŠæŠ¥å‘ŠæŒ‡æ ‡ï¼Œæœ€åè®¡ç®—å…¨å±€å¹³å‡å€¼ã€‚ ï¼ˆå¦‚æœæ­£åœ¨ä½¿ç”¨å¤šä¸ªedge paths ï¼Œåˆ™å°†é’ˆå¯¹æ¯ä¸ªè¾¹ç¼˜è·¯å¾„åˆ†åˆ«è®¡ç®—æŒ‡æ ‡ï¼Œä½†æœ€ç»ˆä»å°†å…¶å¹³å‡ï¼‰ã€‚</p><p>Many metrics are statistics based on the â€œranksâ€ of the edges of the validation set. The rank of a positive edge is determined by the rank of its score against the scores of a certain number of negative edges. A rank of 1 is the â€œbestâ€ outcome as it means that the positive edge had a higher score than all the negatives. Higher values are â€œworseâ€ as they indicate that the positive didnâ€™t stand out.<br>è®¸å¤šæŒ‡æ ‡æ˜¯åŸºäºéªŒè¯é›†è¾¹çš„â€œrankâ€çš„ç»Ÿè®¡ä¿¡æ¯ã€‚æ­£è¾¹çš„rankç”±å¾—åˆ†ç›¸å¯¹äºä¸€å®šæ•°é‡çš„è´Ÿè¾¹ç¼˜çš„å¾—åˆ†çš„rankç¡®å®šã€‚rank=1è¡¨ç¤ºâ€œæœ€ä½³â€ç»“æœï¼Œå› ä¸ºè¿™æ„å‘³ç€æ­£è¾¹æ¯”æ‰€æœ‰è´Ÿè¾¹çš„å¾—åˆ†éƒ½é«˜ã€‚è¾ƒé«˜çš„rankå€¼è¡¨ç¤ºæ€§èƒ½è¾ƒå·®ï¼Œå› ä¸ºå…¶è¡¨æ˜æ­£è¾¹å¹¶æ²¡æœ‰çªå‡ºæ˜¾ç¤ºå‡ºæ¥ã€‚</p><p>It may happen that some of the negative samples used in the rank computation are in fact other positive samples, which are expected to have a high score and may thus cause adverse effects on the rank. This effect is especially visible on smaller graphs, in particular when all other entities are used to construct the negatives. To fix it, and to match what is typically done in the literature, a so-called â€œfilteredâ€ rank is used in the FB15k demo script (and there only), where positive samples are filtered out when computing the rank of an edge. It is hard to scale this technique to large graphs, and thus it is not enabled globally. However, filtering is less important on large graphs as itâ€™s less likely to see a training edge among the sampled negatives.<br>åœ¨è®¡ç®—rankçš„è¿‡ç¨‹ä¸­ï¼ŒæŸäº›è´Ÿæ ·æœ¬å®é™…ä¸Šå¯èƒ½æ˜¯å…¶ä»–æ­£æ ·æœ¬ï¼Œè¿™äº›æ ·æœ¬å¯èƒ½ä¼šå¾—åˆ°è¾ƒé«˜çš„å¾—åˆ†å› æ­¤ä¼šå¯¹rankçš„ç»“æœé€ æˆä¸åˆ©å½±å“ã€‚åœ¨è¾ƒå°çš„å›¾ä¸Šï¼Œå°¤å…¶æ˜¯åœ¨ä½¿ç”¨æ‰€æœ‰å…¶ä»–å®ä½“æ„é€ è´Ÿæ ·æœ¬æ—¶ï¼Œè¿™ç§æ•ˆæœå°¤å…¶æ˜æ˜¾ã€‚ä¸ºäº†è§£å†³è¯¥é—®é¢˜å¹¶ä½¿å…¶ä¸æ–‡çŒ®ä¸­é€šå¸¸æ‰€åšçš„äº‹æƒ…ç›¸åŒ¹é…ï¼ŒFB15kæ¼”ç¤ºè„šæœ¬ï¼ˆä»…åœ¨æ­¤å¤„ï¼‰ä½¿ç”¨äº†æ‰€è°“çš„â€œè¿‡æ»¤åâ€ç­‰çº§ï¼Œåœ¨è®¡ç®—è¾¹rankæ—¶ä¼šæ»¤é™¤æ­£æ ·æœ¬ã€‚å¾ˆéš¾å°†æ­¤æŠ€æœ¯é€‚ç”¨äºåˆ°å¤§å›¾ä¸­ï¼Œå› æ­¤æ— æ³•å…¨å±€å¯ç”¨ã€‚ä½†æ˜¯ï¼Œè¿‡æ»¤åœ¨å¤§å‹å›¾ä¸Šçš„é‡è¦æ€§è¾ƒå¼±ï¼Œå› ä¸ºå®ƒä¸å¤ªå¯èƒ½åœ¨è´Ÿæ ·æœ¬ä¸­ä½¿ç”¨è®­ç»ƒçš„è¾¹ã€‚</p><p>The metrics are:<br>ç›¸å…³çš„æŒ‡æ ‡æœ‰</p><p>â€¢ Mean Rank: the average of the ranks of all positives (lower is better, best is 1).<br>â€¢ Mean Reciprocal Rank (MRR): the average of the reciprocal of the ranks of all positives (higher is better, best is 1).<br>â€¢ Hits@1: the fraction of positives that rank better than all their negatives, i.e., have a rank of 1 (higher is better, best is 1).<br>â€¢ Hits@10: the fraction of positives that rank in the top 10 among their negatives (higher is better, best is 1).<br>â€¢ Hits@50: the fraction of positives that rank in the top 50 among their negatives (higher is better, best is 1).<br>â€¢ Area Under the Curve (AUC): an estimation of the probability that a randomly chosen positive scores higher than a randomly chosen negative (any negative, not only the negatives constructed by corrupting that positive).</p><h2 id="Evaluation-during-training"><a href="#Evaluation-during-training" class="headerlink" title="Evaluation during training"></a>Evaluation during training</h2><p>Offline evaluation is a slow process that is intended to be run after training is complete to evaluate the final model on a held-out set of edges constructed by the user. However, itâ€™s useful to be able to monitor overfitting as training progresses. PBG offers this functionality, by calculating the same metrics as the offline evaluation before and after each pass on a small set of training edges. These stats are printed to the logs.<br>ç¦»çº¿è¯„ä¼°æ˜¯ä¸€ä¸ªç¼“æ…¢çš„è¿‡ç¨‹ï¼Œå…¶ç›®çš„åœ¨äºè¾¹è®­ç»ƒå®Œæˆåï¼Œå¯¹ä¿ç•™çš„è¾¹è¿›è¡Œè¯„ä¼°æ¥è¯„ä¼°è®­ç»ƒçš„æ¨¡å‹ã€‚ä½†æ˜¯ï¼Œè®­ç»ƒè¿‡ç¨‹ä¸­ç›‘æ§è¿‡åº¦æ‹Ÿåˆæ˜¯å¾ˆæœ‰ç”¨çš„ã€‚PBGé€šè¿‡åœ¨æ¯æ¬¡ç»è¿‡ä¸€å°ç»„è®­ç»ƒè¾¹ä¹‹å‰å’Œä¹‹åè®¡ç®—ä¸è„±æœºè¯„ä¼°ç›¸åŒçš„æŒ‡æ ‡æ¥å®ç°è®­ç»ƒæ—¶è¯„ä¼°ã€‚ è¿™äº›ç»Ÿè®¡ä¿¡æ¯å°†æ‰“å°åˆ°æ—¥å¿—ä¸­ã€‚</p><p>The metrics are computed on a set of edges that is held out automatically from the training set. To be more explicit: using this feature means that training happens on fewer edges, as some are excluded and reserved for this evaluation. The holdout fraction is controlled by the eval_fraction config parameter (setting it to zero thus disables this feature). The evaluations before and after each training iteration happen on the same set of edges, thus are comparable. Moreover, the evaluations for the same edge chunk, edge path and bucket at different epochs also use the same set of edges.<br>æŒ‡æ ‡æ˜¯åœ¨ä¸€ç»„è¾¹ä¸Šè®¡ç®—çš„ï¼Œè¿™äº›è¾¹ä¼šä»è®­ç»ƒé›†ä¸­è‡ªåŠ¨ä¿ç•™ä¸‹æ¥ï¼ˆä¸è¢«è®­ç»ƒï¼Œä»…ä½œä¸ºè¯„ä¼°ï¼‰ã€‚æ›´æ˜ç¡®åœ°è¯´ï¼šä½¿ç”¨æ­¤åŠŸèƒ½æ„å‘³ç€ä¼šè®­ç»ƒè¾ƒå°‘çš„è¾¹ï¼Œå› ä¸ºæŸäº›è¾¹è¢«æ’é™¤å¹¶ä¿ç•™ç”¨äºæ­¤è¯„ä¼°ã€‚ä¿æŒæ¯”ä¾‹ç”±eval_fractioné…ç½®å‚æ•°æ§åˆ¶ï¼ˆå°†å…¶è®¾ç½®ä¸ºé›¶å°†ç¦ç”¨æ­¤åŠŸèƒ½ï¼‰ã€‚æ¯æ¬¡è®­ç»ƒè¿­ä»£ä¹‹å‰å’Œä¹‹åçš„è¯„ä¼°éƒ½åœ¨åŒä¸€ç»„è¾¹ä¸Šè¿›è¡Œï¼Œå› æ­¤å…·æœ‰å¯æ¯”æ€§ã€‚æ­¤å¤–ï¼Œåœ¨ä¸åŒæ—¶æœŸå¯¹ç›¸åŒè¾¹ç¼˜å—ï¼Œè¾¹ç¼˜è·¯å¾„å’Œå­˜å‚¨æ¡¶çš„è¯„ä¼°ä¹Ÿä½¿ç”¨ç›¸åŒçš„è¾¹ç¼˜é›†ã€‚</p><p>Evaluation metrics are computed both before and after training each edge bucket because it provides insight into whether the partitioned training is working. If the partitioned training is converging, then the gap between the â€œbeforeâ€ and â€œafterâ€ statistics should go to zero over time. On the other hand, if the partitioned training is causing the model to overfit on each edge bucket (thus decreasing performance for other edge buckets) then there will be a persistent gap between the â€œbeforeâ€ and â€œafterâ€ statistics.<br>è¯„ä¼°æŒ‡æ ‡åœ¨è®­ç»ƒæ¯ä¸ªè¾¹ç¼˜å­˜å‚¨å—ä¹‹å‰å’Œä¹‹åéƒ½ä¼šè¿›è¡Œè®¡ç®—ï¼Œå› ä¸ºå®ƒå¯ä»¥æ´æ‚‰åˆ†åŒºçš„è®­ç»ƒæ˜¯å¦æœ‰æ•ˆã€‚å¦‚æœåˆ†åŒºè®­ç»ƒæ­£åœ¨æ”¶æ•›ï¼Œåˆ™â€œä¹‹å‰â€å’Œâ€œä¹‹åâ€ç»Ÿè®¡é‡ä¹‹é—´çš„å·®è·åº”éšæ—¶é—´æ¨ç§»å˜ä¸ºé›¶ã€‚å¦ä¸€æ–¹é¢ï¼Œå¦‚æœåˆ†åŒºè®­ç»ƒå¯¼è‡´æ¨¡å‹åœ¨æ¯ä¸ªè¾¹ç¼˜å­˜å‚¨åŒºä¸Šè¿‡æ‹Ÿåˆï¼ˆä»è€Œé™ä½äº†å…¶ä»–è¾¹ç¼˜å­˜å‚¨åŒºçš„æ€§èƒ½ï¼‰ï¼Œåˆ™â€œä¹‹å‰â€å’Œâ€œä¹‹åâ€ç»Ÿè®¡é‡ä¹‹é—´å°†å­˜åœ¨æŒç»­çš„å·®è·ã€‚</p><p>Itâ€™s possible to use different batch sizes for same-batch and uniform negative sampling by tuning the eval_num_batch_negs and the eval_num_uniform_negs config parameters.<br>é€šè¿‡è°ƒæ•´eval_num_batch_negså’Œeval_num_uniform_negsé…ç½®å‚æ•°ï¼Œå¯ä»¥å¯¹åŒä¸€æ‰¹æ¬¡å’Œç»Ÿä¸€è´Ÿé‡‡æ ·ä½¿ç”¨ä¸åŒçš„æ‰¹æ¬¡å¤§å°ã€‚</p>]]></content>
    
    
    
    <tags>
      
      <tag>PyTorch-BigGraph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>æ’åé—®é¢˜ä¸­çš„è¯„ä¼°æŒ‡æ ‡</title>
    <link href="/2020/11/04/Eva-Ranking-Problem/"/>
    <url>/2020/11/04/Eva-Ranking-Problem/</url>
    
    <content type="html"><![CDATA[<h2 id="Ranking-Problems"><a href="#Ranking-Problems" class="headerlink" title="Ranking Problems"></a>Ranking Problems</h2><p>In many domains, data scientists are asked to not just predict what class/classes an example belongs to, but to rank classes according to how likely they are for a particular example.<br>åœ¨è®¸å¤šé¢†åŸŸï¼Œæ•°æ®ç§‘å­¦å®¶ä¸ä»…è¢«è¦æ±‚é¢„æµ‹ä¸€ä¸ªç¤ºä¾‹å±äºå“ªä¸ªç±»åˆ«ï¼Œè¿˜åº”æ ¹æ®ç‰¹å®šç¤ºä¾‹å¯¹å®ƒä»¬è¿›è¡Œåˆ†ç±»çš„å¯èƒ½æ€§æ¥å¯¹ç±»åˆ«è¿›è¡Œæ’åã€‚</p><table><thead><tr><th>Classification</th><th>Ranking</th></tr></thead><tbody><tr><td>Order of predictions doesnâ€™t matter</td><td>Order of predictions does matter</td></tr></tbody></table><p>This is often the case because, in the real world, resources are limited.<br>è¿™æ˜¯ç»å¸¸å‘ç”Ÿçš„æƒ…å†µï¼Œå› ä¸ºåœ¨ç°å®ä¸–ç•Œä¸­ï¼Œèµ„æºæ˜¯æœ‰é™çš„ã€‚</p><p>This means that whoever will use the predictions your model makes has limited time, limited space. So they will likely prioritize.Some domains where this effect is particularly noticeable:<br>è¿™æ„å‘³ç€å¯¹äºé¢„æµ‹å‡ºçš„ç»“æœï¼Œä»»ä½•äººåªèƒ½æœ‰é™çš„ç©ºé—´ä»¥åŠæ—¶é—´ï¼Œæ‰€ä»¥ä»–ä»¬æ›´å€¾å‘äºä¼˜å…ˆçº§é«˜çš„ã€‚åœ¨ä¸€äº›ç‰¹å®šé¢†åŸŸå°¤å…¶æ˜æ˜¾:</p><p>â€¢ Search engines: Predict which documents match a query on a search engine.<br>â€¢ Tag suggestion for Tweets: Predict which tags should be assigned to a tweet.<br>â€¢ Image label prediction: Predict what labels should be suggested for an uploaded picture.<br>â€¢ æœç´¢å¼•æ“ï¼šé¢„æµ‹å“ªäº›æ–‡æ¡£åŒ¹é…æœç´¢å¼•æ“ä¸Šçš„æŸ¥è¯¢ã€‚<br>â€¢ æ¨æ–‡æ ‡ç­¾å»ºè®®ï¼šé¢„æµ‹åº”å°†å“ªäº›æ ‡ç­¾åˆ†é…ç»™æ¨æ–‡ã€‚<br>â€¢ å›¾åƒæ ‡ç­¾é¢„æµ‹ï¼šé¢„æµ‹åº”è¯¥ä¸ºä¸Šä¼ çš„å›¾ç‰‡å»ºè®®å“ªäº›æ ‡ç­¾ã€‚</p><p>If your machine learning model produces a real-value for each of the possible classes, you can turn a classification problem into a ranking problem.<br>å¦‚æœæœºå™¨å­¦ä¹ æ¨¡å‹ä¸ºæ¯ä¸€ä¸ªç±»ç”Ÿæˆä¸€ä¸ªå¯èƒ½çš„å®æ•°ï¼Œé‚£ä¹ˆå°±å¯ä»¥å°†ä¸€ä¸ªåˆ†ç±»é—®é¢˜è½¬åŒ–ä¸ºæ’åé—®é¢˜ã€‚ï¼ˆä¸ªäººæ„Ÿè§‰æœ‰ä¸€ç§ç¡¬åˆ†ç±»å’Œè½¯åˆ†ç±»çš„æ„å‘³ã€‚ï¼‰</p><p>In other words, if you predict scores for a set of examples and you have a ground truth, you can order your predictions from highest to lowest and compare them with the ground truth:<br>æ¢å¥è¯è¯´ï¼Œå¦‚æœé¢„æµ‹ä¸€ç»„ç¤ºä¾‹çš„å¾—åˆ†å¹¶ä¸”æœ‰åŸºæœ¬äº‹å®ï¼Œåˆ™å¯ä»¥å°†é¢„æµ‹ä»æœ€é«˜åˆ°æœ€ä½æ’åºï¼Œå¹¶å°†å®ƒä»¬ä¸åŸºæœ¬äº‹å®è¿›è¡Œæ¯”è¾ƒ</p><p>â€¢ Search engines: Do relevant documents appear up on the list or down at the bottom?<br>â€¢ Tag suggestion for Tweets: Are the correct tags predicted with higher score or not?<br>â€¢ Image label prediction: Does your system correctly give more weight to correct labels?<br>â€¢ æœç´¢å¼•æ“ï¼šç›¸å…³æ–‡æ¡£æ˜¯å¦å‡ºç°åœ¨åˆ—è¡¨çš„é¡¶éƒ¨æˆ–åº•éƒ¨ï¼Ÿ<br>â€¢ æ¨ç‰¹çš„æ ‡ç­¾å»ºè®®ï¼šæ˜¯å¦ä»¥è¾ƒé«˜çš„åˆ†æ•°é¢„æµ‹äº†æ­£ç¡®çš„æ ‡ç­¾?<br>â€¢ å›¾åƒæ ‡ç­¾é¢„æµ‹ï¼šç³»ç»Ÿæ˜¯å¦æ­£ç¡®åœ°èµ‹äºˆäº†æ­£ç¡®æ ‡ç­¾æ›´å¤šçš„æƒé‡ï¼Ÿ</p><p>In the following sections, we will go over many ways to evaluate ranked predictions with respect to actual values, or ground truth.<br>åœ¨ä»¥ä¸‹å„èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä»‹ç»è®¸å¤šæ–¹æ³•æ¥è¯„ä¼°å…³äºå®é™…å€¼æˆ–åŸºæœ¬äº‹å®çš„æ’åé¢„æµ‹ã€‚</p><h2 id="Sample-dataset-Ground-Truth"><a href="#Sample-dataset-Ground-Truth" class="headerlink" title="Sample dataset (Ground Truth)"></a>Sample dataset (Ground Truth)</h2><p>We will use the following dummy dataset to illustrate examples in this post:<br>ä½¿ç”¨ä»¥ä¸‹è™šæ‹Ÿæ•°æ®é›†æ¥è¯´æ˜æœ¬æ–‡ä¸­çš„ç¤ºä¾‹:<br><img src="/image/sample-data.png"></p><h2 id="Precision-k"><a href="#Precision-k" class="headerlink" title="Precision @k"></a>Precision @k</h2><p>Precision @k is simply precision evaluated only up to the k-th prediction, i.e.:<br>Prec@Kè¡¨ç¤ºè®¾å®šä¸€ä¸ªé˜ˆå€¼Kï¼Œåœ¨æ£€ç´¢ç»“æœåˆ°ç¬¬Kä¸ªé¢„æµ‹ä¾‹å­ä¸ºæ­¢ï¼Œæ’åºç»“æœçš„æŸ¥å‡†ç‡<br><img src="/image/pred_k.png"> <img src="/image/pred_sample.png"></p><p>ä¾‹å­: Precision @1 = 1/1 =1 ,  Precision @4 = 3/4 =0.75,  Precision @8  = Precision = 4/8 = 0.5</p><h2 id="Recall-k"><a href="#Recall-k" class="headerlink" title="Recall @k"></a>Recall @k</h2><p>Recall @k is simply Recall evaluated only up to the -th prediction, i.e.:<br>Recall@Kè¡¨ç¤ºè®¾å®šä¸€ä¸ªé˜ˆå€¼Kï¼Œåœ¨æ£€ç´¢ç»“æœåˆ°ç¬¬Kä¸ªé¢„æµ‹ä¾‹å­ä¸ºæ­¢ï¼Œæ’åºç»“æœçš„æŸ¥å…¨ç‡</p><p><img src="/image/recall_k.png"> <img src="/image/rec_sample.png"></p><p>ä¾‹å­: Recall @1 = 1/4 =0.25 ,  Recall @4 = 3/4 =0.75,  Recall @8  = Recall = 4/4 = 1</p><h2 id="F1-k"><a href="#F1-k" class="headerlink" title="F1 @k"></a>F1 @k</h2><p>F1 @k is a rank-based metric that can be summarized as follows: â€œWhat F1-score do I get if I only consider the top k predictions my model outputs?<br>F1@Kè¡¨ç¤ºè®¾å®šä¸€ä¸ªé˜ˆå€¼Kï¼Œåœ¨æ£€ç´¢ç»“æœåˆ°ç¬¬Kä¸ªé¢„æµ‹ä¾‹å­ä¸ºæ­¢ï¼Œæ’åºç»“æœçš„F1-score</p><p><img src="/image/f1_k.png"><img src="/image/sample_f1_k.png"></p><p>ä¾‹å­: F1 @1 = 2x (1/1 * 1/4 )/(1/1+1/4) = 0.4 </p><h2 id="AP-Average-Precision"><a href="#AP-Average-Precision" class="headerlink" title="AP (Average Precision)"></a>AP (Average Precision)</h2><p>AP is a metric that tells you how much of the relevant documents are concentrated in the highest ranked predictions.<br>APæ˜¯ä¸€ç§æŒ‡æ ‡ï¼Œå®ƒå‘Šè¯‰æ‚¨æœ‰å¤šå°‘ç›¸å…³æ–‡æ¡£é›†ä¸­åœ¨æ’åæœ€é«˜çš„é¢„æµ‹ä¸­ã€‚</p><p>So for each threshold level (k) you take the difference between the Recall at the current level and the Recall at the previous threshold and multiply by the Precision at that level. Then sum the contributions of each.<br>å› æ­¤ï¼Œå¯¹äºæ¯ä¸ªé˜ˆå€¼çº§åˆ«ï¼ˆkï¼‰ï¼Œéœ€è¦å–å½“å‰çº§åˆ«çš„Recallå’Œå‰ä¸€ä¸ªé˜ˆå€¼çš„Recallä¹‹é—´çš„å·®ï¼Œç„¶åä¹˜ä»¥è¯¥çº§åˆ«çš„Precisionï¼Œæœ€åæ±‚å’Œã€‚</p><p>ä¸ºä»€ä¹ˆä¼šæœ‰APï¼Ÿ<br>precisonåªæ˜¯è€ƒè™‘äº†è¿”å›ç»“æœä¸­ç›¸å…³æ–‡æ¡£çš„ä¸ªæ•°ï¼Œæ²¡æœ‰è€ƒè™‘æ–‡æ¡£ä¹‹é—´çš„åºã€‚å¯¹ä¸€ä¸ªæœç´¢å¼•æ“æˆ–æ¨èç³»ç»Ÿè€Œè¨€è¿”å›çš„ç»“æœå¿…ç„¶æ˜¯æœ‰åºçš„ï¼Œè€Œä¸”è¶Šç›¸å…³çš„æ–‡æ¡£æ’çš„è¶Šé å‰è¶Šå¥½ï¼Œäºæ˜¯æœ‰äº†APçš„æ¦‚å¿µã€‚</p><p><img src="/image/AP.png"></p><h2 id="MAP-Mean-Average-Precision"><a href="#MAP-Mean-Average-Precision" class="headerlink" title="MAP (Mean Average Precision)"></a>MAP (Mean Average Precision)</h2><p>AP (Average Precision) is a metric that tells you how a single sorted prediction compares with the ground truth. E.g. AP would tell you how correct a single ranking of documents is, with respect to a single query.<br>APå¯ä»¥å¾—åˆ°å•ä¸ªæ’åºçš„é¢„æµ‹ä¸åŸºæœ¬äº‹å®è¿›è¡Œæ¯”è¾ƒã€‚ä¾‹å¦‚ï¼Œå¯¹äºå•æ¬¡æŸ¥è¯¢å¾—åˆ°çš„æ’åºç»“æœçš„æ–‡æ¡£åˆ°åº•æœ‰å¤šæ­£ç¡®ã€‚æ‰€ä»¥å¯ä»¥å¯¹æ‰€æœ‰çš„APå–å¹³å‡å¾—åˆ°MAP</p><blockquote><p>AP: Informs you how correct a modelâ€™s ranked predictions are for a single example<br> MAP: Informs you how correct a modelâ€™s ranked predictions are, on average, over a whole validation dataset.</p></blockquote><p>æºåœ°å€: <a href="https://queirozf.com/entries/evaluation-metrics-for-ranking-problems-introduction-and-examples#ranking-problems">https://queirozf.com/entries/evaluation-metrics-for-ranking-problems-introduction-and-examples#ranking-problems</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>Evaluation</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>åˆ†ç±»é—®é¢˜ä¸­çš„è¯„ä¼°æŒ‡æ ‡</title>
    <link href="/2020/11/04/Eva-Classification-Problem/"/>
    <url>/2020/11/04/Eva-Classification-Problem/</url>
    
    <content type="html"><![CDATA[<h2 id="Term"><a href="#Term" class="headerlink" title="Term"></a>Term</h2><ul><li>True Positives (TP): should be TRUE, you predicted TRUE</li><li>False Positives (FP): should be FALSE, you predicted TRUE</li><li>True Negative (TN): should be FALSE, you predicted FALSE</li><li>False Negatives (FN): should be TRUE, you predicted FALSE</li></ul><p>ä¸ªäººçœ‹æ¥ï¼ŒTPå’ŒTNéƒ½å¾ˆå¥½ç†è§£ï¼ŒäºŒè€…åæ˜ äº†æ¨¡å‹å¯¹äºé¢„æµ‹çš„å‡†ç¡®æ€§ã€‚FPå’ŒFNæœ‰ç‚¹å®¹æ˜“è®°ä¸å¤ªé¡ºï¼Œæ‰€ä»¥ä½¿ç”¨ä¸€ä¸ªä¾‹å­å°±å¾ˆå¥½å»åŒºåˆ†ï¼š<br>å¼ ä¸‰å»çœ‹ç—…ï¼Œæ˜¯å¦å¾—äº†ç™Œç—‡, FP=&gt;è¯¯è¯Š, FN=&gt;æ²¡æŸ¥å‡ºæ¥ã€‚</p><h2 id="Accuracy-å‡†ç¡®ç‡"><a href="#Accuracy-å‡†ç¡®ç‡" class="headerlink" title="Accuracy - å‡†ç¡®ç‡"></a>Accuracy - å‡†ç¡®ç‡</h2><blockquote><p>What percentage of my predictions are correct? æ¨¡å‹é¢„æµ‹çš„æ­£ç¡®æ€§</p></blockquote><p><img src="/image/acc.png"></p><ul><li>Good for single label, binary classifcation.</li><li>Not good for imbalanced datasets. å—æ•°æ®ä¸å‡è¡¡å½±å“å¾ˆå¤§<br>  If, in the dataset, 99% of samples are TRUE and you blindly predict TRUE for everything, youâ€™ll have 0.99 accuracy, but you havenâ€™t actually learned anything.</li></ul><h2 id="Precision-æŸ¥å‡†ç‡"><a href="#Precision-æŸ¥å‡†ç‡" class="headerlink" title="Precision - æŸ¥å‡†ç‡"></a>Precision - æŸ¥å‡†ç‡</h2><blockquote><p>Of the points that I predicted TRUE, how many are actually TRUE? æ¨¡å‹é¢„æµ‹çš„æ­£ä¾‹ä¸­ã€‚çœŸå®æ­£ä¾‹çš„æ¯”ä¾‹</p></blockquote><p><img src="/image/pre.png"></p><ul><li>Good for multi-label / multi-class classification and information retrieval</li><li>Good for unbalanced datasets</li></ul><h2 id="Recall-æŸ¥å…¨ç‡"><a href="#Recall-æŸ¥å…¨ç‡" class="headerlink" title="Recall - æŸ¥å…¨ç‡"></a>Recall - æŸ¥å…¨ç‡</h2><blockquote><p>Of all the points that are actually TRUE, how many did I correctly predict çœŸå®æ­£ä¾‹ä¸­ï¼Œæ¨¡å‹é¢„æµ‹ä¸ºæ­£çš„æ¯”ä¾‹</p></blockquote><p><img src="/image/recall.png"></p><ul><li>Good for multi-label / multi-class classification and information retrieval</li><li>Good for unbalanced datasets</li></ul><h2 id="F1"><a href="#F1" class="headerlink" title="F1"></a>F1</h2><blockquote><p>Can you give me a single metric that balances precision and recall?  F1-score (alternatively, F1-Measure), is a mixed metric that takes into account both Precision and Recall. å°†æŸ¥å…¨ä¸æŸ¥å‡†éƒ½è€ƒè™‘è¿›å»çš„F1</p></blockquote><p><img src="/image/f1.png"></p><ul><li>Gives equal weight to precision and recall</li><li>Good for unbalanced datasets</li></ul><h2 id="AUC-Area-under-ROC-Curve"><a href="#AUC-Area-under-ROC-Curve" class="headerlink" title="AUC (Area under ROC Curve)"></a>AUC (Area under ROC Curve)</h2><blockquote><p>Is my model better than just random guessing?<br>â€¦å¾…å®šã€‚ã€‚ã€‚</p></blockquote><p>æºåœ°å€ï¼š <a href="https://queirozf.com/entries/evaluation-metrics-for-classification-quick-examples-references#precision">https://queirozf.com/entries/evaluation-metrics-for-classification-quick-examples-references#precision</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>Evaluation</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch-BigGraph æŸå¤±è®¡ç®—</title>
    <link href="/2020/10/30/PBG-Loss-calculation/"/>
    <url>/2020/10/30/PBG-Loss-calculation/</url>
    
    <content type="html"><![CDATA[<h1 id="PyTorch-BigGraph-æŸå¤±è®¡ç®—"><a href="#PyTorch-BigGraph-æŸå¤±è®¡ç®—" class="headerlink" title="PyTorch-BigGraph æŸå¤±è®¡ç®—"></a>PyTorch-BigGraph æŸå¤±è®¡ç®—</h1><p>The training process aims at finding the embeddings for the entities so that the scores of the positive edges are higher than the scores of the negative edges. When unpacking what this means, three different aspects come into play:<br>è®­ç»ƒè¿‡ç¨‹æ—¨åœ¨æ‰¾åˆ°å®ä½“çš„åµŒå…¥ï¼Œä½¿å¾—æ­£è¾¹å®ä¾‹çš„å¾—åˆ†é«˜äºè´Ÿè¾¹å®ä¾‹çš„å¾—åˆ†ã€‚ å…·ä½“çš„è¯´ï¼Œåˆ†ä¸ºä»¥ä¸‹ä¸‰ä¸ªéƒ¨åˆ†ï¼š</p><p>â€¢ One must first determine which edges are to be considered as positive and negative samples.<br>â€¢ Then, once the scores of all the samples have been determined, one must decide how to aggregate them in a single loss value.<br>â€¢ Finally, one must decide how to go about optimizing that loss.</p><p>â€¢ é¦–å…ˆå¿…é¡»ç¡®å®šå“ªäº›è¾¹è¢«è§†ä¸ºæ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬ã€‚<br>â€¢ ç„¶åï¼Œä¸€æ—¦ç¡®å®šäº†æ‰€æœ‰æ ·æœ¬çš„å¾—åˆ†ï¼Œå°±å¿…é¡»å†³å®šå¦‚ä½•å°†å®ƒä»¬æ±‡æ€»ä¸ºä¸€ä¸ªæŸå¤±å€¼ã€‚<br>â€¢ æœ€åï¼Œå¿…é¡»å†³å®šå¦‚ä½•ä¼˜åŒ–è¿™ä¸€æŸå¤±ã€‚</p><p>This chapter will dive into each of these issues.<br>æœ¬ç« å°†æ·±å…¥æ¢è®¨è¿™äº›é—®é¢˜ã€‚</p><h2 id="Negative-sampling"><a href="#Negative-sampling" class="headerlink" title="Negative sampling"></a>Negative sampling</h2><p>The edges provided in the input data are known to be positives but, as PBG operates under the open-world assumption, the edges that are not in the input are not necessarily negatives. However, as PBG is designed to perform on large sparse graphs, it relies on the approximation that any random edge is a negative with very high probability.<br>å·²çŸ¥è¾“å…¥æ•°æ®ä¸­æä¾›çš„è¾¹ä¸ºæ­£å®ä¾‹ï¼Œä½†æ˜¯ï¼Œç”±äºPBGæ˜¯åŸºäºå¼€æ”¾ä¸–ç•Œå‡è®¾çš„ï¼Œå› æ­¤ä¸åœ¨è¾“å…¥ä¸­çš„è¾¹ä¸ä¸€å®šä¸ºè´Ÿå®ä¾‹ã€‚ä½†æ˜¯ï¼Œç”±äºPBGè®¾è®¡æ˜¯åœ¨å¤§å‹ç¨€ç–å›¾è¿è¡Œçš„ï¼Œå› æ­¤å®ƒä¾èµ–äºè¿‘ä¼¼å€¼ï¼Œå³ä»»ä½•éšæœºè¾¹ä¸ºè´Ÿå®ä¾‹çš„å¯èƒ½æ€§å¾ˆé«˜ã€‚</p><p>The goal of sampling negatives is to produce a set of negative edges for each positive edge of a batch. Usual downstream applications (ranking, classification, â€¦) are interested in comparing the score of an edge (ğ‘¥,ğ‘Ÿ,ğ‘¦1) with the score of an edge (ğ‘¥,ğ‘Ÿ,ğ‘¦2). Therefore, PBG produces negative samples for a given positive edge by corrupting the entity on one of its sides, keeping the other side and the relation type intact. This makes the sampling more suited to the task.<br>è´Ÿé‡‡æ ·çš„ç›®çš„æ˜¯åœ¨ä¸€ä¸ªæ‰¹æ¬¡ä¸Šçš„ä¸ºæ¯æ¡æ­£è¾¹å®ä¾‹å­äº§ç”Ÿä¸€ç»„è´Ÿè¾¹å®ä¾‹ã€‚é€šå¸¸çš„ä¹‹åçš„æ“ä½œï¼ˆæ’åï¼Œåˆ†ç±»ç­‰ï¼‰éƒ½å¸Œæœ›å°†è¾¹ï¼ˆğ‘¥ï¼Œğ‘Ÿï¼Œğ‘¦1ï¼‰çš„å¾—åˆ†ä¸è¾¹ï¼ˆğ‘¥ï¼Œğ‘Ÿï¼Œğ‘¦2ï¼‰çš„å¾—åˆ†è¿›è¡Œæ¯”è¾ƒã€‚å› æ­¤ï¼ŒPBGé€šè¿‡ç ´åå…¶ä¸€ä¾§çš„å®ä½“ï¼Œä¿æŒå¦ä¸€ä¾§å’Œå…³è”ç±»å‹çš„å®Œæ•´æ€§æ¥ç”Ÿæˆç»™å®šæ­£è¾¹å®ä¾‹çš„è´Ÿæ ·æœ¬ã€‚è¿™ä½¿å¾—é‡‡æ ·æ›´åŠ é€‚åˆä»»åŠ¡ã€‚</p><p>For performance reasons, the set of entities used to corrupt the positive edges in order to produce the negative samples may be shared across several positive edges. The way this usually happens is that positive edges are split into â€œchunksâ€, a single set of entities is sampled for each chunk, and all edges in that chunk are corrupted using that set of entities.<br>å‡ºäºæ€§èƒ½åŸå› ï¼Œå¯ç”¨äºç ´åæ­£è¾¹ä»¥ç”Ÿæˆè´Ÿæ ·æœ¬çš„å®ä½“é›†å¯åœ¨å¤šä¸ªæ­£è¾¹ä¹‹é—´å…±äº«ã€‚è¿™ç§æƒ…å†µé€šå¸¸å‘ç”Ÿçš„æ–¹å¼æ˜¯ï¼Œå°†æ­£è¾¹åˆ†æˆâ€œå—â€ï¼Œä¸ºæ¯ä¸ªå—é‡‡æ ·ä¸€ç»„å®ä½“ï¼Œç„¶åä½¿ç”¨è¿™æ ·ä¸€ç»„å®ä½“æ¥ä½œç”¨åˆ°è¿™ä¸ªå—ä¸­çš„æ‰€æœ‰è¾¹æ¥å®Œæˆè´Ÿé‡‡æ ·ã€‚</p><p>PBG supports several ways of sampling negatives:<br>PBGæ”¯æŒå¤šç§è´Ÿé‡‡æ ·ï¼š</p><h3 id="All-negatives"><a href="#All-negatives" class="headerlink" title="All negatives"></a>All negatives</h3><p>The most straightforward way is to use, for each positive edge, all its possible negatives. What this means is that for a positive (ğ‘¥,ğ‘Ÿ,ğ‘¦) (where ğ‘¥ and ğ‘¦ are the left- and right-hand side negatives respectively and ğ‘Ÿ is the relation type), its negatives will be (ğ‘¥â€²,ğ‘Ÿ,ğ‘¦) for all ğ‘¥â€² of the same entity type as ğ‘¥ and (ğ‘¥,ğ‘Ÿ,ğ‘¦â€²) for ğ‘¦â€² of the same entity type as ğ‘¦. (Due to technical reasons this is in fact restricted to only the ğ‘¥â€² in the same partition as ğ‘¥, and similarly for ğ‘¦â€², as negative sampling always operates within the current bucket.)<br>æœ€ç›´æ¥çš„æ–¹å¼æ˜¯å¯¹æ¯ä¸ªæ­£è¾¹å¾—åˆ°æ‰€æœ‰å¯èƒ½çš„è´Ÿè¾¹ã€‚  è¿™æ„å‘³ç€å¯¹äºä¸€ä¸ªæ­£è¾¹ï¼ˆğ‘¥ï¼Œğ‘Ÿï¼Œğ‘¦ï¼‰ï¼Œå®ƒçš„è´Ÿè¾¹ä¸ºï¼ˆğ‘¥â€™ï¼Œğ‘Ÿï¼Œğ‘¦ ï¼‰è¡¨ç¤ºä¸ğ‘¥å…·æœ‰ç›¸åŒå®ä½“ç±»å‹çš„æ‰€æœ‰ğ‘¥â€™ä»¥åŠï¼ˆğ‘¥ï¼Œğ‘Ÿï¼Œğ‘¦â€™ï¼‰è¡¨ç¤ºä¸ğ‘¦å…·æœ‰ç›¸åŒå®ä½“ç±»å‹çš„æ‰€æœ‰ğ‘¦â€™ã€‚ï¼ˆå‡ºäºæŠ€æœ¯åŸå› ï¼Œä¸€èˆ¬å°±ä¸€ç§ï¼Œè¦ä¸å°±xâ€™,è¦ä¸å°±yâ€˜ï¼‰</p><p>As one can imagine, this method generates a lot of negatives and thus doesnâ€™t scale to graphs of any significant size. It should not be used in practice, and is provided in PBG mainly for â€œacademicâ€ reasons. It is mainly useful to get more accurate results during evaluation on small graphs.<br>å¯ä»¥è®¾æƒ³ï¼Œè¿™ç§æ–¹æ³•ä¼šäº§ç”Ÿå¾ˆå¤šè´Ÿæ ·æœ¬ï¼Œå› æ­¤æ— æ³•é€‚ç”¨äºä»»ä½•å¤§å°çš„å›¾å½¢ã€‚å› æ­¤ä¸åº”åœ¨å®è·µä¸­ä½¿ç”¨å®ƒï¼Œè€Œåœ¨PBGä¸­æä¾›å®ƒä¸»è¦æ˜¯å‡ºäºâ€œå­¦æœ¯â€åŸå› ã€‚ èµ·ä½œç”¨ä¸»è¦æ˜¯åœ¨å°å›¾ä¸Šè¿›è¡Œè¯„ä¼°æ—¶è·å¾—æ›´å‡†ç¡®çš„ç»“æœã€‚</p><p>This method is activated on a per-relation basis, by turning on the all_negs config flag. When itâ€™s enabled, this mode takes precedence and overrides any other mode.<br>é€šè¿‡æ‰“å¼€all_negs configæ ‡å¿—ï¼Œå°†åŸºäºæ¯ä¸ªå…³ç³»æ¿€æ´»æ­¤æ–¹æ³•ã€‚ å¯ç”¨åï¼Œæ­¤æ¨¡å¼å°†ä¼˜å…ˆå¹¶è¦†ç›–å…¶ä»–ä»»ä½•æ¨¡å¼ã€‚</p><h3 id="Same-batch-negatives"><a href="#Same-batch-negatives" class="headerlink" title="Same-batch negatives"></a>Same-batch negatives</h3><p>This negative sampling method produces negatives for a given positive edge of a batch by sampling from the other edges of the same batch. This is done by first splitting the batch into so-called chunks (beware that the name â€œchunksâ€ is overloaded, and these chunks are different than the edge chunks explained in Batch preparation). Then the set of negatives for a positive edge (ğ‘¥,ğ‘Ÿ,ğ‘¦) contains the edges (ğ‘¥â€²,ğ‘Ÿ,ğ‘¦) for all entities ğ‘¥â€² that are on left-hand side of another edge in the chunk, and the edges (ğ‘¥,ğ‘Ÿ,ğ‘¦â€²) with ğ‘¦â€² satisfying the same condition for the right-hand side.<br>é€šè¿‡ä»åŒä¸€æ‰¹æ¬¡çš„å…¶ä»–è¾¹è¿›è¡Œé‡‡æ ·ï¼Œæ­¤è´Ÿé‡‡æ ·æ–¹æ³•å¯ä¸ºæ‰¹æ¬¡çš„ç»™å®šæ­£è¾¹ç”Ÿæˆè´Ÿæ ·æœ¬ã€‚è¿™æ˜¯é€šè¿‡é¦–å…ˆå°†æ‰¹å¤„ç†æ‹†åˆ†ä¸ºæ‰€è°“çš„å—æ¥å®Œæˆçš„ï¼ˆè¯·æ³¨æ„ï¼Œâ€œå—â€çš„åç§°å·²è¶…è½½ï¼ˆæœ‰å¤šé‡æ„æ€ï¼‰ï¼Œå¹¶ä¸”è¿™äº›å—ä¸â€œæ‰¹å¤„ç†â€ä¸­ä»‹ç»çš„è¾¹ç¼˜å—ä¸åŒï¼‰ï¼Œç„¶åï¼Œä¸€ä¸ªæ­£è¾¹ï¼ˆğ‘¥ï¼Œğ‘Ÿï¼Œğ‘¦ï¼‰å¾—åˆ°çš„è´Ÿæ ·æœ¬ä¸ºï¼Œè¿™ä¸ªå—ä¸­çš„ç¬¦åˆæ¡ä»¶çš„(ğ‘¥â€²,ğ‘Ÿ,ğ‘¦)ä»¥åŠ(ğ‘¥,ğ‘Ÿ,ğ‘¦â€²)ã€‚</p><p>For a single positive edge, this means that the entities used to construct its negatives are sampled from the current partition proportionally to their degree, a.k.a., according to the data distribution. This helps counteract the effects of a very skewed distribution of degrees, which might cause the embeddings to just capture that distribution.<br>å¯¹äºä¸€ä¸ªæ­£è¾¹æ¥è¯´ï¼Œæ ¹æ®å…¶ç”Ÿæˆçš„è´Ÿè¾¹çš„å®ä½“æ¥æºäºå½“å‰çš„åˆ†åŒºï¼Œå¹¶æ ¹æ®æ•°æ®çš„åˆ†å¸ƒæ¥æŒ‰æ¯”ä¾‹ç”Ÿæˆçš„ã€‚è¿™æœ‰åŠ©äºæŠµæ¶ˆåº¦çš„éå¸¸åæ–œçš„åˆ†å¸ƒçš„å½±å“ï¼Œå¯ä»¥å®ç°åµŒå…¥æ°å¥½æ•è·è¯¥åˆ†å¸ƒã€‚</p><p>The size of the chunks is controlled by the global num_batch_negs parameter. To disable this sampling mode, set that parameter to zero.<br>å—çš„å¤§å°ç”±å…¨å±€num_batch_negså‚æ•°æ§åˆ¶ã€‚ è¦ç¦ç”¨æ­¤é‡‡æ ·æ¨¡å¼ï¼Œè¯·å°†è¯¥å‚æ•°è®¾ç½®ä¸ºé›¶ã€‚</p><h3 id="Uniformly-sampled-negatives"><a href="#Uniformly-sampled-negatives" class="headerlink" title="Uniformly-sampled negatives"></a>Uniformly-sampled negatives</h3><p>This last method is perhaps the most natural approximation of the â€œall negativesâ€ method that scales to arbitrarily large graphs. Instead of using all the entities on either side to produce negative edges (thus having the number of negatives scale linearly withe the size of the graph), a fixed given number of these entities is sampled uniformly with replacement. Thus the set of negatives remains of constant size no matter how large the graph is. As with the â€œall negativesâ€ method, the sampling here is restricted to the entities that have the same type and that belong to the same partition as the entity of the positive edge.<br>æœ€åä¸€ç§æ–¹æ³•ä¸â€œå…¨è´Ÿæ ·æœ¬â€çš„æ–¹æ³•ç±»ä¼¼ï¼Œä½†æ˜¯è¯¥æ–¹æ³•å¯é€‚ç”¨äºåˆ°ä»»æ„å¤§å›¾ã€‚è¯¥æ–¹æ³•å¯¹å›ºå®šæ•°é‡çš„è¿™äº›å®ä½“è¿›è¡Œå‡åŒ€é‡‡æ ·å¹¶æ›¿æ¢è€Œä¸æ˜¯åƒâ€œå…¨è´Ÿæ ·æœ¬â€ä¸€æ ·å®Œå…¨ç”Ÿæˆè´Ÿæ ·æœ¬ï¼ˆè´Ÿè¾¹çš„æ•°é‡ä¸å›¾çš„å¤§å°æˆçº¿æ€§æ¯”ä¾‹ï¼‰ã€‚å› æ­¤æ— è®ºå›¾å½¢æœ‰å¤šå¤§ï¼Œè´Ÿæ ·æœ¬æ•°ç›®ä¿æŒæ’å®šå¤§å°ã€‚ ä¸â€œå…¨è´Ÿæ ·æœ¬â€æ–¹æ³•ä¸€æ ·ï¼Œæ­¤å¤„çš„é‡‡æ ·ä»…é™äºå…·æœ‰ç›¸åŒç±»å‹ä¸”ä¸æ­£è¾¹å®ä½“å±äºåŒä¸€åˆ†åŒºçš„å®ä½“ã€‚</p><p>This method interacts with the same-batch method, as all the edges in a chunk receive the same set of uniformly sampled negatives. This caveat means that the uniform negatives of two different positives are independent and uncorrelated only if they belong to different chunks.<br>è¯¥æ–¹æ³•ä¸same-batchæ–¹æ³•ç›¸äº’å½±å“ï¼Œå› ä¸ºå—ä¸­çš„æ‰€æœ‰è¾¹éƒ½æ¥æ”¶åŒä¸€ç»„å‡åŒ€é‡‡æ ·çš„è´Ÿæ ·æœ¬ã€‚è¿™è¡¨æ˜äº†ä¸¤ä¸ªæ­£è¾¹ç”Ÿæˆçš„è´Ÿæ ·æœ¬åªæœ‰åœ¨å…¶å±äºä¸åŒç»„å—æ—¶æ‰æ˜¯ç‹¬ç«‹ä¸”ä¸ç›¸å…³çš„ã€‚</p><p>This method is controlled by the num_uniform_negs parameter, which controls how many negatives are sampled for each chunk. If num_batch_negs is zero, the batches will be split into chunks of size num_uniform_negs.<br>æ­¤æ–¹æ³•ç”±num_uniform_negså‚æ•°æ§åˆ¶ï¼Œè¯¥å‚æ•°æ§åˆ¶ä¸ºæ¯ä¸ªå—é‡‡æ ·å¤šå°‘ä¸ªè´Ÿè¾¹ã€‚ å¦‚æœnum_batch_negsä¸ºé›¶ï¼Œåˆ™å°†æ‰¹æ¬¡æ‹†åˆ†ä¸ºnum_uniform_negså¤§å°çš„å—ã€‚</p><blockquote><p>ğŸ¤” éœ€è¦å†ç¢ç£¨ç¢ç£¨</p></blockquote><h2 id="Loss-functions"><a href="#Loss-functions" class="headerlink" title="Loss functions"></a>Loss functions</h2><p>Once positive and negative samples have been determined and their scores have been computed by the model, the scoresâ€™ suitability for a certain application must be assessed, which is done by aggregating them into a single real value, the loss. What loss function is most appropriate depends on what operations the embeddings will be used for.<br>ä¸€æ—¦ç¡®å®šäº†æ­£è´Ÿæ ·æœ¬å¹¶é€šè¿‡æ¨¡å‹è®¡ç®—äº†å®ƒä»¬çš„å¾—åˆ†ï¼Œå°±å¿…é¡»è¯„ä¼°å¾—åˆ†å¯¹ç‰¹å®šåº”ç”¨ç¨‹åºçš„é€‚ç”¨æ€§ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œå°†è¿™äº›å¾—åˆ†æ±‡æ€»ä¸ºä¸€ä¸ªå®é™…å€¼å³æŸå¤±ã€‚ å“ªç§æŸå¤±å‡½æ•°æœ€åˆé€‚å–å†³äºåµŒå…¥ä¹‹åçš„çš„åº”ç”¨åœºæ™¯ã€‚</p><p>In all cases, the loss functionâ€™s input will be a series of scores for positive samples and, for each of them, a set of scores for corresponding negative samples. For simplicity, suppose all these sets are of the same size (if they are not, they can be padded with â€œnegative infinityâ€ values, as these are the â€œidealâ€ scores for negative edges and should thus induce no loss).<br>åœ¨æ‰€æœ‰æƒ…å†µä¸‹ï¼ŒæŸå¤±å‡½æ•°çš„è¾“å…¥å°†æ˜¯ä¸€ç³»åˆ—æ­£æ ·æœ¬çš„å¾—åˆ†ï¼Œå¯¹äºæ¯ä¸ªæ­£æ ·æœ¬ï¼Œä¼šæœ‰ä¸€ç»„æ˜¯å…¶å¯¹åº”è´Ÿæ ·æœ¬çš„å¾—åˆ†ã€‚ ä¸ºç®€å•èµ·è§ï¼Œå‡è®¾æ‰€æœ‰è¿™äº›é›†åˆçš„å¤§å°éƒ½ç›¸åŒï¼ˆå¦‚æœä¸æ˜¯ï¼Œåˆ™å¯ä»¥ç”¨â€œè´Ÿæ— ç©·å¤§â€å€¼å¡«å……ï¼Œå› ä¸ºè¿™äº›æ˜¯è´Ÿè¾¹çš„â€œç†æƒ³â€åˆ†æ•°ï¼Œå› æ­¤ä¸åº”å¼•èµ·ä»»ä½•æŸå¤±ï¼‰ã€‚</p><h3 id="Ranking-loss"><a href="#Ranking-loss" class="headerlink" title="Ranking loss"></a>Ranking loss</h3><p>The ranking loss compares each positive score with each of its corresponding negatives. For each such pair, no loss is introduced if the positive score is greater than the negative one by at least a given margin. Otherwise the incurred loss is the amount by which that inequality is violated. This is the hinge loss on the difference between the positive and negative score. Formally, for a margin ğ‘š, a positive score ğ‘ ğ‘– and a negative score ğ‘¡ğ‘–,ğ‘—, the loss is max(0,ğ‘šâˆ’ğ‘ ğ‘–+ğ‘¡ğ‘–,ğ‘—). The total loss is the sum of the losses over all pairs of positive and negative scores, i.e., over all ğ‘– and ğ‘—.<br>æ’åæŸå¤±å°†æ¯ä¸ªæ­£å¾—åˆ†ä¸å…¶å¯¹åº”çš„è´Ÿå¾—åˆ†è¿›è¡Œæ¯”è¾ƒã€‚å¯¹äºæ¯ä¸€ä¸ªè¿™æ ·çš„é…å¯¹ï¼Œå¦‚æœæ­£å€¼è‡³å°‘æ¯”è´Ÿå€¼å¤§ä¸€ä¸ªç»™å®šçš„ä½™é‡ï¼Œåˆ™ä¸ä¼šé€ æˆä»»ä½•æŸå¤±ï¼Œå¦åˆ™ï¼Œå…¶è´¡çŒ®çš„æŸå¤±ä¸ºè¶…è¿‡çš„å€¼ã€‚è¿™å…¶å®æ˜¯ä¸€ç§æ­£è´Ÿå¾—åˆ†å·®çš„hinge lossã€‚å½¢å¼ä¸Šï¼Œå¯¹äºä½™é‡ğ‘šï¼Œæ­£åˆ†æ•°ğ‘ ğ‘–å’Œè´Ÿåˆ†æ•°ğ‘¡ğ‘–ğ‘—ï¼ŒæŸå¤±ä¸ºmaxï¼ˆ0ï¼Œğ‘š-ğ‘ ğ‘–+ğ‘¡ğ‘–ğ‘—ï¼‰ã€‚æ€»æŸå¤±æ˜¯æ‰€æœ‰æ­£è´Ÿåˆ†æ•°å¯¹ï¼ˆå³æ‰€æœ‰ğ‘–å’Œğ‘—ï¼‰çš„æŸå¤±æ€»å’Œã€‚</p><p>This loss function is chosen by setting the loss_fn parameter to ranking, and the target margin is specified by the margin parameter.<br>é€šè¿‡å°†loss_fnå‚æ•°è®¾ç½®ä¸ºç­‰çº§æ¥é€‰æ‹©æ­¤æŸå¤±å‡½æ•°ï¼Œå¹¶ä¸”marginå‚æ•°æŒ‡å®šä½™é‡çš„å¤§å°ã€‚</p><p>This loss function is suitable when the setting requires to rank some entities by how likely they are to be related to another given entity.<br>å½“è®¾ç½®éœ€è¦æ ¹æ®æŸäº›å®ä½“ä¸å¦ä¸€ä¸ªç»™å®šå®ä½“ç›¸å…³çš„å¯èƒ½æ€§æ¥å¯¹æŸäº›å®ä½“è¿›è¡Œæ’åæ—¶ï¼Œæ­¤æŸå¤±å‡½æ•°é€‚ç”¨ã€‚</p><h3 id="Logistic-loss"><a href="#Logistic-loss" class="headerlink" title="Logistic loss"></a>Logistic loss</h3><p>The logistic loss instead interprets the scores as the probabilities that the edges exist. It does so by first passing each score (whose domain is the entire real line) through the logistic function (ğ‘¥â†¦1/(1+ğ‘’âˆ’ğ‘¥), which maps it to a value between 0 and 1). This value is taken as the probability ğ‘ and the loss will be its binary cross entropy with the â€œtargetâ€ probability, i.e., 1 for positive edges and 0 for negative ones. In formulas, the loss for positives is âˆ’logğ‘ whereas for negatives itâ€™s âˆ’log(1âˆ’ğ‘). The total loss of due to the negatives is renormalized so it compares with the one of the positives.<br>é€»è¾‘æŸå¤±å°†åˆ†æ•°è§£é‡Šä¸ºè¾¹å­˜åœ¨çš„æ¦‚ç‡ã€‚é¦–å…ˆè¦é€šè¿‡é€»è¾‘å‡½æ•°ï¼ˆğ‘¥â†¦1/ï¼ˆ1 + ğ‘’âˆ’ğ‘¥ï¼‰ï¼Œå°†å…¶æ˜ å°„åˆ°0åˆ°1ä¹‹é—´çš„å€¼ï¼‰ä¼ é€’æ¯ä¸ªå¾—åˆ†ï¼ˆå…¶åŸŸæ˜¯æ•´ä¸ªå®çº¿ï¼‰ã€‚ å°†è¯¥å€¼ä½œä¸ºæ¦‚ç‡ğ‘ï¼Œå¹¶ä¸”æŸå¤±å°†æ˜¯å…·æœ‰â€œç›®æ ‡â€æ¦‚ç‡çš„äºŒè¿›åˆ¶äº¤å‰ç†µã€‚æ­£è¾¹ä¸º1ï¼Œè´Ÿè¾¹ä¸º0ã€‚ åœ¨å…¬å¼ä¸­ï¼Œæ­£å€¼çš„æŸå¤±ä¸º-logğ‘ï¼Œè´Ÿæ•°çš„æŸå¤±ä¸º-logï¼ˆ1-ğ‘)ã€‚ ç”±äºè´Ÿæ•°å¯¼è‡´çš„æ€»æŸå¤±è¢«é‡æ–°å½’ä¸€åŒ–ï¼Œå› æ­¤å¯ä»¥ä¸æ­£æ•°ä¹‹ä¸€è¿›è¡Œæ¯”è¾ƒã€‚</p><p>One can see this as the cross entropy between two distributions on the values â€œedge existsâ€ and â€œedge doesnâ€™t existâ€. One is given by the score (passed through the logistic function), the other has all the mass on â€œexistsâ€ for positives or all the mass on â€œdoesnâ€™t existâ€ for negatives.<br>é€šè¿‡ä½¿ç”¨äº¤å‰ç†µï¼Œå¯ä»¥å¾—åˆ°è¾¹æ˜¯å¦å­˜åœ¨çš„åˆ†å¸ƒã€‚ä¸€ä¸ªç”±å¾—åˆ†ï¼ˆé€šè¿‡é€»è¾‘å‡½æ•°ä¼ é€’ï¼‰ç»™å‡ºï¼Œå¦ä¸€ä¸ªç”±é˜³æ€§å­˜åœ¨çš„â€œå­˜åœ¨â€ä»£è¡¨æ‰€æœ‰å¦å®šï¼Œæˆ–ç”±è´Ÿå­˜åœ¨æ‰€æœ‰è´¨é‡çš„â€œä¸å­˜åœ¨â€ä»£è¡¨ã€‚</p><p>This loss function is parameterless and is enabled by setting loss_fn to logistic.<br>æ­¤æŸå¤±å‡½æ•°æ˜¯æ— å‚çš„ï¼Œå¯ä»¥é€šè¿‡å°†loss_fnè®¾ç½®ä¸ºlogisticæ¥å¯ç”¨ã€‚</p><h3 id="Softmax-loss"><a href="#Softmax-loss" class="headerlink" title="Softmax loss"></a>Softmax loss</h3><p>The last loss function is designed for when one wants a distribution on the probabilities of some entities being related to a given entity (contrary to just wanting a ranking, as with the ranking loss). For a certain positive ğ‘–, its score ğ‘ ğ‘– and the score ğ‘¡ğ‘–,ğ‘— of all the corresponding negatives ğ‘— are first converted to probabilities by performing a softmax: ğ‘ğ‘–âˆğ‘’ğ‘ ğ‘– and ğ‘ğ‘–,ğ‘—âˆğ‘’ğ‘¡ğ‘–,ğ‘—, normalized so that they sum up to 1. Then the loss is the cross entropy between this distribution and the â€œtargetâ€ one, i.e., the one that puts all the mass on the positive sample. So, in full, the loss for a single ğ‘– is âˆ’logğ‘ğ‘–, i.e., âˆ’ğ‘ ğ‘–+logâˆ‘ğ‘—ğ‘’ğ‘¡ğ‘–,ğ‘—.<br>æœ€åä¸€ä¸ªæŸå¤±å‡½æ•°è®¾è®¡ç”¨äºå½“äººä»¬å¸Œæœ›é€šè¿‡ç»™å®šä¸€ä¸ªå®ä½“ï¼Œå¾—åˆ°å…¶ä»–å®ä½“å’Œå…¶ç›¸å…³æ€§çš„æ¦‚ç‡çš„åœºæ™¯ã€‚ï¼ˆä¸ä»…éœ€è¦æ’åï¼Œä¸æ’åæŸå¤±ç›¸åï¼‰ã€‚å¯¹äºæŸä¸ªæ­£ä¾‹ğ‘–ï¼Œé¦–å…ˆé€šè¿‡æ‰§è¡Œsoftmaxï¼šğ‘ğ‘–âˆğ‘’ğ‘ ğ‘–å’Œğ‘ğ‘–ï¼Œğ‘—âˆğ‘’ğ‘¡ğ‘–ï¼Œğ‘—è¿›è¡Œå½’ä¸€åŒ–ï¼Œä½¿å¾—æ¦‚ç‡å’Œä¸º1ã€‚æ­¤æ—¶æŸå¤±å°±æ˜¯è¿™ç§åˆ†å¸ƒä¸â€œç›®æ ‡â€åˆ†å¸ƒä¹‹é—´çš„äº¤å‰ç†µã€‚å³å°†æ‰€æœ‰è´¨é‡ç½®äºæ­£æ ·æœ¬ä¸Šçš„äº¤å‰ç†µã€‚ å› æ­¤ï¼Œæ€»çš„æ¥è¯´ï¼Œå•ä¸ªğ‘–çš„æŸå¤±ä¸º-logğ‘ğ‘–ï¼Œå³-ğ‘ ğ‘–+ logâˆ‘ğ‘—ğ‘’ğ‘¡ğ‘–ï¼Œğ‘—ã€‚</p><p>This loss is activated by setting loss_fn to softmax.<br>é€šè¿‡åœ¨é…ç½®å‚æ•°ä¸­è®¾ç½®loss_fn=softmaxæ¥å®ç°é…ç½®ã€‚</p><h2 id="Optimizers"><a href="#Optimizers" class="headerlink" title="Optimizers"></a>Optimizers</h2><p>The Adagrad optimization method is used to update all model parameters. Adagrad performs stochastic gradient descent with an adaptive learning rate applied to each parameter inversely proportional to the inverse square magnitude of all previous updates. In practice, Adagrad updates lead to an order of magnitude faster convergence for typical PBG models.</p><p>Adagradä¼˜åŒ–æ–¹æ³•ç”¨äºæ›´æ–°æ‰€æœ‰æ¨¡å‹å‚æ•°ã€‚Adagradä½¿ç”¨ä¸æ‰€æœ‰å…ˆå‰æ›´æ–°çš„å¹³æ–¹åæ¯”æˆåæ¯”çš„è‡ªé€‚åº”å­¦ä¹ ç‡ï¼Œä»¥è‡ªé€‚åº”å­¦ä¹ ç‡æ‰§è¡Œéšæœºæ¢¯åº¦ä¸‹é™ã€‚ å®é™…ä¸Šï¼ŒAdagradæ›´æ–°ä½¿å…¸å‹PBGæ¨¡å‹çš„æ”¶æ•›é€Ÿåº¦æé«˜äº†ä¸€ä¸ªæ•°é‡çº§ã€‚</p><p>The initial learning rate for Adagrad is specified by the lr config parameter.A separate learning rate can also be set for non-embeddings using the relation_lr parameter.<br>Adagradçš„åˆå§‹å­¦ä¹ ç‡ç”±configæ–‡ä»¶é‡Œçš„lrå‚æ•°æŒ‡å®šã€‚è¿˜å¯ä»¥ä½¿ç”¨related_lrå‚æ•°ä¸ºéåµŒå…¥è®¾ç½®å•ç‹¬çš„å­¦ä¹ ç‡ã€‚</p><p>Standard Adagrad requires an equal amount of memory for optimizer state as the size of the model, which is prohibitive for the large models targeted by PBG. To reduce optimizer memory usage, a modified version of Adagrad is used that uses a common learning rate for each entity embedding. The learning rate is proportional to the inverse sum of the squared gradients from each element of the embedding, divided by the dimension. Non-embedding parameters (e.g. relation operator parameters) use standard Adagrad.<br>æ ‡å‡†Adagradè¦æ±‚ä¼˜åŒ–ç¨‹åºçŠ¶æ€çš„å†…å­˜é‡ä¸æ¨¡å‹å¤§å°ç›¸åŒï¼Œè¿™å¯¹äºPBGå®šä½çš„å¤§å‹æ¨¡å‹æ˜¯ä¸å…è®¸çš„ã€‚ä¸ºäº†å‡å°‘ä¼˜åŒ–å™¨çš„å†…å­˜ä½¿ç”¨ï¼Œä½¿ç”¨äº†Adagradçš„ä¿®æ”¹ç‰ˆæœ¬ï¼Œè¯¥ç‰ˆæœ¬å¯¹æ¯ä¸ªå®ä½“åµŒå…¥ä½¿ç”¨é€šç”¨çš„å­¦ä¹ ç‡ã€‚å­¦ä¹ ç‡ä¸åµŒå…¥å…ƒç´ çš„æ¢¯åº¦å¹³æ–¹çš„å€’æ•°ä¹‹å’Œæˆæ¯”ä¾‹ï¼Œå†é™¤ä»¥å°ºå¯¸ã€‚ éåµŒå…¥å‚æ•°ï¼ˆä¾‹å¦‚å…³ç³»è¿ç®—ç¬¦å‚æ•°ï¼‰ä½¿ç”¨æ ‡å‡†Adagradã€‚</p><p>Adagrad parameters are updated asynchronously across worker threads with no explicit synchronization. Asynchronous updates to the Adagrad state (the total squared gradient) appear stable, likely because each element of the state tensor only accumulates positives updates. Optimization is further stabilized by performing a short period of training with a single thread before beginning Hogwild! training, which is tuned by the hogwild_delay parameter.<br>Adagradå‚æ•°åœ¨å·¥ä½œçº¿ç¨‹ä¹‹é—´å¼‚æ­¥æ›´æ–°ï¼Œè€Œæ²¡æœ‰æ˜¾å¼åŒæ­¥ã€‚å¼‚æ­¥æ›´æ–°ä½¿å¾—AdagradçŠ¶æ€(æ€»å¹³æ–¹æ¢¯åº¦)çš„æ›´æ–°æ˜¾å¾—ç¨³å®š,è¿™å¯èƒ½æ˜¯å› ä¸ºçŠ¶æ€å¼ é‡çš„æ¯ä¸ªå…ƒç´ ä»…ç´¯ç§¯æ­£æ›´æ–°ã€‚åœ¨å¼€å§‹Hogwildä¹‹å‰ï¼Œå¯ä»¥é€šè¿‡å•çº¿ç¨‹è¿›è¡ŒçŸ­æœŸåŸ¹è®­æ¥è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚ åŸ¹è®­ï¼Œå…·ä½“å–å†³äºhogwild_delayå‚æ•°ã€‚</p><p>In distributed training, the Adagrad state for shared parameters (e.g. relation operator parameters) are shared via the parameter server using the same asynchronous gradient update as the parameters themselves. Similar to inter-thread synchronization, these asynchronous updates are stable after an initial burn-in period because the total squared gradient strictly accumulates positive values.<br>åˆ†å¸ƒå¼è®­ç»ƒä¸­ï¼Œå…±äº«å‚æ•°ï¼ˆä¾‹å¦‚å…³ç³»è¿ç®—ç¬¦å‚æ•°ï¼‰çš„AdagradçŠ¶æ€é€šè¿‡å‚æ•°æœåŠ¡å™¨ä½¿ç”¨ä¸å‚æ•°æœ¬èº«ç›¸åŒçš„å¼‚æ­¥æ¢¯åº¦æ›´æ–°è¿›è¡Œå…±äº«ã€‚ä¸çº¿ç¨‹é—´åŒæ­¥ç±»ä¼¼ï¼Œè¿™äº›å¼‚æ­¥æ›´æ–°åœ¨åˆå§‹é˜¶æ®µä¼šä¸ç¨³å®šï¼Œä¹‹åä¼šä¿æŒç¨³å®šï¼Œå› ä¸ºæ€»å¹³æ–¹æ¢¯åº¦ä¸¥æ ¼ç´¯åŠ æ­£å€¼ã€‚</p><blockquote><p>ğŸ¤” </p></blockquote><p>æºåœ°å€ï¼š<a href="https://torchbiggraph.readthedocs.io/en/latest/loss_optimization.html">https://torchbiggraph.readthedocs.io/en/latest/loss_optimization.html</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>PyTorch-BigGraph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch-BigGraph åˆ†å¸ƒå¼</title>
    <link href="/2020/10/28/PBG-Distributed-mode/"/>
    <url>/2020/10/28/PBG-Distributed-mode/</url>
    
    <content type="html"><![CDATA[<h1 id="PyTorch-BigGraph-åˆ†å¸ƒå¼"><a href="#PyTorch-BigGraph-åˆ†å¸ƒå¼" class="headerlink" title="PyTorch-BigGraph åˆ†å¸ƒå¼"></a>PyTorch-BigGraph åˆ†å¸ƒå¼</h1><p>PBG can perform training across multiple machines which communicate over a network, in order to reduce training time on large graphs. Distributed training is able to concurrently utilize larger computing resources, as well as to keep the entire model stored in memory across all machines, avoiding the need to swap it to disk. On each machine, the training is further parallelized across multiple subprocesses.<br>PBGå¯ä»¥åœ¨é€šè¿‡ç½‘ç»œè¿›è¡Œé€šä¿¡çš„å¤šå°æœºå™¨ä¸Šæ‰§è¡Œè®­ç»ƒï¼Œä»¥å‡å°‘å¤§å›¾ä¸Šçš„è®­ç»ƒæ—¶é—´ã€‚åˆ†å¸ƒå¼è®­ç»ƒèƒ½å¤Ÿåˆ©ç”¨å·¨å¤§çš„è®¡ç®—èµ„æºï¼ŒåŒæ—¶å…¶å¯ä»¥å°†æ•´ä¸ªæ¨¡å‹å­˜å‚¨åœ¨æ‰€æœ‰æœºå™¨çš„å†…å­˜ä¸­è€Œä¸éœ€è¦è¿›è¡Œç£ç›˜äº¤æ¢ã€‚åœ¨æ¯ä¸€å°æœºå™¨ä¸Šï¼Œè®­ç»ƒé€šè¿‡å¤šä¸ªå­è¿›ç¨‹è¿›è¡Œã€‚</p><h2 id="Set-up"><a href="#Set-up" class="headerlink" title="Set up"></a>Set up</h2><p>In order to perform distributed training, the configuration file must first be updated to contain the specification of the desired distributed setup. If training should be carried out on ğ‘ machines, then the num_machines key in the config must be set to that value. In addition, the distributed_init_method must describe a way for the trainers to discover each other and set up their communication. All valid values for the init_method argument of torch.distributed.init_process_group() are accepted here. Usually this will be a path to a shared network filesystem or the network address of one of the machines. See the PyTorch docs for more information and a complete reference.<br>ä¸ºäº†æ‰§è¡Œåˆ†å¸ƒå¼è®­ç»ƒï¼Œé…ç½®æ–‡ä»¶å¿…é¡»é¦–å…ˆè¿›è¡Œç›¸åº”é…ç½®ï¼Œå…¶éœ€è¦åŒ…æ‹¬åˆ†å¸ƒå¼éƒ¨ç½²çš„ç›¸å…³é…ç½®ã€‚å¦‚æœè®­ç»ƒåœ¨Nå°æœºå™¨ä¸Šè¿è¡Œï¼Œnum_machineså¿…é¡»è¦è¦é…ç½®æˆNã€‚å¦å¤–ï¼Œdistributed_init_methodå¿…é¡»æè¿°å„ä¸ªæœºå™¨ä¹‹é—´çš„é€šä¿¡æ–¹å¼ã€‚è¿™é‡Œèƒ½å¤Ÿæ¥å—æ‰€æœ‰torch.distributed.init_process_group()é‡Œé¢çš„å‚æ•°ã€‚é€šå¸¸æ¥è¯´ï¼Œåˆ†å¸ƒå¼è®­ç»ƒå°†ä¸€å°è®¡ç®—æœºçš„ç½‘ç»œåœ°å€è®¾ç½®ä¸ºæ–‡ä»¶å…±äº«ç³»ç»Ÿçš„åœ°å€ã€‚ æœ‰å…³æ›´å¤šä¿¡æ¯å’Œå®Œæ•´å‚è€ƒï¼Œè¯·å‚è§PyTorchæ–‡æ¡£ã€‚</p><p>To launch distributed training, call torchbiggraph_train â€“rank rank config.py on each machine, with rank replaced by an integer between 0 and ğ‘âˆ’1 (inclusive), different for each machine. Each machine must have PBG installed and have a copy of the config file.<br>è¦å¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒï¼Œé¦–å…ˆåœ¨æ¯å°æœºå™¨ä¸Šè°ƒç”¨torchbiggraph_train â€“rank rank config.pyï¼Œ å…¶ä¸­æ¯å°æœºå™¨æœ‰å„è‡ªçš„rankå€¼ï¼ˆä»1åˆ°N-1ï¼‰ã€‚æ¯å°æœºå™¨å¿…é¡»å®‰è£…äº†PBGï¼Œå¹¶ä¸”å…·æœ‰é…ç½®æ–‡ä»¶çš„å‰¯æœ¬ã€‚</p><p>In some uncommon circumstances, one may want to store the embeddings on different machines than the ones that are performing training. In that case, one would set num_partition_servers to a positive value and manually launch some instances of torchbiggraph_partitionserver as well. See below for more information on this.<br>ç‰¹å®šæƒ…å†µä¸‹ï¼Œå¯èƒ½æœ‰å°†åµŒå…¥å­˜å‚¨åœ¨ä¸åŒæœºå™¨è€Œä¸æ˜¯ä¸€å°æœºå™¨ä¸Šçš„éœ€æ±‚ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œéœ€è¦åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®num_partition_serversä¸ºä¸€ä¸ªæ­£æ•°å¹¶ä¸”æ‰‹åŠ¨ä½¿ç”¨torchbiggraph_partitionserveræ¥å¯åŠ¨ä¸€äº›å®ä¾‹ã€‚è¯¦æƒ…è§ä¸‹æ–‡</p><blockquote><p>Tip<br> A good default setting is to set num_machines to half the number of partitions (see below why) and leave num_partition_servers unset.<br> ä¸€ä¸ªå¥½çš„é»˜è®¤è®¾ç½®æ˜¯å°†num_machinesè®¾ç½®ä¸ºåˆ†åŒºæ•°çš„ä¸€åŠï¼ˆè¯·å‚é˜…ä¸‹é¢çš„åŸå› ï¼‰ï¼Œå¹¶ä¿æŒnum_partition_serversä¸ºæœªè®¾ç½®çŠ¶æ€ã€‚</p></blockquote><blockquote><p>Warning<br> Unpartitioned entity types should not be used with distributed training. While the embeddings of partitioned entity types are only in use on one machine at a time and are swapped between machines as needed, the embeddings of unpartitioned entity types are communicated asynchronously through a poorly-optimized parameter server which was designed for sharing relation parameters, which are small. It cannot support synchronizing large amounts of parameters, e.g. an unpartitioned entity type with more than 1000 entities. In that case, the quality of the unpartitioned embeddings will likely be very poor.<br> æœªåˆ†åŒºçš„å®ä½“ä¸åº”è¯¥è¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒã€‚å®ä½“ç±»å‹çš„åˆ†åŒºä»…åœ¨åŒä¸€æ—¶åˆ»åœ¨æŸä¸€å°æœºå™¨ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶ä¸”æ ¹æ®éœ€è¦åœ¨ä¸åŒæœºå™¨é—´è¿›è¡Œäº¤æ¢ã€‚æœªåˆ†åŒºçš„å®ä½“ç±»å‹çš„åµŒå…¥è®¡ç®—æ˜¯é€šè¿‡æ¬ ä¼˜åŒ–çš„å‚æ•°æœåŠ¡åœ¨æœºå™¨ä¹‹é—´è¿›è¡Œå¼‚æ­¥äº¤æ¢çš„ï¼Œè¿™ä¸ªæœåŠ¡åªæ˜¯è®¾è®¡æˆç”¨æ¥è¿›è¡Œå…³ç³»å‚æ•°çš„å…±äº«å¹¶ä¸”å¾ˆå°ã€‚å…¶ä¸èƒ½æ”¯æŒå¤§é‡å‚æ•°çš„åŒæ­¥ã€‚ä¾‹å¦‚ï¼šå¯¹äºä¸€ä¸ªæœªåˆ†åŒºçš„è¶…è¿‡1000ä¸ªå®ä½“çš„å®ä½“ç±»å‹ï¼Œåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæœªåˆ†åŒºçš„å¾—åˆ°çš„åµŒå…¥è´¨é‡ä¼šå¾ˆå·®ã€‚</p></blockquote><h2 id="Communication-protocols"><a href="#Communication-protocols" class="headerlink" title="Communication protocols"></a>Communication protocols</h2><p> Distributed training requires the machines to coordinate and communicate in various ways for different purposes. These tasks are:<br> åˆ†å¸ƒå¼è®­ç»ƒæ±‚æœºå™¨ä»¥å„ç§æ–¹å¼é’ˆå¯¹ä¸åŒç›®çš„è¿›è¡Œåè°ƒå’Œé€šä¿¡ã€‚ è¿™äº›ä»»åŠ¡æ˜¯ï¼š</p><p> â€¢ synchronizing which trainer is operating on which bucket, assigning them so that there are no conflicts<br> â€¢ passing the embeddings of an entity partition from one trainer to the next one when needed (as this is data that is only accessed by one trainer at a time)<br> â€¢ sharing parameters that all trainers need access to simultaneously, by collecting and redistributing the updates to them.</p><p> â€¢ åŒæ­¥å“ªä¸ªè®­ç»ƒå™¨åœ¨è®­ç»ƒå“ªä¸ªæ¡¶ï¼Œåˆ†é…å¥½ä»»åŠ¡ä»¥é˜²äº§ç”Ÿå†²çª<br> â€¢ å°†ä¸€ä¸ªå®ä½“åˆ†åŒºçš„åµŒå…¥ä»ä¸€ä¸ªè®­ç»ƒå™¨ä¼ å…¥åˆ°å¦ä¸€ä¸ªè®­ç»ƒå™¨ ï¼ˆå› ä¸ºä¸€ä¸ªè®­ç»ƒå™¨åªä½¿ç”¨ä¸€æ¬¡åœ¨ä¸€ä¸ªepochä¸­ï¼‰<br> â€¢ é€šè¿‡æ”¶é›†å’Œé‡æ–°åˆ†å‘å‚æ•°æ¥å®ç°å„ä¸ªè®­ç»ƒå™¨é—´çš„å‚æ•°å…±äº«</p><p> Each of these is implemented by a separate â€œprotocolâ€, and each trainer takes part in some or all of them by launching subprocesses that act as clients or servers for the different protocols. These protocols are explained below to provide insight into the system.</p><p> è¿™äº›ä¸­çš„æ¯ä¸€ä¸ªä»»åŠ¡éƒ½ç”±å•ç‹¬çš„â€œåè®®â€å®ç°ï¼Œå¹¶ä¸”æ¯ä¸ªè®­ç»ƒå™¨éƒ½é€šè¿‡å¯åŠ¨å……å½“é’ˆå¯¹ä¸åŒåè®®çš„å®¢æˆ·ç«¯æˆ–æœåŠ¡å™¨çš„å­è¿›ç¨‹æ¥å‚ä¸æ•´ä¸ªè¿‡ç¨‹çš„ä¸€éƒ¨åˆ†æˆ–å…¨éƒ¨ã€‚ä¸‹é¢è¯´æ˜è¿™äº›åè®®ä»¥æä¾›å¯¹ç³»ç»Ÿçš„äº†è§£ã€‚</p><h3 id="Synchronizing-bucket-access"><a href="#Synchronizing-bucket-access" class="headerlink" title="Synchronizing bucket access"></a>Synchronizing bucket access</h3><p>PBG parallelizes training across multiple machines by having them all operate simultaneously on disjoint buckets (i.e., buckets that donâ€™t have any partition in common). Therefore, each partition is in use by up to one machine at a time, and each machine uses up to two partitions (the only exception is for buckets â€œon the diagonalâ€, that have the same left- and right-hand side partition). This means that the number of buckets one can simultaneously train on is about half the total number of partitions.<br>PBGé€šè¿‡ä½¿å®ƒä»¬åŒæ—¶åœ¨ä¸ç›¸äº¤çš„å­˜å‚¨æ¡¶ï¼ˆå³æ²¡æœ‰å…±åŒåˆ†åŒºçš„å­˜å‚¨æ¡¶ï¼‰ä¸ŠåŒæ—¶è¿è¡Œæ¥å¹¶è¡ŒåŒ–å¤šå°æœºå™¨çš„åŸ¹è®­ã€‚ï¼ˆä¹Ÿå°±æ˜¯æ‰€è°“çš„æ•°æ®åˆ†åŒºï¼‰ã€‚å› æ­¤ï¼Œæ¯ä¸ªåˆ†åŒºä¸€æ¬¡æœ€å¤šåœ¨ä¸€å°æœºå™¨ä¸Šè¢«ä½¿ç”¨ï¼Œå¹¶ä¸”è¢«ä¸ªæœºå™¨ä¸€æ¬¡è®­ç»ƒæœ€å¤šç”¨ä¸¤ä¸ªåˆ†åŒºï¼ˆå”¯ä¸€çš„ä¾‹å¤–æ˜¯â€œå¯¹è§’çº¿â€ä¸Šçš„å­˜å‚¨æ¡¶ï¼Œå®ƒä»¬å…·æœ‰ç›¸åŒçš„å·¦ä¾§å’Œå³ä¾§åˆ†åŒºï¼‰ï¼‰ã€‚è¿™æ„å‘³åŒæ—¶å¯ä»¥è®­ç»ƒçš„æ¡¶çš„æ•°é‡å¤§æ¦‚æ˜¯ä¸€èˆ¬çš„åˆ†åŒºæ•°é‡ã€‚</p><p>The way the machines agree on which one gets to operate on what bucket is through a â€œlock serverâ€. The server is implicitly started by the trainer of rank 0. All other machines connect to it as clients, ask for a new bucket to operate on (when they need one), get a bucket assigned from the server (or none, if all buckets have already been trained on or are â€œlockedâ€ because their partitions are in use by another trainer), train on it, then report it as done and repeat. The lock server tries to optimize I/O by preferring, when a trainer asks for a bucket, to assign one that has as many partitions in common with the previous bucket that the trainer trained on, so that these partitions can be kept in memory rather than having to be unloaded and reloaded.<br>æœºå™¨é—´é€šè¿‡â€œé”æœåŠ¡â€çš„å½¢å¼æ¥è¡¨æ˜å“ªä¸ªæ¡¶æ­£åœ¨è¢«æ“ä½œã€‚æœåŠ¡å™¨ç”±çº§åˆ«0ï¼ˆmasterï¼‰çš„è®­ç»ƒå™¨éšå¼å¯åŠ¨ï¼Œæ‰€æœ‰å…¶ä»–æœºå™¨ä½œä¸ºå®¢æˆ·ç«¯è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œå½“å®ƒä»¬éœ€è¦æ–°çš„æ¡¶çš„æ—¶å€™ï¼Œä»–ä»¬å‘masterè¯·æ±‚å¹¶ä¸”å¾—åˆ°ä¸€ä¸ªæ–°çš„æ¡¶æ•°æ®ï¼ˆå¯èƒ½æ²¡æ‹¿åˆ°ï¼Œå› ä¸ºå¯èƒ½å­˜åœ¨æ‰€æœ‰çš„æ¡¶éƒ½è¢«è®­ç»ƒå®Œä¸€æ¬¡äº†æˆ–è€…æ¡¶æ˜¯é”ä½çš„çŠ¶æ€ï¼‰æ¥è¿›è¡Œè®­ç»ƒã€æŠ¥å‘Šç„¶åé‡å¤æ‰§è¡Œã€‚å½“ä¸€ä¸ªè®­ç»ƒå™¨è¯·æ±‚æ–°æ¡¶çš„æ—¶å€™ï¼Œé”å®šæœåŠ¡å™¨é€šè¿‡ä¼˜å…ˆåˆ†é…ä¸è¯¥è®­ç»ƒå™¨ä¸Šä¸€æ¬¡è®­ç»ƒçš„æ•°æ®æœ‰è¾ƒå¤šç›¸åŒåˆ†åŒºçš„æ¡¶æ¥ä¼˜åŒ–I/Oï¼Œé€šè¿‡è¿™æ ·é‚£äº›åˆ†åŒºå°±å¯ä»¥è¢«ä¿ç•™åœ¨å†…å­˜ä¸Šè€Œä¸æ˜¯è¢«å¸è½½ç„¶ååˆåŠ è½½ã€‚</p><h3 id="Exchanging-partition-embeddings"><a href="#Exchanging-partition-embeddings" class="headerlink" title="Exchanging partition embeddings"></a>Exchanging partition embeddings</h3><p>When a trainer starts operating on a bucket it needs access to the embeddings of all entities (of all types) that belong to either the left- or the right-hand side partition of the bucket. The â€œlockingâ€ mechanism of the lock server ensures that at most one trainer is operating on a partition at any given time. This doesnâ€™t hold for unpartitioned entity types, which are shared among all trainers; see below. Thus each trainer has exclusive hold of the partitions itâ€™s training on.<br>å½“ä¸€ä¸ªè®­ç»ƒå™¨å¼€å§‹åœ¨ä¸€ä¸ªæ¡¶ä¸Šæ‰§è¡Œè®­ç»ƒçš„æ—¶å€™ï¼Œä»–éœ€è¦è·å–é¦–å…ˆè·å–å±äºæ¡¶çš„å·¦ä¾§æˆ–å³ä¾§åˆ†åŒºçš„æ‰€æœ‰å®ä½“ï¼ˆæ‰€æœ‰ç±»å‹ï¼‰çš„åµŒå…¥ã€‚ é”å®šæœåŠ¡å™¨çš„â€œé”å®šâ€æœºåˆ¶ç¡®ä¿åœ¨ä»»ä½•ç»™å®šæ—¶é—´æœ€å¤šæœ‰ä¸€ä¸ªè®­ç»ƒå™¨åœ¨ä¸€ä¸ªåˆ†åŒºä¸Šè¿è¡Œã€‚è¿™ä¸ªæœºåˆ¶ä¸é€‚ç”¨äºæœªåˆ†åŒºçš„å®ä½“ï¼Œå› ä¸ºä»–ä»¬è¢«æ‰€æœ‰çš„è®­ç»ƒå™¨å…±äº«ã€‚è§ä¸‹æ–‡ã€‚ å› æ­¤ï¼Œæ¯ä¸ªè®­ç»ƒå™¨åœ¨è®­ç»ƒæ—¶å¯ä»¥ç‹¬å å…¶è®­ç»ƒçš„åˆ†åŒºã€‚</p><p>Once a trainer starts working on a new bucket it needs to acquire the embeddings of its partitions, and once itâ€™s done it needs to release them and make them available, in their updated version, to the next trainer that needs them. In order to do this, thereâ€™s a system of so-called â€œpartition serversâ€ that store the embeddings, provide them upon request to the trainers who need them, receive back the updated embedding and store it.<br>å½“ä¸€ä¸ªè®­ç»ƒå™¨å¼€å§‹åœ¨æ–°çš„æ¡¶ä¸Šä¸Šå·¥ä½œåï¼Œéœ€è¦è·å–å…¶åˆ†åŒºçš„åµŒå…¥å†…å®¹ï¼Œå®Œæˆåï¼Œéœ€è¦é‡Šæ”¾å®ƒä»¬å¹¶ä»¥æ›´æ–°ç‰ˆæœ¬å°†å…¶æä¾›ç»™éœ€è¦è¯¥è®­ç»ƒçš„ä¸‹ä¸€ä¸ªè®­ç»ƒå™¨ã€‚ ä¸ºæ­¤ï¼Œæœ‰ä¸€ä¸ªæ‰€è°“çš„â€œåˆ†åŒºæœåŠ¡å™¨â€ç³»ç»Ÿï¼Œç”¨äºå­˜å‚¨åµŒå…¥å†…å®¹ï¼Œå¹¶æ ¹æ®éœ€è¦å°†å…¶æä¾›ç»™éœ€è¦å®ƒä»¬çš„è®­ç»ƒå™¨ï¼Œå¹¶æ¥æ”¶æ›´æ–°çš„åµŒå…¥å†…å®¹å¹¶è¿›è¡Œå­˜å‚¨ã€‚</p><p>This service is optional, and is disabled when num_partition_servers is set to zero. In that case the trainers â€œsendâ€ each other the embeddings simply by writing them to the checkpoint directory (which should reside on a shared disk) and then fetching them back from there.<br>æ­¤æœåŠ¡æ˜¯å¯é€‰çš„ï¼Œå¹¶ä¸”åœ¨num_partition_serversè®¾ç½®ä¸ºé›¶æ—¶è¢«ç¦ç”¨ã€‚ åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè®­ç»ƒå™¨åªéœ€å°†åµŒå…¥å†…å®¹å†™å…¥â€œæ£€æŸ¥ç‚¹â€ç›®å½•ï¼ˆåº”ä½äºå…±äº«ç£ç›˜ä¸Šï¼‰ï¼Œç„¶åä»é‚£é‡Œå–å›å®ƒä»¬ï¼Œå³å¯ç›¸äº’â€œå‘é€â€åµŒå…¥å†…å®¹ã€‚</p><p>When this system is enabled, it can operate in two modes. The simplest mode is triggered when num_partition_servers is -1 (the default): in that case all trainers spawn a local process that acts as a partition server. If, on the other hand, num_partition_servers is a positive value then the trainers will not spawn any process, but will instead connect to the partition servers that the user must have provisioned manually by launching the torchbiggraph_partitionserver command on the appropriate number of machines.<br>å¯ç”¨æ­¤ç³»ç»Ÿåï¼Œå®ƒå¯ä»¥åœ¨ä¸¤ç§æ¨¡å¼ä¸‹è¿è¡Œã€‚ å½“num_partition_serversä¸º-1ï¼ˆé»˜è®¤å€¼ï¼‰æ—¶ï¼Œå°†è§¦å‘æœ€ç®€å•çš„æ¨¡å¼ï¼šåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‰€æœ‰è®­ç»ƒå™¨éƒ½ä¼šç”Ÿæˆä¸€ä¸ªå……å½“åˆ†åŒºæœåŠ¡å™¨çš„æœ¬åœ°è¿›ç¨‹ã€‚ å¦ä¸€æ–¹é¢ï¼Œå¦‚æœnum_partition_serversä¸ºæ­£å€¼ï¼Œé‚£ä¹ˆè®­ç»ƒå™¨å°†ä¸ä¼šäº§ç”Ÿä»»ä½•è¿›ç¨‹ï¼Œè€Œæ˜¯å°†ä¼šè¿æ¥åˆ°ç”¨æˆ·æ‰‹åŠ¨è®¾ç½®çš„æä¾›çš„åˆ†åŒºæœåŠ¡å™¨ä¸Šï¼Œç”¨æˆ·é€šè¿‡åœ¨é€‚å½“æ•°é‡çš„æœºå™¨ä¸Šè¿è¡Œtorchbiggraph_partitionserveræ¥å®ç°é¢„å…ˆä¾›ç»™ã€‚</p><h3 id="Updating-shared-parameters"><a href="#Updating-shared-parameters" class="headerlink" title="Updating shared parameters"></a>Updating shared parameters</h3><p>Some parameters of the model need to be used by all trainers at the same time (this includes the operator weights, the global embeddings of each entity type, the embeddings of the unpartitioned entities). These are parameters that donâ€™t depend on what bucket the trainer is operating on, and therefore are always present on all trainers (as opposed to the entity embeddings, which are loaded and unloaded as needed). These parameters are synchronized using a series of â€œparameter serversâ€. Each trainer starts a local parameter server (in a separate subprocess) and connects to all other parameter servers. Each parameter that is shared between trainers is then stored in a parameter server (possibly sharded across several of them, if too large). Each trainer also has a loop (also in a separate subprocess) which, at regular intervals, goes over each shared parameter, computes the difference between its current local value and the value it had when it was last synced with the server where the parameter is hosted and sends that delta to that server. The server, in turn, accumulates all the deltas it receives from all trainers, updates the value of the parameter and sends this new value back to the trainers. The parameter server performs throttling to 100 updates/s or 1GB/s, in order to prevent the parameter server from starving the other communication.<br>æ‰€æœ‰è®­ç»ƒå™¨å¿…é¡»åŒæ—¶ä½¿ç”¨æ¨¡å‹çš„æŸäº›å‚æ•°ï¼ˆè¿™åŒ…æ‹¬æ“ä½œå‘˜æƒé‡ï¼Œæ¯ç§å®ä½“ç±»å‹çš„å…¨å±€åµŒå…¥ï¼Œæœªåˆ†åŒºå®ä½“çš„åµŒå…¥ï¼‰ã€‚è¿™äº›å‚æ•°å¹¶ä¸å–å†³äºé‚£äº›è®­ç»ƒå™¨æ­£åœ¨æ“ä½œçš„æ¡¶ï¼Œå› æ­¤å…¶å§‹ç»ˆå­˜åœ¨äºæ‰€æœ‰è®­ç»ƒå™¨ä¸Šï¼ˆä¸å®ä½“åµŒå…¥æƒ…å†µç›¸ä»¿ï¼Œå®ä½“åµŒå…¥æ ¹æ®éœ€è¦è¿›è¡ŒåŠ è½½å’Œå¸è½½ï¼‰è¿™äº›å‚æ•°ä½¿ç”¨ä¸€ç³»åˆ—â€œå‚æ•°æœåŠ¡å™¨â€è¿›è¡ŒåŒæ­¥ã€‚æ¯ä¸€ä¸ªè®­ç»ƒå™¨å¼€å¯ä¸€ä¸ªæœ¬åœ°çš„å‚æ•°æœåŠ¡å™¨ï¼ˆä»¥ä¸€ä¸ªç‹¬è‡ªçš„å­è¿›ç¨‹ï¼‰å¹¶ä¸”å’Œå…¶ä»–æ‰€æœ‰çš„å‚æ•°æœåŠ¡å™¨è¿›è¡Œè¿æ¥ã€‚æ¯ä¸€ä¸ªè¢«è®­ç»ƒå™¨å…±äº«çš„å‚æ•°è¢«å­˜å‚¨åœ¨å‚æ•°æœåŠ¡å™¨ä¸­ï¼ˆå¦‚æœå‚æ•°å¤ªå¤§çš„è¯ï¼Œåˆ™å¯èƒ½å°†å…¶åˆ†æ•£åœ¨å…¶ä¸­çš„å‡ ä¸ªæœåŠ¡å™¨ä¸­ï¼‰ã€‚æ¯ä¸€ä¸ªè®­ç»ƒå™¨è¿˜æœ‰ä¸€ä¸ªloopï¼ˆåŒæ ·ä¹Ÿåœ¨ä¸€ä¸ªå­è¿›ç¨‹ä¸­ï¼‰ï¼Œè¯¥å¾ªç¯ä»¥å›ºå®šçš„æ—¶é—´é—´éš”éå†æ¯ä¸ªå…±äº«å‚æ•°ï¼Œè®¡ç®—å…¶å½“å‰æœ¬åœ°å€¼ä¸ä¸Šæ¬¡ä¸è¯¥æœåŠ¡å™¨ä¸Šæ¬¡ä¸æœåŠ¡å™¨åŒæ­¥æ—¶æ‰€å…·æœ‰çš„å€¼ä¹‹é—´çš„å·®ï¼Œé‚£äº›æœåŠ¡å™¨çš„å‚æ•°å€¼æ˜¯è¢«æ‰˜ç®¡å¹¶ä¸”å‘é€åˆ°æœ¬åœ°çš„å­è¿›ç¨‹ä¸­ã€‚åè¿‡æ¥ï¼ŒæœåŠ¡å™¨ä¼šç´¯ç§¯ä»æ‰€æœ‰è®­ç»ƒå™¨é‚£é‡Œæ”¶åˆ°çš„æ‰€æœ‰å·®ï¼Œæ›´æ–°å‚æ•°çš„å€¼ï¼Œç„¶åå°†æ­¤æ–°å€¼å‘é€å›è®­ç»ƒå™¨ã€‚å‚æ•°æœåŠ¡å™¨æ‰§è¡Œé™åˆ¶è‡³100ä¸ªæ›´æ–°æ¯ç§’æˆ–è€…1GBæ¯ç§’ï¼Œä»¥é˜²æ­¢å‚æ•°æœåŠ¡å™¨ä½¿å…¶ä»–é€šä¿¡ä¸­æ–­ã€‚</p><p>æºåœ°å€ï¼š<a href="https://torchbiggraph.readthedocs.io/en/latest/distributed_training.html">https://torchbiggraph.readthedocs.io/en/latest/distributed_training.html</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>PyTorch-BigGraph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch-BigGraph  æ‰¹å‡†å¤‡</title>
    <link href="/2020/10/27/PBG-Batch-preparation/"/>
    <url>/2020/10/27/PBG-Batch-preparation/</url>
    
    <content type="html"><![CDATA[<h1 id="PBG-æ‰¹å‡†å¤‡"><a href="#PBG-æ‰¹å‡†å¤‡" class="headerlink" title="PBG æ‰¹å‡†å¤‡"></a>PBG æ‰¹å‡†å¤‡</h1><p>This section presents how the training data is prepared and organized in batches before the loss is calculated and optimized on each of them.<br>æœ¬èŠ‚ä»‹ç»äº†å¦‚ä½•åœ¨è®¡ç®—å’Œä¼˜åŒ–æŸå¤±ä¹‹å‰å¦‚ä½•å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œå‡†å¤‡å’Œç»„ç»‡ã€‚</p><p>Training proceeds by iterating over the edges, through various nested loops. The outermost one walks through so-called epochs. Each epoch is independent and essentially equivalent to every other one. Their goal is to repeat the inner loop until convergence. Each epoch visits all the edges exactly once. The number of epochs is specified in the num_epochs configuration parameter.<br>è®­ç»ƒè¿‡ç¨‹é€šè¿‡ä¸æ–­åµŒå¥—å¾ªç¯å„æ¡è¾¹æ¥è¿›è¡Œã€‚æ‰€æœ‰è¾¹éƒ½è¢«è®­ç»ƒè¿‡ä¸€æ¬¡å«åšä¸€ä¸ªepochï¼Œæ¯ä¸€ä¸ªepochéƒ½æ˜¯äº’ç›¸ç‹¬ç«‹ä¸”å¹³ç­‰çš„ã€‚ä»–ä»¬çš„ç›®æ ‡éƒ½æ˜¯ä¸ºäº†é‡å¤è®­ç»ƒè¾¹æœ€ç»ˆè¾¾åˆ°æ”¶æ•›çš„æ•ˆæœã€‚æ¯ä¸€ä¸ªepochåªè®¿é—®æ¯ä¸€æ¡ä¸€æ¬¡ã€‚åœ¨é…ç½®æ–‡ä»¶ä¸­çš„num_epochsæŒ‡å®šepochæ•°ç›®ã€‚</p><p>The edges are partitioned into edge sets (one for each directory of the edge_paths configuration key) and, within each epoch, the edge sets are traversed in order.<br>å›¾ä¸­çš„è¾¹è¢«åˆ’åˆ†ä¸ºè¾¹é›†åˆçš„å½¢å¼ï¼ˆedge_pathsç›®å½•ä¸‹çš„æ¯ä¸ªæ–‡ä»¶è¡¨ç¤ºä¸€ä¸ªè¾¹é›†åˆï¼‰ï¼Œåœ¨æ¯ä¸€ä¸ªepochä¸‹ï¼Œè¿™äº›è¾¹é›†åˆæŒ‰ç…§é¡ºåºè®¿é—®éå†ã€‚</p><p>When iterating over an edge set, each of its buckets is first divided into equally sized chunks: each chunk spans a contiguous interval of edges (in the order they are stored in the files) and the number of chunks can be tweaked using the num_edge_chunks configuration key. The training first operates on the all the first chunks of all buckets, then on all of their second chunks, and so on.<br>å½“åœ¨æŸä¸€ä¸ªè¾¹é›†åˆä¸Šè¿›è¡Œè¿­ä»£è®­ç»ƒçš„æ—¶å€™ï¼Œæ¯ä¸€ä¸ªæ¡¶ï¼ˆä¸€ä¸ªè¾¹é›†åˆï¼‰é¦–å…ˆè¢«åˆ’åˆ†æˆç›¸åŒå¤§å°çš„chunksï¼Œæ¯ä¸€ä¸ªchunkè·¨åº¦è¿ç»­çš„è¾¹é—´éš”ï¼ˆæŒ‰å®ƒä»¬å­˜å‚¨åœ¨æ–‡ä»¶ä¸­çš„é¡ºåºï¼‰ï¼Œå¯ä»¥åœ¨é…ç½®æ–‡ä»¶ä¸­ä½¿ç”¨num_edge_chunksæ¥è®¾ç½®chunkçš„å¤§å°ã€‚è®­ç»ƒé¦–å…ˆå¯¹æ¡¶ä¸­çš„ç¬¬ä¸€ä¸ªchunkè¿›è¡Œè®­ç»ƒï¼Œç„¶åå¯¹ç¬¬äºŒä¸ªï¼Œä»¥æ­¤ç±»æ¨ã€‚</p><p>Next, the algorithm iterates over the buckets. The order in which buckets are processed depends on the value of the bucket_order configuration key. In addition to a random permutation, there are methods that try to have successive buckets share a common partition: this allows for that partition to be reused, thus allowing it to be kept in memory rather than being unloaded and another one getting loaded in its place. (In distributed mode, the various trainer processes operate on the buckets at the same time, thus the iteration is managed differently).<br>æ¥ä¸‹æ¥ï¼Œè¯¥ç®—æ³•è¿­ä»£è®­ç»ƒæ¯ä¸€ä¸ªæ¡¶ã€‚æ¡¶è®­ç»ƒé¡ºåºå–å†³äºé…ç½®æ–‡ä»¶ä¸­çš„bucket_orderã€‚é™¤äº†éšæœºæ’åˆ—ä¹‹å¤–ï¼Œè¿˜æœ‰ä¸€äº›æ–¹æ³•å°è¯•ä½¿è¿ç»­çš„å­˜å‚¨æ¡¶å…±äº«ä¸€ä¸ªå…¬å…±åˆ†åŒºï¼Œä¹Ÿå°±æ˜¯è¯´å…è®¸è¿™ä¸ªå…±äº«åˆ†åŒºè¢«é‡ç”¨ã€‚é€šè¿‡è¿™æ ·å…¶å…è®¸è¿™è¿™äº›è¾¹æ•°æ®ä¿å­˜åœ¨å†…å­˜ä¸­è€Œä¸æ˜¯è¢«å¸è½½ç„¶åè¢«å…¶ä»–çš„è¾¹æ•°æ®å–ä»£ã€‚ï¼ˆåœ¨åˆ†å¸ƒå¼æ¨¡å¼ä¸‹ï¼Œå„ç§è®­ç»ƒå™¨è¿›ç¨‹åŒæ—¶åœ¨å­˜å‚¨æ¡¶ä¸Šè¿è¡Œè®­ç»ƒï¼Œå› æ­¤å¯¹è¿­ä»£çš„ç®¡ç†ä¸åŒï¼‰ã€‚</p><p>Once the trainer has fixed a given chunk and a certain bucket, its edges are finally loaded from disk. When evaluating during training, a subset of these edges is withheld (such subset is the same for all epochs). The remaining edges are immediately uniformly shuffled and then split into equal parts. These parts are distributed among a pool of processes, so that the training can proceed in parallel on all of them at the same time. These subprocesses are â€œHogwild!â€ workers, which do not synchronize their computations or memory accesses. The number of such workers is determined by the workers parameter.<br>ä¸€æ—¦è®­ç»ƒå™¨è·å¾—äº†ä¸€ä¸ªç»™å®šçš„chunkå’Œbucketï¼Œå…¶chuckçš„è¾¹æœ€ç»ˆä»ç£ç›˜ä¸ŠåŠ è½½åˆ°å†…å­˜ã€‚åœ¨è®­ç»ƒä¹‹å‰ï¼Œè¾¹çš„ä¸€éƒ¨åˆ†è¢«ä¿ç•™ä¸‹è½½ä½œä¸ºä¹‹åçš„è¯„ä¼°ä½¿ç”¨ã€‚ï¼ˆå¯¹äºæ‰€æœ‰çš„epochè€Œè¨€ï¼Œè¿™äº›è¾¹æ˜¯ä¸€æ ·çš„ï¼‰ï¼Œå…¶ä½™çš„è¾¹éƒ½ä½œä¸ºè®­ç»ƒæ•°æ®ï¼Œä»–ä»¬è¢«å‡åŒ€åœ°æ··æ´—ï¼Œç„¶ååˆ†æˆç›¸ç­‰çš„éƒ¨åˆ†åˆ†å‘åˆ°è¿›ç¨‹æ± é‡Œè¿›è¡Œè®­ç»ƒã€‚å› æ­¤è®­ç»ƒæ˜¯å¯ä»¥åœ¨æ‰€æœ‰è¿›ç¨‹ä¸Šå¹¶è¡Œè¿è¡Œçš„ã€‚è¿™äº›å­è¿›ç¨‹è¢«ç§°ä¸ºâ€œHogwild!â€ workerï¼Œä»–ä»¬çš„è®¡ç®—å’Œå†…å­˜ä½¿ç”¨å¹¶ä¸åŒæ­¥è¿›è¡Œã€‚workerçš„æ•°ç›®åœ¨é…ç½®æ–‡ä»¶ä¸­çš„worferså‚æ•°æŒ‡å®šã€‚</p><blockquote><p>key point: è¿™é‡Œworkerå°±å¯ä»¥å½“æˆæ˜¯è¿›ç¨‹æ•°ç›®ï¼Œå‡ ä¸ªworkerè¡¨ç¤ºå¯ä»¥åŒæ—¶å‡ ä¸ªè¿›ç¨‹å¹¶è¡Œè®­ç»ƒæ•°æ®ã€‚</p></blockquote><p>The way each worker trains on its set of edges depends on whether dynamic relations are in use. The simplest scenario is if they are, in which case the edges are split into contiguous batches (each one having the size specified in the batch_size configuration key, except possibly the last one which could be smaller). Training is then performed on that batch before moving on to the next one.<br>workerè®­ç»ƒè¾¹é›†åˆçš„æ–¹å¼å–å†³äºæ˜¯å¦ä½¿ç”¨åŠ¨æ€å…³ç³»ã€‚æœ€ç®€å•çš„æƒ…å†µæ˜¯ï¼Œå¦‚æœè¾¹è¢«åˆ†æˆè¿ç»­çš„æ‰¹æ¬¡ï¼Œï¼ˆæ¯ä¸ªæ‰¹æ¬¡å…·æœ‰ä¸€æ ·çš„å¤§å°ï¼Œå¹¶ä¸”å…¶åœ¨é…ç½®æ–‡ä»¶çš„batch_sizeä¸­æŒ‡å®šï¼Œæœ€åä¸€ä¸ªæ‰¹æ¬¡å¯èƒ½ä¼šå°äº›ã€‚ï¼‰è®­ç»ƒåˆ†æ‰¹æ¬¡ä¾æ¬¡è¿›è¡Œè®­ç»ƒã€‚</p><p>When dynamic relations are not in use, however, the loss can only be computed on a set of edges that are all of the same type. Thus the worker first randomly samples a relation type, with probability proportional to the number of edges of that type that are left in the pool. It then takes the first batch_size relations of that type (or fewer, if not enough of them are left), removes them from the pool and performs training on them.<br>å½“ä¸ä½¿ç”¨åŠ¨æ€å…³ç³»çš„æ—¶å€™ï¼ŒæŸå¤±å‡½æ•°å°†åªèƒ½ç”¨äºåŒç§å…³ç³»ç±»å‹çš„è¾¹è®¡ç®—ã€‚å› æ­¤workeré¦–å…ˆéœ€è¦éšæœºçš„é€‰å‡ºæŸä¸€ç§å…³ç³»ç±»å‹çš„æ ·æœ¬ï¼Œï¼ˆæŒ‘é€‰æ¦‚ç‡å’Œæ± å­æ®‹ç•™çš„è¾¹æˆæ­£æ¯”ï¼‰ã€‚éšåï¼Œå…¶é‡‡ç”¨è¯¥ç±»å‹çš„ç¬¬ä¸€ä¸ªbatch_sizeï¼ˆå¦‚æœå‰©ä½™çš„ä¸å¤šçš„è¯ï¼Œæ•°ç›®å¯èƒ½ä¼šå¾ˆå°‘ï¼‰,ä»æ± å­ä¸­ç§»é™¤ç„¶åè¿›è¡Œè®­ç»ƒã€‚</p><p>æºåœ°å€ï¼š<a href="https://torchbiggraph.readthedocs.io/en/latest/batch_preparation.html">https://torchbiggraph.readthedocs.io/en/latest/batch_preparation.html</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>PyTorch-BigGraph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch-BigGraph I/O æ ¼å¼</title>
    <link href="/2020/10/27/PBG-I-O-format/"/>
    <url>/2020/10/27/PBG-I-O-format/</url>
    
    <content type="html"><![CDATA[<h1 id="PBG-I-Oæ ¼å¼"><a href="#PBG-I-Oæ ¼å¼" class="headerlink" title="PBG I/Oæ ¼å¼"></a>PBG I/Oæ ¼å¼</h1><h2 id="Entity-and-relation-types"><a href="#Entity-and-relation-types" class="headerlink" title="Entity and relation types"></a>Entity and relation types</h2><p>The list of entity types (each identified by a string), plus some information about each of them, is given in the <code>entities</code> dictionary in the configuration file. The list of relation types (each identified by its index in that list), plus some data like what their left- and right-hand side entity types are, is in the <code>relations</code> key of the configuration file.<br>å®ä½“ç±»å‹çš„åˆ—è¡¨(æ¯ä¸ªå®ä½“ç±»å‹ç”±ä¸€ä¸ªå­—ç¬¦ä¸²æ ‡è¯†)ä»¥åŠæœ‰å…³äºä»–ä»¬çš„ä¸€äº›ä¿¡æ¯ç”±é…ç½®æ–‡ä»¶ä¸­çš„å®ä½“å­—å…¸æä¾›ã€‚å…³ç³»ç±»å‹çš„åˆ—è¡¨ï¼ˆæ¯ä¸ªéƒ½ç”±è¯¥åˆ—è¡¨ä¸­çš„ç´¢å¼•æ ‡è¯†ï¼‰ä»¥åŠä¸€äº›æ•°æ®ï¼ˆå¦‚å…¶å·¦ä¾§å’Œå³ä¾§å®ä½“ç±»å‹ï¼‰åœ¨é…ç½®æ–‡ä»¶çš„relation keyä¸­æŒ‡ç¤ºã€‚</p><h2 id="Entities"><a href="#Entities" class="headerlink" title="Entities"></a>Entities</h2><p>The only information that needs to be provided about entities is how many there are in each entity typeâ€™s partition. This is done by putting a file named <code>entity_count_type_part.txt</code> for each entity type identified by <code>type</code> and each partition <code>part</code> in the directory specified by the <code>entity_path</code> config parameter. These files must contain a single integer (as text), which is the number of entities in that partition. The directory where all these files reside must be specified as the <code>entity_path</code> key of the configuration file.<br>å¯¹äºå®ä½“è€Œè¨€ï¼Œå…¶åªéœ€è¦æä¾›æ¯ç§å®ä½“ç±»å‹çš„åˆ†åŒºä¸­æœ‰å¤šå°‘ä¸ªå®ä½“è¿™æ ·ä¸€ä¸ªä¿¡æ¯å³å¯ã€‚ä»–é€šè¿‡å°†æ–‡ä»¶åç§°ä¸º<code>entity_count_type_part.txt</code>(<code>type</code>è¡¨ç¤ºå®ä½“ç±»å‹ï¼Œ<code>part</code>è¡¨ç¤ºåˆ†åŒºid)æ”¾åˆ°é…ç½®æ–‡ä»¶æŒ‡å®šçš„æ–‡ä»¶å¤¹æ¥å®ç°ï¼Œè¿™ä¸ªæ–‡ä»¶å¤¹åœ¨é…ç½®æ–‡ä»¶ä¸­çš„keyä¸º<code>entity_path</code>ã€‚ è¿™äº›æ–‡ä»¶(entity_count_type1_part1.txt, entity_count_type2_part2.txtâ€¦)å¿…é¡»åŒ…å«ä¸€ä¸ªæ•´æ•°ï¼ˆä½œä¸ºæ–‡æœ¬ï¼‰ï¼Œè¯¥æ•´æ•°è¡¨ç¤ºåœ¨è¯¥åˆ†åŒºä¸­å®ä½“çš„æ•°é‡ã€‚è¿™äº›æ–‡ä»¶æ‰€åœ¨çš„ç›®å½•åç§°å¿…é¡»æŒ‡å®šä¸ºåœ¨é…ç½®æ–‡ä»¶ä¸‹çš„<code>entity_path</code>ã€‚</p><p>It is possible to provide an initial value for the embeddings, by specifying a value for the <code>init_path</code> configuration key, which is the name of a directory that contains files in a format similar to the output format detailed in Checkpoint (possibly without the optimizer state dicts).<br>é€šè¿‡ä¸º<code>init_path</code>é…ç½®é”®æŒ‡å®šä¸€ä¸ªå€¼ï¼Œå¯ä»¥ä¸ºåµŒå…¥æä¾›ä¸€ä¸ªåˆå§‹å€¼ã€‚<code>init_path</code>å€¼çš„ç›®å½•ä¸‹åŒ…å«å’ŒCheckpointç±»ä¼¼çš„æ–‡ä»¶æ ¼å¼ã€‚ï¼ˆè¯¦æƒ…è§checkpointï¼‰</p><p>If no initial value is provided, it will be auto-generated, with each dimension sampled from the centered normal distribution whose standard deviation can be configured using the <code>init_scale</code> configuration key. For performance reasons the samples of all the entities of a certain type will not be independent.<br>å¦‚æœä¸ºåµŒå…¥æä¾›åˆå§‹å€¼ï¼Œå®ƒå°†ä¼šè‡ªåŠ¨ç”Ÿæˆï¼Œå…¶æ¯ä¸ªç»´çš„å€¼éƒ½æ˜¯ä»æ­£æ€åˆ†å¸ƒä¸­é‡‡æ ·å¾—åˆ°ã€‚å¯ä»¥é€šè¿‡é…ç½®æ–‡ä»¶ä¸­çš„init_scaleæ¥è°ƒæ•´æ–¹å·®èŒƒå›´ã€‚å‡ºäºæ€§èƒ½åŸå› ï¼Œå¯¹äºåŒä¸€ä¸ªç±»å‹ä¸‹çš„æ‰€æœ‰å®ä½“çš„æ ·æœ¬å°†ä¸æ˜¯ç‹¬ç«‹çš„ã€‚</p><h2 id="Edges"><a href="#Edges" class="headerlink" title="Edges"></a>Edges</h2><p>For each bucket there must be a file that stores all the edges that fall in that bucket, of all relation types. This means that such a file is only identified by two integers, the partitions of its left- and right-hand side entities. It must be named <code>edges_lhs_rhs.h5</code> (where lhs and rhs are the above integers), it must be a HDF5 file containing three one-dimensional datasets of the same length, called rel, lhs and rhs. The elements in the ğ‘–-th positions in each of them define the ğ‘–-th edge: rel identifies the relation type (and thus the left- and right-hand side entity types), lhs and rhs given the indices of the left- and right-hand side entities within their respective partitions.<br>å¯¹äºæ¯ä¸€ä¸ªæ¡¶ï¼Œå¿…é¡»è¦æœ‰ä¸€ä¸ªæ–‡ä»¶æ¥å­˜å‚¨è¯¥æ¡¶ä¸‹çš„æ‰€æœ‰å…³ç³»ç±»å‹çš„æ‰€æœ‰è¾¹ä¿¡æ¯ã€‚è¿™æ„å‘³è¿™æ ·çš„ä¸€ä¸ªæ–‡ä»¶ä»…ç”±ä¸¤ä¸ªæ•´æ•°æ¥è¿›è¡Œæ ‡è¯†ï¼Œå³å®ƒçš„å·¦ä¾§å’Œå³ä¾§å®ä½“çš„åˆ†åŒºidã€‚ å¿…é¡»å°†å…¶å‘½åä¸ºedges_lhs_rhs.h5ï¼ˆå…¶ä¸­lhså’Œrhsæ˜¯å·¦ä¾§åˆ†åŒºidå’Œå³ä¾§åˆ†åŒºidï¼‰ï¼Œå®ƒå¿…é¡»æ˜¯HDF5æ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å«ä¸‰ä¸ªç›¸åŒé•¿åº¦çš„ä¸€ç»´æ•°æ®é›†ï¼Œåˆ†åˆ«ç§°ä¸ºrelï¼Œlhså’Œrhsã€‚<br>åœ¨è¿™ä¸‰ä¸ªä¸€ç»´æ•°æ®é›†ä¸­ï¼Œç¬¬ğ‘–ä¸ªä½ç½®çš„å…ƒç´ å®šä¹‰äº†ç¬¬iæ¡è¾¹: relå®šä¹‰äº†å…³ç³»ç±»å‹ï¼ˆå¹¶å› æ­¤æŒ‡å®šå·¦ä¾§å’Œå³ä¾§å®ä½“ç±»å‹ï¼‰ï¼Œlhså’Œrhså®šä¹‰äº†å·¦å³ä¾§çš„å®ä½“åœ¨å…¶å„è‡ªåˆ†åŒºä¸‹çš„ç´¢å¼•ã€‚</p><p>To ease future updates to this format, each file must contain the format version in the format_version attribute of the top-level group. The current version is 1.<br>ä¸ºäº†ç®€åŒ–ä»¥åå¯¹è¯¥æ ¼å¼çš„æ›´æ–°ï¼Œæ¯ä¸ªæ–‡ä»¶éƒ½å¿…é¡»åœ¨é¡¶çº§ç»„çš„format_versionå±æ€§ä¸­åŒ…å«æ ¼å¼ç‰ˆæœ¬ã€‚ å½“å‰ç‰ˆæœ¬æ˜¯1ã€‚ï¼ˆè¿™ä¸ªæ˜¯H5çš„æ ¼å¼é—®é¢˜ï¼‰</p><p>If an entity type is unpartitioned (that is, all its entities belong to the same partition), then the edges incident to these entities must still be uniformly spread across all buckets.<br>å¦‚æœæŸä¸€ä¸ªå®ä½“ç±»å‹æ˜¯æœªåˆ†åŒºçš„ï¼ˆå³ï¼Œå…¶æ‰€æœ‰å®ä½“éƒ½å±äºåŒä¸€åˆ†åŒºï¼‰ï¼Œåˆ™è¿™äº›å®ä½“è¿æ¥çš„çš„è¾¹å¿…é¡»ä»ç„¶å‡åŒ€åœ°åˆ†å¸ƒåœ¨æ‰€æœ‰å­˜å‚¨æ¡¶ä¸­ã€‚</p><p>These files, for all buckets, must be stored in the same directory, which must be passed as the edge_paths configuration key. That key can actually contain a list of paths, each pointing to a directory of the format described above: in that case the graph will contain the union of all their edges.<br>å¯¹äºæ‰€æœ‰æ¡¶å¯¹åº”çš„æ–‡ä»¶éƒ½å¿…é¡»å­˜å‚¨åœ¨åŒä¸€ä¸ªç›®å½•ä¸‹ã€‚è¯¥ç›®å½•å°†ä¼šè¢«é…ç½®åˆ°é…ç½®æ–‡ä»¶çš„<code>edge_paths</code>keyä¸‹ï¼Œè¯¥keyå®é™…ä¸Šå¯ä»¥åŒ…å«ä¸€ä¸ªè·¯å¾„åˆ—è¡¨ï¼Œæ¯ä¸ªè·¯å¾„éƒ½æŒ‡å‘ä¸Šè¿°æ ¼å¼çš„ç›®å½•ï¼šåœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå›¾å°†åŒ…å«å…¶æ‰€æœ‰è¾¹çš„å¹¶é›†ã€‚</p><h2 id="Checkpoint"><a href="#Checkpoint" class="headerlink" title="Checkpoint"></a>Checkpoint</h2><p>The trainingâ€™s checkpoints are also its output, and they are written to the directory given as the checkpoint_path parameter in the configuration. Checkpoints are identified by successive positive integers, starting from 1, and all the files belonging to a certain checkpoint have an extra component .vversion between their name and extension (e.g., something.v42.h5 for version 42).<br>è®­ç»ƒçš„æ£€æŸ¥ç‚¹ä¹Ÿæ˜¯å…¶è¾“å‡ºï¼Œå®ƒä»¬è¢«å†™å…¥é…ç½®ä¸­æŒ‡å®šä¸ºcheckpoint_pathå‚æ•°çš„ç›®å½•ä¸­ã€‚æ£€æŸ¥ç‚¹ç”±ä»1å¼€å§‹çš„è¿ç»­æ­£æ•´æ•°æ ‡è¯†ï¼Œå¹¶ä¸”å±äºæŸä¸ªæ£€æŸ¥ç‚¹çš„æ‰€æœ‰æ–‡ä»¶çš„åç§°å’Œæ‰©å±•åä¹‹é—´éƒ½æœ‰ä¸€ä¸ªé¢å¤–çš„ç»„ä»¶.vversionï¼ˆä¾‹å¦‚ï¼Œç‰ˆæœ¬42çš„something.v42.h5ï¼‰ã€‚</p><p>The latest complete checkpoint version is stored in an additional file in the same directory, called <code>checkpoint_version.txt</code>, which contains a single integer number, the current version.<br>æœ€æ–°çš„å®Œæ•´æ£€æŸ¥ç‚¹ç‰ˆæœ¬å­˜å‚¨åœ¨åŒä¸€ç›®å½•ä¸­çš„å¦ä¸€ä¸ªæ–‡ä»¶ä¸­ï¼Œè¯¥æ–‡ä»¶ç§°ä¸ºcheckpoint_version.txtï¼Œå…¶ä¸­åŒ…å«ä¸€ä¸ªæ•´æ•°ï¼Œå³å½“å‰ç‰ˆæœ¬ã€‚</p><p>Each checkpoint contains a JSON dump of the config that was used to produce it stored in the config.json file.<br>æ¯ä¸€ä¸ªæ£€æŸ¥ç‚¹éƒ½ä¸ºé…ç½®æ–‡ä»¶ç”Ÿæˆäº†å¯¹åº”jsonæ–‡ä»¶ï¼Œå¹¶å°†å…¶å­˜å‚¨åœ¨config.jsonæ–‡ä»¶ä¸­ã€‚</p><p>After a new checkpoint version is saved, the previous one will automatically be deleted. In order to periodically preserve some of these versions, set the <code>checkpoint_preservation_interval</code> config flag to the desired period (expressed in number of epochs).<br>å½“ä¸€ä¸ªæ–°çš„æ£€æŸ¥ç‚¹ç‰ˆæœ¬è¢«ä¿å­˜æ—¶ï¼Œä¸Šä¸€ä¸ªå°†ä¼šè‡ªåŠ¨è¢«åˆ é™¤ã€‚å¦‚æœæƒ³è¦å‘¨æœŸæ€§çš„ä¿å­˜ä¸€äº›æ£€æŸ¥ç‚¹ï¼Œå¯ä»¥åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®checkpoint_preservation_intervalï¼ˆä»¥è®­ç»ƒè½®æ¬¡æ•°çš„å½¢å¼ï¼‰</p><h2 id="Model-parameters"><a href="#Model-parameters" class="headerlink" title="Model parameters"></a>Model parameters</h2><p>The model parameters are stored in a file named model.h5, which is a HDF5 file containing one dataset for each parameter, all of which are located within the model group. Currently, the parameters that are provided are:<br>â€¢ model/relations/idx/operator/side/param with the parameters of each relationâ€™s operator.<br>â€¢ model/entities/type/global_embedding with the per-entity type global embedding.<br>æ¨¡å‹å‚æ•°å­˜å‚¨åœ¨åä¸ºmodel.h5çš„æ–‡ä»¶ä¸­ï¼Œè¯¥æ–‡ä»¶æ˜¯ä¸€ä¸ªHDF5æ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å«æ¯ä¸ªå‚æ•°çš„ä¸€ä¸ªæ•°æ®é›†ï¼Œæ‰€æœ‰æ•°æ®é›†éƒ½ä½äºæ¨¡å‹ç»„ä¸‹ã€‚ å½“å‰ï¼Œæä¾›çš„å‚æ•°æœ‰ï¼š<br>â€¢ model/relations/idx/operator/side/param -&gt; å¯¹åº”æ¯ä¸ªç®—å­çš„å‚æ•°<br>â€¢ model/entities/type/global_embedding -&gt;å¸¦æœ‰æ¯ä¸ªå®ä½“ç±»å‹å…¨å±€åµŒå…¥</p><blockquote><p>ğŸ¤” è¿™é‡Œå¥½åƒå’Œå®é™…æœ‰ç‚¹å‡ºå…¥</p></blockquote><p>Each of these datasets also contains, in the state_dict_key attribute, the key it was stored inside the model state dict. An additional dataset may exist, optimizer/state_dict, which contains the binary blob (obtained through torch.save()) of the state dict of the modelâ€™s optimizer.</p><blockquote><p>ğŸ¤” H5æ ¼å¼</p></blockquote><p>Finally, the top-level group of the file contains a few attributes with additional metadata. This mainly includes the format version, a JSON-dump of the config and some information about the iteration that produced the checkpoint.<br>æœ€åï¼Œæ–‡ä»¶çš„é¡¶çº§ç»„åŒ…å«ä¸€äº›å¸¦æœ‰å…¶ä»–å…ƒæ•°æ®çš„å±æ€§ã€‚ ä¸»è¦åŒ…æ‹¬æ ¼å¼ç‰ˆæœ¬ï¼Œé…ç½®çš„JSONè½¬å‚¨ä»¥åŠæœ‰å…³ç”Ÿæˆæ£€æŸ¥ç‚¹çš„è¿­ä»£çš„ä¸€äº›ä¿¡æ¯ã€‚</p><h2 id="Embeddings"><a href="#Embeddings" class="headerlink" title="Embeddings"></a>Embeddings</h2><p>Then, for each entity type and each of its partitions, there is a file embeddings_type_part.h5 (where type is the typeâ€™s name and part is the 0-based index of the partition), which is a HDF5 file with two datasets. One two-dimensional dataset, called embeddings, contains the embeddings of the entities, with the first dimension being the number of entities and the second being the dimension of the embedding.<br>å¯¹äºæ¯ç§å®ä½“ç±»å‹åŠå…¶æ¯ä¸ªåˆ†åŒºï¼Œéƒ½æœ‰ä¸€ä¸ªembeddings_type_part.h5æ–‡ä»¶ï¼ˆå…¶ä¸­typeæ˜¯ç±»å‹çš„åç§°ï¼Œpartæ˜¯åˆ†åŒºçš„ä»0å¼€å§‹çš„ç´¢å¼•ï¼‰ï¼Œå®ƒæ˜¯ä¸€ä¸ªåŒ…å«ä¸¤ä¸ªæ•°æ®é›†çš„HDF5æ–‡ä»¶ã€‚ ä¸€ä¸ªç§°ä¸ºåµŒå…¥çš„äºŒç»´æ•°æ®é›†åŒ…å«å®ä½“çš„åµŒå…¥ï¼Œç¬¬ä¸€ä¸ªç»´åº¦æ˜¯å®ä½“çš„æ•°é‡ï¼Œç¬¬äºŒä¸ªç»´åº¦æ˜¯åµŒå…¥çš„ç»´åº¦ã€‚ï¼ˆå…¶å®å°±æ˜¯å®ä½“åµŒå…¥çš„çŸ©é˜µï¼‰ï¼ˆæ•°æ®é›†1ï¼‰</p><p>Just like for the model parameters file, the optimizer state dict and additional metadata is also included.<br>å°±åƒmodel.h5ä¸€æ ·ï¼Œembeedings.h5ä¸­è¿˜åŒ…å«äº†ä¸€äº›å…³äºä¼˜åŒ–çŠ¶æ€ç­‰é¢å¤–çš„å…ƒæ•°æ®ã€‚ï¼ˆæ•°æ®é›†2ï¼‰</p><p>æºåœ°å€ï¼š<a href="https://torchbiggraph.readthedocs.io/en/latest/input_output.html">https://torchbiggraph.readthedocs.io/en/latest/input_output.html</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>PyTorch-BigGraph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch-BigGraph ä»å®ä½“åµŒå…¥åˆ°è¾¹å¾—åˆ†</title>
    <link href="/2020/10/23/From-embedding-to-scores/"/>
    <url>/2020/10/23/From-embedding-to-scores/</url>
    
    <content type="html"><![CDATA[<h1 id="From-entity-embeddings-to-edge-scores"><a href="#From-entity-embeddings-to-edge-scores" class="headerlink" title="From entity embeddings to edge scores"></a>From entity embeddings to edge scores</h1><p>The goal of training is to embed each entity in â„^D so that the embeddings of two entities are a good proxy to predict whether there is a relation of a certain type between them.<br>è®­ç»ƒçš„ç›®çš„æ˜¯å°†æ¯ä¸ªå®ä½“åµŒå…¥åˆ°Dç»´çš„å‘é‡ç©ºé—´ä¸­ï¼Œä»¥ä¾¿ä¸¤ä¸ªå®ä½“çš„åµŒå…¥å¯ä»¥å¾ˆå¥½åœ°é¢„æµ‹å®ƒä»¬ä¹‹é—´æ˜¯å¦å­˜åœ¨æŸç§ç±»å‹çš„å…³ç³»ã€‚</p><p>To be more precise, the goal is to learn an embedding for each entity and a function for each relation type that takes two entity embeddings and assigns them a score, with the goal of having positive relations achieve higher scores than negative ones.<br>æ›´ç¡®åˆ‡åœ°è¯´ï¼ŒPBGçš„ç›®æ ‡æ˜¯å­¦ä¹ æ¯ä¸ªå®ä½“çš„åµŒå…¥å’Œæ¯ç§å…³ç³»ç±»å‹çš„å‡½æ•°ï¼Œè¯¥å‡½æ•°æ¥å—ä¸¤ä¸ªå®ä½“åµŒå…¥å¹¶ä¸ºå…¶åˆ†é…ä¸€ä¸ªåˆ†æ•°ï¼Œç›®çš„æ˜¯ä½¿æ­£é¢å…³ç³»æ¯”è´Ÿé¢å…³ç³»è·å¾—æ›´é«˜çš„åˆ†æ•°ã€‚</p><blockquote><p>key point: å®ä½“-&gt;Dç»´å‘é‡ å…³ç³»-&gt;å‡½æ•°</p></blockquote><p>All the edges provided in the training set are considered positive instances. In order to perform training, a set of negative edges is needed as well. These are not provided by the user but instead generated by the system during training (Negative sampling), usually by fixing the left-hand side entity and the relation type and sampling a new right-hand side entity, or vice versa. This sampling scheme makes sense for large sparse graphs, where there is a low probability that edges generated this way are true positives edges in the graph.<br>è®­ç»ƒé›†ä¸­æä¾›çš„æ‰€æœ‰è¾¹è¢«è§†ä¸ºæ­£ä¾‹ã€‚ä¸ºäº†æ‰§è¡Œè®­ç»ƒï¼Œè¿˜éœ€è¦ä¸€äº›è´Ÿè¾¹ï¼ˆè´Ÿæ ·æœ¬ï¼‰ã€‚ è¿™äº›ä¸æ˜¯ç”±ç”¨æˆ·æä¾›çš„ï¼Œè€Œæ˜¯ç”±ç³»ç»Ÿåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç”Ÿæˆçš„ï¼ˆè´Ÿé‡‡æ ·ï¼‰ï¼Œé€šå¸¸æ˜¯é€šè¿‡å›ºå®šå·¦ä¾§å®ä½“å’Œå…³ç³»ç±»å‹å¹¶é‡‡æ ·æ–°çš„å³ä¾§å®ä½“ï¼Œåä¹‹äº¦ç„¶ã€‚ å¯¹äºå¤§çš„ç¨€ç–å›¾ï¼Œè¿™ç§é‡‡æ ·æ–¹æ¡ˆæ˜¯æœ‰æ„ä¹‰çš„ï¼Œå› ä¸ºåœ¨è¿™æ ·çš„æƒ…å†µä¸‹ï¼Œä»¥è¿™ç§æ–¹å¼ç”Ÿæˆçš„è¾¹ä¸ºå›¾ä¸­çš„æ­£ä¾‹çš„å¯èƒ½æ€§å¾ˆå°ã€‚</p><p>A priori, entity embeddings could take any value in â„^D. Although, in some cases (for example when restricting them to be within a certain ball, or when comparing them using cosine distance), their â€œangleâ€ will have greater importance than their norm.<br>å…ˆéªŒå®ä½“åµŒå…¥å¯ä»¥åœ¨Dç»´ç©ºé—´ä¸­å–ä»»ä½•å€¼ã€‚ä½†æ˜¯åœ¨æŸäº›æƒ…å†µä¸‹ï¼ˆä¾‹å¦‚ï¼Œå½“å°†å®ƒä»¬é™åˆ¶åœ¨æŸä¸ªçƒå†…æˆ–ä½¿ç”¨ä½™å¼¦è·ç¦»è¿›è¡Œæ¯”è¾ƒæ—¶ï¼‰ï¼Œå®ƒä»¬çš„â€œè§’åº¦â€æ¯”èŒƒæ•°æ›´å…·æœ‰æ„ä¹‰ã€‚</p><p>Per-relation scoring functions, however, must be expressible in a specific form (the most common functions in the literature can be converted to such a representation). In the current implementation, they are only allowed to transform the embedding of one of the two sides, which is then compared to the un-transformed embedding of the other side using a generic symmetric comparator function, which is the same for all relations. Formally, for left- and right-hand side entities ğ‘¥ and ğ‘¦ respectively, and for a relation type ğ‘Ÿ, the score is:<center>ğ‘“ğ‘Ÿ(ğœƒğ‘¥,ğœƒğ‘¦)=ğ‘(ğœƒğ‘¥,ğ‘”ğ‘Ÿ(ğœƒğ‘¦))</center><br>where ğœƒğ‘¥ and ğœƒğ‘¦ are the embeddings of ğ‘¥ and ğ‘¦ respectively, ğ‘“ğ‘Ÿ is the scoring function for ğ‘Ÿ, ğ‘”ğ‘Ÿ is the operator for ğ‘Ÿ and ğ‘ is the comparator.</p><!-- $$f_{r}\left(\theta_{x}, \theta_{y}\right)=c\left(\theta_{x}, g_{r}\left(\theta_{y}\right)\right) --><p>ç„¶è€Œï¼Œå¯¹äºæ¯ä¸ªå…³ç³»çš„å¾—åˆ†è®¡ç®—å‡½æ•°ï¼Œå¿…é¡»ä»¥ç‰¹å®šçš„å½¢å¼è¡¨ç°å‡ºæ¥ï¼ˆæ–‡çŒ®ä¸­æœ€å¸¸è§çš„å‡½æ•°å¯ä»¥è½¬æ¢ä¸ºè¿™ç§è¡¨ç¤ºå½¢å¼ï¼‰ã€‚åœ¨ç›®å‰çš„å®ç°ä¸­ï¼Œåªå…è®¸å¯¹ä¸€ä¾§çš„å®ä½“è¿›è¡ŒåµŒå…¥è½¬æ¢ï¼Œé€šè¿‡ä½¿ç”¨é€šç”¨çš„å¯¹ç§°æ¯”è¾ƒå™¨å°†å…¶ä¸å¦ä¸€ä¾§æœªè½¬æ¢çš„å®ä½“åµŒå…¥è¿›è¡Œæ¯”è¾ƒï¼Œè¿™æ ·çš„æ“ä½œå¯¹äºæ‰€æœ‰çš„å…³ç³»ç±»å‹éƒ½æ˜¯ä¸€æ ·çš„ã€‚å½¢å¼ä¸Šï¼Œåˆ†åˆ«å¯¹äºå·¦ä¾§å’Œå³ä¾§å®ä½“ğ‘¥å’Œ,ï¼Œä»¥åŠå¯¹äºå…³ç³»ç±»å‹ğ‘Ÿï¼Œå¾—åˆ†ä¸ºï¼šğ‘“ğ‘Ÿ(ğœƒğ‘¥,ğœƒğ‘¦)=ğ‘(ğœƒğ‘¥,ğ‘”ğ‘Ÿ(ğœƒğ‘¦)), å…¶ä¸­ï¼Œğœƒğ‘¥å’Œğœƒğ‘¦åˆ†åˆ«æ˜¯ğ‘¥å’Œğ‘¦çš„åµŒå…¥ï¼Œğ‘“ğ‘Ÿæ˜¯å…³ç³»ğ‘Ÿçš„è¯„åˆ†å‡½æ•°ï¼Œğ‘”ğ‘Ÿæ˜¯å…³ç³»rçš„ç®—å­ï¼Œğ‘æ˜¯æ¯”è¾ƒå™¨ã€‚</p><p>Under â€œnormalâ€ circumstances (the so-called â€œstandardâ€ relations mode) the operator is solely applied to the right-hand side entities. This is not the case when using dynamic relations. Applying the operator to both sides would oftentimes be redundant. Also, preferring one side over the other allows to break the symmetry and capture the direction of the edge.<br>åœ¨é€šå¸¸æƒ…å†µä¸‹(æˆ–è€…è¯´æ˜¯æ ‡å‡†çš„å…³ç³»æ¨¡å¼ä¸­)ï¼Œç®—å­ä»…ä»…æ˜¯é€‚ç”¨äºå³ä¾§å®ä½“ã€‚ä½†æ˜¯åœ¨PBGçš„åŠ¨æ€å…³ç³»ä¸­åˆ™ä¸æ˜¯è¿™æ ·ã€‚é€šå¸¸ï¼Œå°†ç®—å­è¿ç”¨åœ¨ä¸¤ä¾§çš„å®ä½“åµŒå…¥ä¸Šæ˜¯å¤šä½™çš„ï¼Œå¹¶ä¸”å€¾å‘äºé€‰æ‹©æŸä¸€ä¾§çš„ä¸¾åŠ¨å¯ä»¥å¾ˆå¥½çš„æ‰“ç ´å¯¹ç§°æ€§å¹¶ä¸”æ•æ‰åˆ°è¾¹çš„æ–¹å‘ã€‚</p><h2 id="Embeddings"><a href="#Embeddings" class="headerlink" title="Embeddings"></a>Embeddings</h2><p>Embeddings live in a ğ·-dimensional real space, where ğ· is determined by the dimension configuration parameter.<br>åµŒå…¥æ˜¯ä¸€ä¸ªğ·ç»´å®ç©ºé—´çš„å‘é‡ï¼Œå…¶ä¸­ğ·çš„å¤§å°ç”±é…ç½®å‚æ•°ç¡®å®šã€‚</p><p>Normally, each entity has its own embedding, which is entirely independent from any other entityâ€™s embedding. When using featurized entities however this works differently, and an entityâ€™s embedding will be the average of the embeddings of its features.<br>é€šå¸¸çš„ï¼Œæ¯ä¸€ä¸ªå®ä½“éƒ½æœ‰å±äºè‡ªå·±çš„å®Œå…¨å’Œå…¶ä»–å®ä½“åµŒå…¥ç‹¬ç«‹çš„åµŒå…¥ã€‚ç„¶è€Œï¼Œå½“ä½¿ç”¨ç‰¹å¾åŒ–çš„å®ä½“æ—¶ï¼Œæƒ…å†µæœ‰æ‰€ä¸åŒã€‚æ­¤æ—¶å®ä½“çš„åµŒå…¥ä¸ºå…¶ç‰¹å¾åµŒå…¥çš„å¹³å‡å€¼ã€‚</p><p>If the max_norm configuration parameter is set, embeddings will be projected onto the unit ball with radius max_norm after each parameter update.<br>å¦‚æœè®¾ç½®äº†max_normé…ç½®å‚æ•°ï¼Œåˆ™åœ¨æ¯æ¬¡æ›´æ–°å‚æ•°åï¼ŒåµŒå…¥å°†ä¼šè¢«æŠ•å½±åˆ°åŠå¾„ä¸ºmax_normçš„å•ä½çƒä¸Šã€‚</p><blockquote><p>ğŸ¤”ï¸ æš‚æ—¶æ²¡çœ‹æ‡‚ã€‚</p></blockquote><p>To add a new type of embedding, one needs to subclass the torchbiggraph.model.AbstractEmbedding class.<br>è¦æ·»åŠ ä¸€ç§æ–°å‹çš„åµŒå…¥ï¼Œéœ€è¦å°†torchbiggraph.model.AbstractEmbeddingç±»ä½œä¸ºå­ç±»ã€‚</p><blockquote><p>ğŸ¤”ï¸ æš‚æ—¶æ²¡çœ‹æ‡‚ã€‚</p></blockquote><h2 id="Global-embeddings"><a href="#Global-embeddings" class="headerlink" title="Global embeddings"></a>Global embeddings</h2><p>When the global_emb configuration option is active, each entityâ€™s embedding will be translated by a vector that is specific to each entity type (and that is learned at the same time as the embeddings).<br>å½“global_embé…ç½®å‚æ•°è®¾ç½®ä¸ºTrueçš„æ—¶å€™ï¼Œæ¯ä¸ªå®ä½“çš„åµŒå…¥å°†ä¼šè¢«è¡¨ç¤ºæˆä¸€ä¸ªå‘é‡ï¼Œè¯¥å‘é‡å¯¹äºæ¯ç§å®ä½“ç±»å‹éƒ½æ˜¯ç‰¹å®šçš„ã€‚ï¼ˆå¹¶ä¸”è¯¥å‘é‡æ˜¯ä¸åµŒå…¥åŒæ—¶å­¦ä¹ å¾—åˆ°çš„ï¼‰</p><blockquote><p>ğŸ¤”ï¸ æš‚æ—¶æ²¡çœ‹æ‡‚ã€‚</p></blockquote><h2 id="Operators"><a href="#Operators" class="headerlink" title="Operators"></a>Operators</h2><p>The operators that are currently provided are:<br>â€¢ none, no-op, which leaves the embeddings unchanged;<br>â€¢ translation, which adds to the embedding a vector of the same dimension;<br>â€¢ diagonal, which multiplies each dimension by a different coefficient (equivalent to multiplying by a diagonal matrix);<br>â€¢ linear, which applies a linear map, i.e., multiplies by a full square matrix<br>â€¢ affine, which applies a affine transformation, i.e., linear followed by translation.<br>â€¢ complex_diagonal, which interprets the ğ·-dimensional real vector as a ğ·/2-dimensional complex vector (ğ· must be even; the first half of the vector are the real parts, the second half the imaginary parts) and then multiplies each entry by a different complex parameter, just like diagonal.<br>å½“å‰æä¾›çš„ç®—å­æœ‰:<br>â€¢ æ— ï¼Œæ— æ“ä½œï¼Œä½¿åµŒå…¥ä¿æŒä¸å˜ï¼›<br>â€¢ å¹³ç§»ç®—å­ï¼Œå°†ç›¸åŒå°ºå¯¸çš„å‘é‡æ·»åŠ åˆ°åµŒå…¥ä¸­ï¼›<br>â€¢ å¯¹è§’ç®—å­ï¼Œå°†æ¯ä¸ªç»´åº¦ä¹˜ä»¥ä¸åŒçš„ç³»æ•°ï¼ˆç›¸å½“äºä¹˜ä»¥å¯¹è§’çŸ©é˜µï¼‰ï¼›<br>â€¢ çº¿æ€§ç®—å­ï¼Œè¿ç”¨ä¸€ä¸ªçº¿æ€§æ˜ å°„ï¼Œä¾‹å¦‚ï¼Œè®²åµŒå…¥å’Œä¸€ä¸ªå…¨æ–¹é˜µç‚¹ä¹˜ï¼›<br>â€¢ ä»¿å°„ç®—å­ï¼Œåº”ç”¨ä»¿å°„å˜æ¢ï¼Œå³çº¿æ€§å˜æ¢åå†è¿›è¡Œå¹³ç§»ï¼›<br>â€¢ å¤å¯¹è§’ç®—å­ï¼Œå°†Dç»´å®å‘é‡è½¬åŒ–ä¸ºD/2ç»´å¤çŸ¢é‡ï¼ˆğ·å¿…é¡»æ˜¯å¶æ•°ï¼›çŸ¢é‡çš„å‰åŠéƒ¨åˆ†æ˜¯å®æ•°éƒ¨åˆ†ï¼ŒååŠéƒ¨åˆ†æ˜¯è™šæ•°éƒ¨åˆ†ï¼‰ï¼Œç„¶åå°†æ¯ä¸ªé¡¹ä¹˜ä»¥ä¸åŒçš„å¤æ•°å‚æ•°ï¼Œå°±åƒå¯¹è§’ç®—å­ä¸€æ ·ã€‚</p><p>All the operatorsâ€™ parameters are learned during training.<br>è®­ç»ƒè¿‡ç¨‹ä¸­å°†å­¦ä¹ æ‰€æœ‰ç®—å­çš„å‚æ•°ã€‚</p><p>To define an additional operator, one must subclass the torchbiggraph.model.AbstractOperator class (or the torchbiggraph.model.AbstractDynamicOperator one when using dynamic relations; their docstrings explain what must be implemented) and decorate it with the torchbiggraph.model.OPERATORS.register_as() decorator (respectively the torchbiggraph.model.DYNAMIC_OPERATORS.register_as() one), specifying a new name that can then be used in the config to select that comparator. All of the above can be done inside the config file itself.<br>å¦‚æœè¦è‡ªå®šä¹‰æ–°çš„ç®—å­ï¼Œéœ€è¦å®ç°torchbiggraph.model.AbstractOperatorçš„å­ç±»ï¼ˆåŠ¨æ€å…³ç³»æƒ…å†µä¸‹å®ç°torchbiggraph.model.AbstractDynamicOperatorå­ç±»ï¼Œdocstringsè§£é‡Šäº†å¿…é¡»å®ç°ä»€ä¹ˆï¼‰å¹¶ä¸”åœ¨torchbiggraph.model.OPERATORS.register_as()è£…é¥°å™¨ä¸­æ³¨å†Œï¼ˆæˆ–è€…torchbiggraph.model.DYNAMIC_OPERATORS.register_as() ï¼‰æŒ‡å®šä¸€ä¸ªæ–°åç§°ï¼Œç„¶ååœ¨é…ç½®ä¸­ä½¿ç”¨è¯¥åç§°æ¥é€‰æ‹©æ¯”è¾ƒå™¨ã€‚ä¸Šè¿°æ‰€æœ‰æ“ä½œéƒ½å¯ä»¥åœ¨é…ç½®æ–‡ä»¶å†…éƒ¨å®Œæˆã€‚</p><blockquote><p>ğŸ¤”ï¸ æš‚æ—¶æ²¡çœ‹æ‡‚ã€‚</p></blockquote><h2 id="Comparators"><a href="#Comparators" class="headerlink" title="Comparators"></a>Comparators</h2><p>The available comparators are:<br>â€¢ dot, the dot-product, which computes the scalar or inner product of the two embedding vectors;<br>â€¢ cos, the cos distance, which is the cosine of the angle between the two vectors or, equivalently, the dot product divided by the product of the vectorsâ€™ norms.<br>â€¢ l2, the negative L2 distance, a.k.a. the Euclidean distance (negative because smaller distances should get higher scores).<br>â€¢ squared_l2, the negative squared L2 distance.<br>å½“å‰æä¾›çš„æ¯”è¾ƒå™¨æœ‰ï¼š<br>â€¢ ç‚¹ä¹˜ï¼Œè®¡ç®—ä¸¤ä¸ªå®ä½“åµŒå…¥å‘é‡çš„æ ‡é‡æˆ–å†…ç§¯ï¼›<br>â€¢ ä½™å¼¦è·ç¦»ï¼Œä¸¤ä¸ªå®ä½“åµŒå…¥å‘é‡çš„ä½™å¼¦å¤¹è§’ï¼Œæˆ–è€…ç­‰æ•ˆçš„è¯´æ˜¯ dot(a,b)/(sqrt(a^2)*sqrt(a^2))<br>â€¢ è´ŸL2è·ç¦»ï¼Œåˆç§°æ¬§å‡ é‡Œå¾—è·ç¦»ï¼ˆä½¿ç”¨è´Ÿçš„äºŒèŒƒæ•°æ˜¯å› ä¸ºçœŸæ­£æ¯”è¾ƒçš„æ˜¯ä¸¤è€…çš„ç›¸ä¼¼åº¦ï¼Œè¾ƒå°çš„è·ç¦»åº”è·å¾—æ›´é«˜çš„åˆ†æ•°ï¼Œè¿™é‡Œçš„åˆ†æ•°å…¶å®å°±ç±»ä¼¼äºç›¸ä¼¼åº¦)<br>â€¢ L2çš„è´Ÿå¹³æ–¹è·ç¦»ã€‚</p><p>Custom comparators need to extend the torchbiggraph.model.AbstractComparator class (its docstring explains how) and decorate it with the torchbiggraph.model.COMPARATORS.register_as() decorator, specifying a new name that can then be used in the config to select that comparator. All of the above can be done inside the config file itself.<br>è‡ªå®šä¹‰æ¯”è¾ƒå™¨éœ€è¦æ‰©å±•torchbiggraph.model.AbstractComparatorç±»ï¼ˆå…¶æ–‡æ¡£å­—ç¬¦ä¸²è¯´æ˜æ–¹å¼ï¼‰ï¼Œå¹¶ä½¿ç”¨torchbiggraph.model.COMPARATORS.register_asï¼ˆï¼‰è£…é¥°å™¨å¯¹å…¶è¿›è¡Œä¿®é¥°ï¼Œå¹¶æŒ‡å®šä¸€ä¸ªæ–°åç§°ï¼Œè¯¥åç§°éšåå¯åœ¨é…ç½®ä¸­ç”¨äºé€‰æ‹©è¯¥æ¯”è¾ƒå™¨ã€‚ä»¥ä¸Šæ‰€æœ‰æ“ä½œå‡å¯åœ¨é…ç½®æ–‡ä»¶æœ¬èº«ä¸­å®Œæˆã€‚</p><h2 id="Bias"><a href="#Bias" class="headerlink" title="Bias"></a>Bias</h2><p>If the bias configuration key is in use, then the first coordinate of the embeddings will act as a bias in the comparator computation. This means that the comparator will be computed on the last ğ·âˆ’1 entries of the vectors only, and then both the first entries of the two vectors will be added to the result.<br>å¦‚æœbiaså‚æ•°åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®ä¸ºTrueï¼Œé‚£ä¹ˆåµŒå…¥çš„ç¬¬ä¸€ä¸ªåæ ‡å°†å……å½“æ¯”è¾ƒå™¨è®¡ç®—ä¸­çš„åç½®ã€‚è¿™æ„å‘³ç€æ¯”è¾ƒå™¨å°†ä»…åœ¨å‘é‡å¾—ç¬¬äºŒç»´åˆ°ç¬¬Dç»´ä¸Šè¿›è¡Œè®¡ç®—ï¼Œç„¶åå°†ä¸¤ä¸ªå‘é‡çš„ç¬¬ä¸€ç»´éƒ½ç›´æ¥è¢«æ·»åŠ åˆ°ç»“æœä¸­ã€‚</p><h2 id="Coherent-sets-of-configuration-parameters"><a href="#Coherent-sets-of-configuration-parameters" class="headerlink" title="Coherent sets of configuration parameters"></a>Coherent sets of configuration parameters</h2><p>While the parameters described in this chapter are exposed as uncoupled knobs in the configuration file (to more closely match the implementation, and to allow for more flexible tuning), some combinations of them are more sensible than others.<br>å°½ç®¡æœ¬ç« ä¸­æè¿°çš„å‚æ•°åœ¨é…ç½®æ–‡ä»¶ä¸­æ˜¾ç¤ºä¸ºæœªè€¦åˆçš„æ—‹é’®ï¼ˆä¸ºäº†æ›´è¿‘ä¼¼åŒ¹é…å®ç°æ•ˆæœï¼Œå¹¶å…è®¸æ›´çµæ´»çš„è°ƒä¼˜ï¼‰ï¼Œä½†å®ƒä»¬ä¸­çš„æŸäº›ç»„åˆæ¯”å…¶ä»–ç»„åˆæ›´åˆç†ã€‚</p><p>Apart from the default one, the following configuration has been found to work well: init_scale = 0.1, comparator = dot, bias = true, loss_fn = logistic, lr = 0.1.<br>é™¤é»˜è®¤é…ç½®å¤–ï¼Œè¿˜å‘ç°ä»¥ä¸‹é…ç½®å¯ä»¥æ­£å¸¸è¿è¡Œï¼šinit_scale = 0.1ï¼Œcomparator = dot, bias = true, loss_fn = logistic, lr = 0.1ã€‚</p><h2 id="Interpreting-the-scores"><a href="#Interpreting-the-scores" class="headerlink" title="Interpreting the scores"></a>Interpreting the scores</h2><p>The scores will be tuned to have different meaning and become more suitable for certain applications based on the loss function used during training. Common options include ranking what other entities may be related to a given entity, determining the probability that a certain relation exists between two given entities, etc.<br>æ ¹æ®è®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨çš„æŸå¤±å‡½æ•°ï¼Œå¾—åˆ†å°†è¢«è°ƒæ•´ä¸ºå…·æœ‰ä¸åŒçš„å«ä¹‰ï¼Œå¹¶ä¸”å˜å¾—æ›´é€‚åˆæŸäº›ç‰¹å®šçš„åº”ç”¨ã€‚å¸¸è§é€‰é¡¹åŒ…æ‹¬å¯¹å…¶ä»–å®ä½“å¯èƒ½ä¸ç»™å®šå®ä½“ç›¸å…³çš„ç­‰çº§è¿›è¡Œæ’åã€ç¡®å®šä¸¤ä¸ªç»™å®šå®ä½“ä¹‹é—´å­˜åœ¨æŸç§å…³ç³»çš„å¯èƒ½æ€§ç­‰æŒ‡æ ‡ã€‚</p><p>æºåœ°å€ï¼š<br><a href="https://torchbiggraph.readthedocs.io/en/latest/scoring.html">https://torchbiggraph.readthedocs.io/en/latest/scoring.html</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>PyTorch-BigGraph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ç¤¾äº¤ç½‘ç»œ</title>
    <link href="/2020/10/23/Social-network/"/>
    <url>/2020/10/23/Social-network/</url>
    
    <content type="html"><![CDATA[<h2 id="æ€»è§ˆ"><a href="#æ€»è§ˆ" class="headerlink" title="æ€»è§ˆ"></a>æ€»è§ˆ</h2><p>ç¤¾äº¤ç½‘ç»œä¸å›¾, ç¤¾äº¤ç½‘ç»œçš„èšç±», ç¤¾åŒºå‘ç°</p><h2 id="ç¤¾äº¤ç½‘ç»œä¸å›¾"><a href="#ç¤¾äº¤ç½‘ç»œä¸å›¾" class="headerlink" title="ç¤¾äº¤ç½‘ç»œä¸å›¾"></a>ç¤¾äº¤ç½‘ç»œä¸å›¾</h2><p>1.What is a network? a network can be defined as a graph in which nodes and/or edges have attributes (e.g. names). å¸¦æœ‰å±æ€§ä¿¡æ¯çš„å›¾</p><p>2.Networkâ€™s properties:</p><ul><li>size: # of nodes/edges</li><li>node degree: # of links to other nodes</li><li>degree distribution: probability that a randomly selected node has degree k<ul><li>scale-free network: network whose degree distribution follows a power law, at least asymptotically. ç½‘ç»œä¸­çš„å¤§éƒ¨åˆ†èŠ‚ç‚¹åªå’Œå¾ˆå°‘èŠ‚ç‚¹è¿æ¥ï¼Œè€Œæœ‰æå°‘çš„èŠ‚ç‚¹ä¸éå¸¸å¤šçš„èŠ‚ç‚¹è¿æ¥,å¹‚å¾‹åˆ†å¸ƒ/é•¿å°¾æ•ˆåº”</li><li>Real networks are scale-free</li></ul></li><li>path,</li><li>shortest path </li><li>diameter: shortest path between most distant nodes/maximal shortest path<br>â€¦</li></ul><p>3.Mathematical representation<br>Adjacency matrix : A<br>Path matrix: å¯ä»¥é€šè¿‡é‚»æ¥çŸ©é˜µè®¡ç®—è·¯å¾„çŸ©é˜µ, A^l ç»“æœè¡¨ç¤ºä¸ºè·¯å¾„çŸ©é˜µ</p><p>3.Phenomena arise as a result of properties: </p><ul><li><p>Friendship paradox: on average, your friends have more friends than you do, å‹è°Šæ‚–è®º</p></li><li><p>Small world: most nodes are not neighbors of one another,but most nodes can be reached from every other by a small number of hops or steps. å°ä¸–ç•Œç†è®ºï¼Œå…­åº¦ç©ºé—´</p><ul><li>The typical distance L between two randomly chosen nodes grows proportionally to the logarithm of the number of nodes N in the network, ä¸¤ä¸ªèŠ‚ç‚¹çš„è·ç¦»å’Œæ•´ä¸ªç½‘ç»œçš„èŠ‚ç‚¹æ•°çš„å¯¹æ•°æˆæ­£æ¯”<br><img src="/image/small_world.png"></li></ul></li><li><p>Perception bias in networks,ç½‘ç»œä¸­å­˜åœ¨æ„ŸçŸ¥è¯¯å·®</p></li></ul><h2 id="ç¤¾äº¤ç½‘ç»œçš„èšç±»"><a href="#ç¤¾äº¤ç½‘ç»œçš„èšç±»" class="headerlink" title="ç¤¾äº¤ç½‘ç»œçš„èšç±»"></a>ç¤¾äº¤ç½‘ç»œçš„èšç±»</h2><p>æ–¹å¼:<br>1.Hierarchical</p><ul><li>Agglomerative (bottom-up):<br>  Initially, each point is a clusterï¼Œæ¯ä¸ªç‚¹éƒ½æ˜¯ä¸€ä¸ªcluster<br>  Repeatedly combine the two â€œnearestâ€ clusters into oneï¼Œä¸æ–­å¾€ä¸Šå»åˆå¹¶ç‚¹ï¼Œæœ€ç»ˆå¾—åˆ°ç»“æœã€‚<br>  Use distance metric</li><li>Divisive (top-down):  ==&gt;&gt; æœ¬æ–‡å…³æ³¨çš„ç®—æ³•<br>  Start with one cluster and recursively split it æ•´ä¸ªå›¾ä¸ºä¸€ä¸ªclusterï¼Œä¸æ–­å»ç»†åˆ†clusters</li></ul><p>2.Point assignment<br>    Maintain a set of clusters<br>    Points belong to â€œnearestâ€ cluster<br>    Use distance metric</p><p>ç¤¾äº¤ç½‘ç»œä¸­è·ç¦»æŒ‡æ ‡</p><p>1.d(x, y) is 0 if there is an edge and 1 if there is no such edge.<br>é™åˆ¶ğŸš«: violate the triangle inequality<br>ä¾‹å­: å‡è®¾A,B,Cä¸‰ç‚¹,ACä¸€è¾¹,é‚£ä¹ˆ d(A,B) = d(B,C) = 0 and d(A,C) = 1 &gt; d(A,B) + d(B,C) </p><p>====&gt;</p><p>2.Shortest path distance: Minimum # of edges connecting to nodes:<br>ä¾‹å­: å‡è®¾A,B,Cä¸‰ç‚¹ï¼Œè¾¹ABï¼ŒBCï¼Œé‚£ä¹ˆd(A,B) = d(B,C) = 1   and  d(A,C) = 2</p><p>The problem is more complex because the distance between data points (nodes) is not measured by Euclidian<br>ç”±æ­¤å¯ä»¥çœ‹åˆ°ä¼ ç»Ÿçš„èšç±»æ–¹æ³•ï¼ˆKNNï¼ŒKmeansï¼‰ä¸å¤ªé€‚ç”¨äºç¤¾äº¤ç½‘ç»œçš„èšç±»ï¼Œå› ä¸ºè·ç¦»æŒ‡æ ‡è®¡ç®—å¾ˆå¤æ‚</p><p>====&gt;<br>3. Betweenness ä¸­ä»‹æ€§/å±…é—´æ€§</p><p>Edge betweenness: # of shortest paths passing over the edge<br>è¾¹çš„ä¸­ä»‹æ€§ï¼Œç®€å•ç†è§£å°±æ˜¯ç»è¿‡è¯¥æ¡è¾¹çš„æœ€çŸ­è·¯å¾„æ•°ç›®</p><p>example:Betweenness of edge (a, b):<br>number of pairs of nodes x and y -&gt; x<br>edge (a,b) lies on the shortest path between x and y</p><p>However,if there are several shortest paths between x and y, edge (a,b) is credited with the fraction of those shortest paths that include edge (a,b)</p><p>ä½†æ˜¯!!!y-&gt;xçš„æœ€çŸ­è·¯å¾„ä¸åªæœ‰ä¸€æ¡ï¼Œå‡è®¾y-&gt;xçš„æœ€çŸ­è·¯å¾„æœ‰3æ¡ï¼Œå…¶ä¸­æœ‰ä¸€æ¡è¿›è¿‡äº†è¾¹(a,b),é‚£ä¹ˆè¿™ä¸€æ¡æœ€çŸ­è·¯å¾„ä¸ºï¼ˆa,bï¼‰çš„ä¸­ä»‹æ€§è´¡çŒ®äº†1/3</p><p>A high score is bad: suggests that edge (a,b) runs between two different communities<br>æˆ‘ä»¬å¯ä»¥å‘ç°å¦‚æœä¸€æ¡è¾¹çš„ä¸­ä»‹æ€§å¾ˆé«˜çš„è¯ï¼Œè¡¨æ˜aå’Œbæ˜¯å±äºä¸¤ä¸ªä¸åŒçš„ç¤¾åŒº&lt;&lt;== èšç±»å®ç°</p><p><img src="/image/edge_betweeness.png"></p><h2 id="ç¤¾åŒºå‘ç°"><a href="#ç¤¾åŒºå‘ç°" class="headerlink" title="ç¤¾åŒºå‘ç°"></a>ç¤¾åŒºå‘ç°</h2><h3 id="åˆ©ç”¨betweenessçš„ç¤¾åŒºå‘ç°ç®—æ³•ï¼šGirvan-Newman-Algorithm"><a href="#åˆ©ç”¨betweenessçš„ç¤¾åŒºå‘ç°ç®—æ³•ï¼šGirvan-Newman-Algorithm" class="headerlink" title="åˆ©ç”¨betweenessçš„ç¤¾åŒºå‘ç°ç®—æ³•ï¼šGirvan-Newman Algorithm"></a>åˆ©ç”¨betweenessçš„ç¤¾åŒºå‘ç°ç®—æ³•ï¼šGirvan-Newman Algorithm</h3><p>Idea: discover communities using divisive hierarchical clustering (Start with one cluster (the social network) and recursively split it)</p><p>Strategy: edge betweenness(# of shortest paths passing through the edge)</p><p>Algorithm: Girvan-Newman Algorithm</p><p>Repeat until no edges are left:<br>    Calculate betweenness of edges<br>    Remove edges with highest betweenness</p><p>Result: Connected components are communities<br><img src="/image/GN.png"></p><p>ä½†æ˜¯é€šè¿‡ä¸Šè¿°çš„æè¿°å¯ä»¥å‘ç°ï¼Œé€šè¿‡ä¸æ–­çš„ç§»é™¤æœ€å¤§çš„edge betweenessï¼Œæœ€åå¾—åˆ°ç»“æœæ˜¯ä¸€ä¸ªä¸ªå­¤ç«‹çš„ç‚¹ï¼Œæ‰€ä»¥éœ€è¦æ˜ç¡®ä»¥ä¸‹ä¸¤ç‚¹:<br>1.How to compute betweenness?<br>2.How to select the number of clusters?</p><h4 id="Compute-betweenness"><a href="#Compute-betweenness" class="headerlink" title="Compute betweenness"></a>Compute betweenness</h4><p>Strategy: BFS</p><p>1.Perform a breadth-first search (BFS) of the graph, starting at node X<br>é¦–å…ˆå¯¹äºæ¯ä¸€ä¸ªç‚¹ Xï¼Œå¾—åˆ°ä¸€ä¸ªBFS treeï¼Œè¿™ä¸ªBFS treeå¯ä»¥åæ˜ å‡ºè¯¥ç‚¹åˆ°å…¶ä»–æ‰€æœ‰ç‚¹çš„æœ€çŸ­è·¯å¾„</p><p>2.Label each node by the number of shortest paths that reach it from the root node<br>æ ‡è®°å¤„æ¯ä¸ªç‚¹åˆ°root node Xçš„æœ€çŸ­è·¯å¾„æ•°ç›®<br><img src="/image/label_sp_num.png"></p><p>3.Calculate for each edge e, the sum over all nodes Y (of the fraction) of the shortest paths from the root X to Y that go through edge e<br>ä¸ºæ¯æ¡è¾¹eè®¡ç®—ä»root nodeXåˆ°å…¶ä»–æ‰€æœ‰ç‚¹Yçš„æœ€çŸ­è·¯å¾„ä¸­ç»è¿‡eçš„æ€»å’Œ(åŒ…æ‹¬åˆ†æ•°éƒ¨åˆ†)</p><p>å…·ä½“è®¡ç®—:<br><img src="/image/step1.png"><br>ç¬¬ä¸€æ­¥: ä»åº•éƒ¨å¼€å§‹<br>â€¢ A and C are leaves: get credit = 1;<br>â€¢ Each of these nodes has only one parent, so their credit=1 is given to edges (B,A) and (B,C)<br>â€¢ At level 2, G is a leaf: gets credit = 1<br>â€¢ B gets credit 1 + credit of DAG edges entering from below = 1 + 1 +1 = 3<br>â€¢ B has only one parent, so edge (D,B) gets entire credit of node B = 3</p><p>ç¬¬äºŒæ­¥:ç¢°è§éœ€è¦æ‹†åˆ†çš„æƒ…å†µ G has 2 parents<br><img src="/image/step2.png"><br>â€¢ In this case, both D and F have just one shortest path from E to each of those nodes<br>    â€¢ So, give half credit of node G to each of those edges<br>    â€¢ Credit = 1/(1 + 1) = 0.5<br>â€¢ In general, how we distribute credit of a node to its edges depends on number of shortest paths<br>    â€¢ Say there were 5 shortest paths to D and only 3 to F<br>    â€¢ Then credit of edge (D,G) = 5/8 and credit of edge (F,G) = 3/8<br>â€¢ Node D gets credit = 1 + credits of edges below it = 1 + 3 + 0.5 = 4.5<br>â€¢ Node F gets credit = 1 + 0.5 = 1.5<br>â€¢ D has only one parent, so Edge (E,D) gets credit = 4.5 from D<br>â€¢ Likewise for F: Edge (E,F) gets credit = 1.5 from F.</p><p>To complete betweenness calculation, must: </p><ul><li>Repeat this for every node as root</li><li>Sum the contributions on each edge</li><li>Divide by 2 to get true betweenness<ul><li>since every shortest path will be counted twice, once for each of its endpoints</li></ul></li></ul><p>ä»¥ä¸Šä»…ä»…æ˜¯å¯¹é’ˆå¯¹ä¸€ä¸ªèŠ‚ç‚¹è®¡ç®—çš„å„ä¸ªè¾¹çš„betweenessï¼Œéœ€è¦å¯¹æ¯ä¸ªèŠ‚ç‚¹é‡å¤è¿™æ ·çš„è®¡ç®—éšåç´¯åŠ é™¤ä»¥2å¾—åˆ°æœ€ç»ˆç»“æœã€‚ä»è¿™é‡Œä¹Ÿå¯ä»¥å‘ç°GNæ˜¯é’ˆå¯¹æ— å‘å›¾çš„ï¼Œå¦‚æœæ˜¯æœ‰å‘å›¾çš„è¯ï¼Œå°±ä¸éœ€è¦é™¤ä»¥2äº†ã€‚</p><h4 id="Select-the-number-of-clusters"><a href="#Select-the-number-of-clusters" class="headerlink" title="Select the number of clusters"></a>Select the number of clusters</h4><p>Communities: sets of tightly connected nodes</p><p>Modularity Q: A measure of how well a network is partitioned into communities<br>æ¨¡å—ï¼šè¡¡é‡ä¸€ä¸ªç½‘ç»œä¸­ç¤¾åŒºèšç±»å¥½åçš„æŒ‡æ ‡</p><blockquote><p>Modularity compares the number of edges inside a cluster with the expected number of edges that one would find in the cluster if the network were a random network with the same number of nodes and where each node keeps its degree, but edges are otherwise randomly attached.<br> Networks with high modularity have dense connections between the nodes within groups but sparse connections between nodes in different groups.<br> The null model is a graph which matches one specific graph in some of its structural features, but which is otherwise taken to be an instance of a random graph. The null model is used as a term of comparison, to verify whether the graph in question displays some feature, such as community structure, or not.</p></blockquote><p><img src="/image/modularity.png"></p><p>rclone mount GD: /nas/home/binzhang/data â€“allow-other â€“allow-non-empty â€“vfs-cache-mode writes</p><p>rclone mount GD: /nas/home/binzhang/GoogleDrive â€“allow-other â€“allow-non-empty â€“vfs-cache-mode writes</p><p> rclone copy /home/backup gdrive:backu</p>]]></content>
    
    
    
    <tags>
      
      <tag>Data mining</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DSCI-553-outline</title>
    <link href="/2020/10/23/DSCI-553-outline/"/>
    <url>/2020/10/23/DSCI-553-outline/</url>
    
    <content type="html"><![CDATA[<h2 id="DSCI551-Foundations-and-Applications-of-Data-Mining"><a href="#DSCI551-Foundations-and-Applications-of-Data-Mining" class="headerlink" title="DSCI551 - Foundations and Applications of Data Mining"></a>DSCI551 - Foundations and Applications of Data Mining</h2><h3 id="Week1"><a href="#Week1" class="headerlink" title="Week1:  "></a>Week1:  <a href="/2020/11/10/553week1/" title="æ•°æ®æŒ–æ˜, MapReduce ä»‹ç»">æ•°æ®æŒ–æ˜, MapReduce ä»‹ç»</a></h3><h3 id="Part2"><a href="#Part2" class="headerlink" title="Part2:"></a>Part2:</h3><!-- <a href="/2020/09/07/JSON-review/" title="JSON-review">JSON-review</a>  --><h3 id="Part3"><a href="#Part3" class="headerlink" title="Part3: "></a>Part3: <a href="/2020/10/23/Social-network/" title="ç¤¾äº¤ç½‘ç»œ">ç¤¾äº¤ç½‘ç»œ</a></h3><!-- <a href="/2020/09/10/File-Systems/" title="File systems">File systems</a>  -->]]></content>
    
    
    
    <tags>
      
      <tag>Course</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>sshè¿æ¥è¿œç¨‹æœåŠ¡å™¨ä¸­é€”æ–­å¼€</title>
    <link href="/2020/10/23/Linux-screen/"/>
    <url>/2020/10/23/Linux-screen/</url>
    
    <content type="html"><![CDATA[<h2 id="é—®é¢˜æè¿°"><a href="#é—®é¢˜æè¿°" class="headerlink" title="é—®é¢˜æè¿°"></a>é—®é¢˜æè¿°</h2><p>Macæœºå™¨ä½¿ç”¨sshæ“ä½œè¿œç¨‹æœåŠ¡å™¨çš„é€”ä¸­,ç”±äºç½‘ç»œæ³¢åŠ¨,æ–­å¼€è¿æ¥,ä¼‘çœ ç­‰ä¸€ç³»åˆ—å¥‡è‘©åŸå› å¯¼è‡´ç»ˆç«¯<code>client_loop: send disconnect: Broken pipe</code>,<br>åœ¨è¿™æ ·çš„æƒ…å†µä¸‹ï¼Œè¿œç¨‹æœåŠ¡å™¨ä¹Ÿè·Ÿç€æ‰çº¿ã€‚</p><h2 id="éœ€æ±‚"><a href="#éœ€æ±‚" class="headerlink" title="éœ€æ±‚"></a>éœ€æ±‚</h2><p>å³ä½¿æœ¬åœ°Macæ‰çº¿ï¼Œè¿œç¨‹æœåŠ¡å™¨ä»æ—§ä¿æŒå·¥ä½œ</p><h2 id="è§£å†³æ–¹å¼-Screen"><a href="#è§£å†³æ–¹å¼-Screen" class="headerlink" title="è§£å†³æ–¹å¼: Screen"></a>è§£å†³æ–¹å¼: Screen</h2><ol><li><p>è¿æ¥è¿œç¨‹æœåŠ¡å™¨<br><code>binzhang@MacBin ~$  ssh username@servername</code></p></li><li><p>åˆ›å»ºåä¸ºcskgçš„screen,  æ­¤æ—¶screenè¢«åˆ›å»ºï¼Œä¹‹åçš„ä»£ç æˆ–è€…å„ç§å·¥ä½œåœ¨è¯¥screenä¸‹æ“ä½œ<br><code>[servername ~]$ screen -S cskg </code></p></li><li><p>ä¸‡ä¸€æœ¬åœ°æœºå™¨æ‰çº¿ï¼Œé‡æ–°è¿æ¥è¿œç¨‹æœåŠ¡å™¨ï¼Œéšåä½¿ç”¨screen -ls æŸ¥çœ‹ä¹‹å‰åˆ›å»ºçš„screenä¿¡æ¯</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs routeros">[servername ~]$<span class="hljs-built_in"> screen </span>-ls  <br>æ˜¾ç¤ºä¿¡æ¯ï¼š<br>There is a<span class="hljs-built_in"> screen </span>on:<br>        157586.cskg  (Attached)<br>1 Socket <span class="hljs-keyword">in</span> /var/run/screen/xx<br></code></pre></td></tr></table></figure></li><li><p>ä½¿ç”¨-rå›åˆ°ä¹‹å‰æœåŠ¡å™¨å·¥ä½œçš„screen<br><code>screen -r 157586</code></p></li></ol><h3 id="Screenå¸¸è§é—®é¢˜"><a href="#Screenå¸¸è§é—®é¢˜" class="headerlink" title="Screenå¸¸è§é—®é¢˜"></a>Screenå¸¸è§é—®é¢˜</h3><p>ä½¿ç”¨<code>screen -ls</code>, æ˜¾å¼å½“å‰çŠ¶æ€ä¸ºAttachedï¼Œä½†å¹¶æ²¡æœ‰æ²¡æœ‰ç”¨æˆ·ç™»é™†è¯¥screenã€‚screenæ­¤æ—¶æ­£å¸¸çŠ¶æ€åº”è¯¥ä¸º(Detached)ä½¿ç”¨ <code>screen -r &lt;session-id&gt;</code>æ— æ³•è¿æ¥ï¼Œ</p><p>è§£å†³æ–¹æ¡ˆ:<code>screen -D  -r ï¼œsession-id&gt;</code>,-D -r  è¡¨ç¤ºå…ˆè¸¢æ‰å‰ç”¨æˆ·ï¼Œå†ç™»é™†ã€‚</p>]]></content>
    
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch-BigGraph æ•°æ®æ¨¡å‹</title>
    <link href="/2020/10/22/PBG-Data-model/"/>
    <url>/2020/10/22/PBG-Data-model/</url>
    
    <content type="html"><![CDATA[<h1 id="PBGæ¨¡å‹"><a href="#PBGæ¨¡å‹" class="headerlink" title="PBGæ¨¡å‹"></a>PBGæ¨¡å‹</h1><p>PBG operates on directed multi-relation multigraphs, whose vertices are called entities. Each edge connects a source to a destination entity, which are respectively called its left- and right-hand side (shortened to LHS and RHS). Multiple edges between the same pair of entities are allowed. Loops, i.e., edges whose left- and right- hand sides are the same, are allowed as well.<br>PBGä½œç”¨åœ¨æœ‰å‘å¤šå…³ç³»å¤šå›¾ä¸Šï¼Œå…¶ä¸­ï¼Œå›¾çš„é¡¶ç‚¹ç§°ä¸ºå®ä½“ã€‚æ¯ä¸€æ¡è¾¹å°†æºå®ä½“è¿æ¥åˆ°ç›®æ ‡å®ä½“ï¼Œæºå®ä½“ç§°ä¸ºå·¦ä¾§ï¼Œç›®æ ‡å®ä½“ç§°ä¸ºå³ä¾§(ç¼©å†™ä¸ºLHSå’ŒRHS)åŒä¸€å¯¹å®ä½“ä¹‹é—´å¯ä»¥æœ‰å¤šä¸ªè¾¹ã€‚å¾ªç¯ä¹Ÿæ˜¯å…è®¸çš„ï¼Œä¾‹å¦‚ï¼ŒLHSå’ŒRHSæ˜¯ç›¸åŒçš„è¾¹.(A-&gt;B B-&gt;A)</p><blockquote><p>key point: directed, multi-relation, multigraph </p></blockquote><p>Each entity is of a certain entity type (one and only one type per entity). Thus, the types partition all the entities into disjoint groups. Similarly, each edge also belongs to exactly one relation type. All edges of a given relation type must have all their left-hand side entities of the same entity type and, similarly, all their right-hand side entities of the same entity type (possibly a different entity type than the left-hand side one). This property means that each relation type has a left-hand side entity type and a right-hand side entity type.<br>æ¯ä¸€ä¸ªå®ä½“éƒ½å…·æœ‰æŸç§å®ä½“ç±»å‹(æ¯ä¸ªå®ä½“éƒ½åªæœ‰ä¸€ç§ç±»å‹)ã€‚å› æ­¤ï¼Œå®ä½“çš„ç±»å‹å°†æ‰€æœ‰çš„å®ä½“åˆ’åˆ†æˆä¸ç›¸äº¤çš„ç»„ã€‚ç±»ä¼¼çš„ï¼Œæ¯ä¸€æ¡è¾¹ä¹Ÿåªå±äºä¸ªå”¯ä¸€çš„å…³ç³»ç±»å‹ã€‚ç»™å®šå…³ç³»ç±»å‹çš„è¾¹çš„LHS/RHSå®ä½“éƒ½åªå±äºä¸€ä¸ªå®ä½“ç±»å‹ï¼ˆå·¦å³ä¸¤ä¾§çš„å®ä½“ç±»å‹å¯ä»¥ä¸åŒï¼‰ã€‚æ­¤å±æ€§æ„å‘³ç€æ¯ç§å…³ç³»ç±»å‹éƒ½å…·æœ‰å·¦ä¾§å®ä½“ç±»å‹å’Œå³ä¾§å®ä½“ç±»å‹ã€‚</p><blockquote><p>key point: entity, relation, entity type, relation type</p></blockquote><p><img src="/image/PBG_entity_relation.png"><br>In this graph, there are 14 entities: 5 of the red entity type, 6 of the yellow entity type and 3 of the blue entity type; there are also 12 edges: 6 of the orange relation type (between red and yellow entities), 3 of the purple entity type (between red and blue entities) and 3 of the green entity type (between yellow and blue entities).<br>åœ¨è¯¥å›¾ä¸­ï¼Œå­˜åœ¨14ä¸ªå®ä½“ï¼šçº¢è‰²å®ä½“ç±»å‹çš„5ä¸ªï¼Œé»„è‰²å®ä½“ç±»å‹çš„6ä¸ªå’Œè“è‰²å®ä½“ç±»å‹çš„3ä¸ªï¼› è¿˜æœ‰12æ¡è¾¹ï¼šæ©™è‰²å…³è”ç±»å‹çš„6ä¸ªï¼ˆåœ¨çº¢è‰²å’Œé»„è‰²å®ä½“ä¹‹é—´ï¼‰ï¼Œç´«è‰²å…³è”ç±»å‹çš„3ä¸ªï¼ˆåœ¨çº¢è‰²å’Œè“è‰²å®ä½“ä¹‹é—´ï¼‰å’Œç»¿è‰²å…³è”ç±»å‹çš„3ä¸ªï¼ˆåœ¨é»„è‰²å’Œè“è‰²å®ä½“ä¹‹é—´ï¼‰ã€‚</p><p>In order for PBG to operate on large-scale graphs, the graph is broken up into small pieces, on which training can happen in a distributed manner. This is first achieved by further splitting the entities of each type into a certain number of subsets, called partitions. Then, for each relation type, its edges are divided into buckets: for each pair of partitions (one from the left- and one from the right-hand side entity types for that relation type) a bucket is created, which contains the edges of that type whose left- and right-hand side entities are in those partitions.<br>ä¸ºäº†ä½¿å¾—PBGåœ¨å¤§å‹å›¾å½¢ä¸Šè¿è¡Œï¼Œå›¾å½¢å°†è¢«åˆ†è§£æˆå°å—ï¼Œå¯ä»¥åœ¨è¿™äº›å°å—ä¸Šè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒã€‚é¦–å…ˆé€šè¿‡å°†æ¯ç§ç±»å‹çš„å®ä½“è¿›ä¸€æ­¥æ‹†åˆ†ä¸ºä¸€å®šæ•°é‡çš„å­é›†ï¼ˆç§°ä¸ºåˆ†åŒºï¼‰æ¥å®ç°ã€‚ ç„¶åï¼Œå¯¹äºæ¯ç§å…³ç³»ç±»å‹ï¼Œå®ƒçš„è¾¹è¢«åˆ’åˆ†æˆæ¡¶ï¼šå¯¹äºæ¯ä¸€å¯¹åˆ†åŒºï¼ˆå¯¹äºè¯¥å…³ç³»ç±»å‹ï¼Œä¸€ä¸ªåˆ†åŒºæ˜¯æ¥æºäºLHSçš„å®ä½“ç±»å‹ï¼Œä¸€ä¸ªåˆ†åŒºæ˜¯æ¥æºäºRHSçš„å®ä½“ç±»å‹ï¼‰ï¼Œä¸€ä¸ªå­˜å‚¨æ¡¶è¢«åˆ›å»ºï¼Œè¿™ä¸ªå­˜å‚¨æ¡¶ä¸­åŒ…å«äº†ç‰¹å®šç±»å‹çš„è¾¹åŠå¯¹åº”å·¦ã€å³ä¾§å®ä½“ç±»å‹çš„å®ä½“ã€‚</p><blockquote><p>key point: partition, bucket </p></blockquote><p><img src="/image/PBG_partition_bucket.png"><br>This graph shows a possible partition of the entities, with red having 3 partitions, yellow having 3, and blue having only one (hence blue is unpartitioned). The edges displayed are those of the orange bucket between the partitions 2 of the red entities and the partition 1 of the yellow entities.<br>æ­¤å›¾æ˜¾ç¤ºäº†å®ä½“çš„å¯èƒ½åˆ†åŒºï¼Œå…¶ä¸­çº¢è‰²å…·æœ‰3ä¸ªåˆ†åŒºï¼Œé»„è‰²å…·æœ‰3ä¸ªåˆ†åŒºï¼Œè“è‰²ä»…å…·æœ‰1ä¸ªåˆ†åŒºï¼ˆå› æ­¤ï¼Œè“è‰²æ˜¯æœªåˆ†åŒºçš„ï¼‰ã€‚ æ˜¾ç¤ºçš„è¾¹æ˜¯çº¢è‰²å®ä½“çš„åˆ†åŒº2å’Œé»„è‰²å®ä½“çš„åˆ†åŒº1ä¹‹é—´çš„æ©™è‰²æ¡¶çš„è¾¹ã€‚</p><blockquote><p>Note<br>For technical reasons, at the current state all entity types that appear on the left-hand side of some relation type must be divided into the same number of partitions (except unpartitioned entities). The same must hold for all entity types that appear on the right-hand side. In numpy-speak, it means that the number of partitions of all entities must be broadcastable to the same value.<br>å‡ºäºæŠ€æœ¯åŸå› ï¼Œå½“å‰å‡ºç°åœ¨æŸç§å…³ç³»ç±»å‹å·¦ä¾§çš„æ‰€æœ‰å®ä½“ç±»å‹å¿…é¡»åˆ’åˆ†ä¸ºç›¸åŒæ•°é‡çš„åˆ†åŒºï¼ˆæœªåˆ†åŒºçš„å®ä½“é™¤å¤–ï¼‰ã€‚å¯¹äºå‡ºç°åœ¨å³ä¾§çš„æ‰€æœ‰å®ä½“ç±»å‹ï¼Œå¿…é¡»ä¿æŒç›¸åŒçš„çŠ¶æ€ã€‚åœ¨numpyä¸­ï¼Œè¿™æ„å‘³ç€æ‰€æœ‰å®ä½“çš„åˆ†åŒºæ•°å¿…é¡»å¯ä»¥æ‰©å±•åˆ°ç›¸åŒçš„å€¼ã€‚<br>ä¸¾ä¸ªä¾‹å­ï¼Œæ¯”å¦‚è¯´LHSä»¥åŠRHSå®ä½“ç±»å‹åªæœ‰ä¸€ç§ï¼Œç„¶åå…³ç³»ç±»å‹ä¹Ÿå°±æ˜¯ä¸€ç§ï¼Œè¿™ä¸ªæ—¶å€™å¯¹LHSåˆ’åˆ†æˆ2ä¸ªpartitionï¼Œé‚£ä¹ˆRHSä¹Ÿè¦åˆ’åˆ†æˆ2ä¸ªpartitionï¼Œæ­¤æ—¶å¾—åˆ°çš„æ¡¶ä¸ªæ•°ä¸º2x2=4ä¸ª</p></blockquote><p>An entity is identified by its type, its partition and its index within the partition (indices must be contiguous, meaning that if there are ğ‘ entities in a typeâ€™s partition, their indices lie in the half-open interval [0,ğ‘)). An edge is identified by its type, its bucket (i.e., the partitions of its left- and right-hand side entity types) and the indices of its left- and right-hand side entities in their respective partitions. An edge doesnâ€™t have to specify its left- and right-hand side entity types, because they are implicit in the edgeâ€™s relation type.<br>å®ä½“ç”±å…¶ç±»å‹ï¼Œåˆ†åŒºå’Œåˆ†åŒºå†…çš„ç´¢å¼•æ ‡è¯†(ç´¢å¼•å¿…é¡»æ˜¯è¿ç»­çš„ï¼Œè¿™æ„å‘³ç€å¦‚æœç±»å‹çš„åˆ†åŒºä¸­æœ‰Nä¸ªå®ä½“ï¼Œåˆ™å…¶ç´¢å¼•ä½äº[0ï¼Œğ‘)ä¸­)ã€‚è¾¹ç”±å…¶ç±»å‹ï¼Œå…¶å­˜å‚¨æ¡¶ï¼ˆå³å…¶å·¦ä¾§å’Œå³ä¾§å®ä½“ç±»å‹çš„åˆ†åŒºå¯¹ï¼‰ä»¥åŠå…¶å·¦ä¾§å’Œå³ä¾§å®ä½“åœ¨å®ƒä»¬å„è‡ªåˆ†åŒºä¸­çš„ç´¢å¼•æ¥æ ‡è¯†ã€‚è¾¹ä¸å¿…æŒ‡å®šå…¶å·¦ä¾§å’Œå³ä¾§å®ä½“ç±»å‹ï¼Œå› ä¸ºå®ƒä»¬éšå«åœ¨è¾¹çš„å…³ç³»ç±»å‹ä¸­ã€‚</p><p>Formally, each bucket can be identifies by a pair of integers (ğ‘–,ğ‘—), where ğ‘– and ğ‘— are respectively the left- and right-hand side partitions. Inside that bucket, each edge can be identified by a triplet of integers (ğ‘¥,ğ‘Ÿ,ğ‘¦), with ğ‘¥ and ğ‘¦ representing respectively the left- and right-hand side entities and ğ‘Ÿ representing the relation type. This edge is â€œinterpretedâ€ by first looking up relation type ğ‘Ÿ in the configuration, and finding out that it can only have entities of type ğ‘’1 on its left-hand side and of type ğ‘’2 on its right-hand side. One can then determine the left-hand side entity, which is given by (ğ‘’1,ğ‘–,ğ‘¥) (its type, its partition and its index within the partition), and, similarly, the right-hand side one which is (ğ‘’2,ğ‘—,ğ‘¦).<br>å½¢å¼ä¸Šï¼Œæ¯ä¸ªæ¡¶éƒ½å¯ä»¥ç”±ä¸€å¯¹æ•´æ•°ï¼ˆğ‘–ï¼Œğ‘—ï¼‰æ ‡è¯†ï¼Œå…¶ä¸­ğ‘–å’Œğ‘—åˆ†åˆ«æ˜¯å·¦ä¾§å’Œå³ä¾§åˆ†åŒºçš„ç´¢å¼•ã€‚ åœ¨è¯¥æ¡¶å†…ï¼Œæ¯æ¡è¾¹éƒ½å¯ä»¥ç”±ä¸‰å…ƒç»„ï¼ˆğ‘¥ï¼Œğ‘Ÿï¼Œğ‘¦ï¼‰æ ‡è¯†ï¼Œå…¶ä¸­ğ‘¥å’Œğ‘¦åˆ†åˆ«è¡¨ç¤ºå·¦ä¾§å’Œå³ä¾§å®ä½“åœ¨å„è‡ªåˆ†åŒºä¸­çš„ç´¢å¼•ï¼Œè€Œğ‘Ÿè¡¨ç¤ºå…³ç³»ç±»å‹ã€‚ è¾¹çš„è§£è¯‘é€šè¿‡:é¦–å…ˆåœ¨é…ç½®æ–‡ä»¶ä¸­æŸ¥æ‰¾å…³ç³»ç±»å‹ğ‘Ÿï¼Œç„¶åå‘ç°ğ‘Ÿçš„å·¦ä¾§åªèƒ½æ˜¯å…·æœ‰ğ‘’1ç±»å‹çš„å®ä½“ï¼Œè€Œåœ¨å³ä¾§åˆ™æ˜¯å…·æœ‰ğ‘’2ç±»å‹çš„å®ä½“ï¼Œ ç„¶åï¼Œå¯ä»¥ç¡®å®šå·¦ä¾§å®ä½“ï¼Œè¯¥å®ä½“ç”±ï¼ˆğ‘’1ï¼Œğ‘–ï¼Œğ‘¥ï¼‰ï¼ˆğ‘’1=å®ä½“ç±»å‹ï¼Œi=å·¦ä¾§åˆ†åŒºç´¢å¼•ï¼Œx=è¯¥å®ä½“åœ¨åˆ†åŒºå†…çš„ç´¢å¼•ï¼‰ç»™å‡ºï¼Œç±»ä¼¼åœ°ï¼Œå³ä¾§å®ä½“ä¸ºï¼ˆğ‘’2 ï¼Œğ‘—ï¼Œğ‘¦ï¼‰ã€‚</p><p>æºåœ°å€ï¼š<br><a href="https://torchbiggraph.readthedocs.io/en/latest/data_model.html">https://torchbiggraph.readthedocs.io/en/latest/data_model.html</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>PyTorch-BigGraph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch-BigGraph æ¦‚è¦</title>
    <link href="/2020/10/22/PBG-overview/"/>
    <url>/2020/10/22/PBG-overview/</url>
    
    <content type="html"><![CDATA[<h1 id="PBGæ¦‚è¦"><a href="#PBGæ¦‚è¦" class="headerlink" title="PBGæ¦‚è¦"></a>PBGæ¦‚è¦</h1><p>PyTorch-BigGraph (PBG) is a distributed system for learning graph embeddings for large graphs, particularly big web interaction graphs with up to billions of entities and trillions of edges.PBG now supports GPU training.<br>PyTorch-BigGraphï¼ˆPBGï¼‰æ˜¯ä¸€ä¸ªç”¨äºå­¦ä¹ å­¦ä¹ å¤§å›¾ï¼ˆèŠ‚ç‚¹ã€å…³ç³»ä¼—å¤šï¼‰ï¼Œç‰¹åˆ«æ˜¯é‚£äº›å…·æœ‰å¤šè¾¾æ•°åäº¿ä¸ªå®ä½“å’Œæ•°ä¸‡äº¿æ¡è¾¹çš„å¤§å‹Webäº¤äº’å›¾åµŒå…¥çš„åˆ†å¸ƒå¼ç³»ç»Ÿã€‚å¦‚ä»ŠPBGä¹Ÿæ”¯æŒäº†GPUè®­ç»ƒçš„è¿‡ç¨‹ã€‚</p><blockquote><p>key point: PBG, distributed, big graph, embedding, GPU</p></blockquote><p>PBG was introduced in the PyTorch-BigGraph: A Large-scale Graph Embedding Framework paper, presented at the SysML conference in 2019.<br>PBGæ˜¯äº2019å¹´å‘è¡¨åœ¨SysMLä¼šè®®ä¸Šçš„ä¸€ç¯‡è®ºæ–‡ PYTORCH-BIGGRAPH: A LARGE-SCALE GRAPH EMBEDDING SYSTEMè¢«é¦–æ¬¡æå‡º<br>è®ºæ–‡åœ°å€: <a href="https://mlsys.org/Conferences/2019/doc/2019/71.pdf">https://mlsys.org/Conferences/2019/doc/2019/71.pdf</a></p><p>PBG trains on an input graph by ingesting its list of edges, each identified by its source and target entities and, possibly, a relation type. It outputs a feature vector (embedding) for each entity, trying to place adjacent entities close to each other in the vector space, while pushing unconnected entities apart. Therefore, entities that have a similar distribution of neighbors will end up being nearby.<br>PBGé€šè¿‡æå–å›¾çš„è¾¹åˆ—è¡¨æ¥è¿›è¡Œembeddingè®­ç»ƒï¼Œæ¯æ¡è¾¹ç”±å…¶æºå®ä½“,ç›®æ ‡å®ä½“ä»¥åŠä¸€ä¸ªå¯èƒ½çš„å…³ç³»ç±»å‹ä½œä¸ºæ ‡è¯†ã€‚PBGå¯¹æ¯ä¸ªå®ä½“è¾“å‡ºä¸€ä¸ªç‰¹å¾å‘é‡ï¼ˆåµŒå…¥ï¼‰ã€‚å®ƒé€šè¿‡å°†ç›¸é‚»çš„å®ä½“åœ¨å‘é‡ç©ºé—´ä¸­å½¼æ­¤é è¿‘æ”¾ç½®ï¼Œä¸ç›¸é‚»çš„å®ä½“å½¼æ­¤è¿œç¦»æ”¾ç½®ã€‚é€šè¿‡è¿™æ ·çš„æ‰‹æ®µï¼Œç›¸ä¼¼çš„å®ä½“æœ€ç»ˆçš„åµŒå…¥äº’ç›¸é è¿‘ã€‚</p><blockquote><p>key point: ç»“ç‚¹å‘é‡é—´çš„è·ç¦»èƒ½å¤Ÿè¡¡é‡åŸå›¾ä¸­çš„é‚»æ¥å…³ç³»å¼ºå¼±ã€‚</p></blockquote><p>It is possible to configure each relation type to calculate this â€œproximity scoreâ€ in a different way, with the parameters (if any) learned during training. This allows the same underlying entity embeddings to be shared among multiple relation types.<br>åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¯ä»¥é€šè¿‡é…ç½®æ¯ç§å…³ç³»ç±»å‹æ¥è®¡ç®—æ¥è¿‘ç¨‹åº¦ä»¥åŠå‚æ•°å­¦ä¹ ã€‚å¦‚æ­¤ä¸€æ¥ä¸€äº›ç›¸åŒçš„å®ä½“åµŒå…¥å¯ä»¥è¢«å¤šç§å…³ç³»ç±»å‹è¿›è¡Œå…±äº«ã€‚</p><p>The generality and extensibility of its model allows PBG to train a number of models from the knowledge graph embedding literature, including TransE, RESCAL, DistMult and ComplEx.<br>æ¨¡å‹çš„é€šç”¨æ€§å’Œå¯æ‰©å±•æ€§ä½¿å¾—PBGå¯ä»¥ä»çŸ¥è¯†å›¾åµŒå…¥æ–‡çŒ®ä¸­è®­ç»ƒè®¸å¤šæ¨¡å‹ï¼ŒåŒ…æ‹¬TransEï¼ŒRESCALï¼ŒDistMultå’ŒComplExã€‚</p><blockquote><p>key point: embedding algorithm: TransE, RESCAL, DistMult, ComplEx</p></blockquote><p>PBG is designed with scale in mind, and achieves it through:<br>PBGçš„è®¾è®¡è€ƒè™‘äº†è§„æ¨¡ï¼Œå¹¶é€šè¿‡ä»¥ä¸‹æ–¹æ³•å®ç°äº†è§„æ¨¡ï¼š</p><p>1.graph partitioning, so that the model does not have to be fully loaded into memory<br>2.multi-threaded computation on each machine<br>3.distributed execution across multiple machines (optional), all simultaneously operating on disjoint parts of the graph<br>4.batched negative sampling, allowing for processing &gt;1 million edges/sec/machine with 100 negatives per edge</p><p>1.å›¾å½¢åˆ†åŒºï¼Œå› æ­¤æ¨¡å‹ä¸å¿…å®Œå…¨åŠ è½½åˆ°å†…å­˜ä¸­<br>2.æ¯å°æœºå™¨ä¸Šçš„å¤šçº¿ç¨‹è®¡ç®—<br>3.åœ¨å¤šå°è®¡ç®—æœºä¸Šåˆ†å¸ƒæ‰§è¡Œï¼ˆå¯é€‰ï¼‰ï¼Œæ‰€æœ‰è¿™äº›æ“ä½œåŒæ—¶åœ¨å›¾çš„ä¸è¿ç»­éƒ¨åˆ†ä¸Šè¿è¡Œ(æ•°æ®åˆ†å¸ƒ)<br>4.æ‰¹é‡è´Ÿé‡‡æ ·ï¼Œå¯å¤„ç† &gt;1,000,00 ä¸ªè¾¹/ç§’/æœºå™¨, æ¯æ¡è¾¹100ä¸ªè´Ÿé‡‡æ ·</p><blockquote><p>key point: partition, distributed,  batched negative sampling</p></blockquote><p>PBG is not optimized for small graphs. If your graph has fewer than 100,000 nodes, consider using KBC with the ComplEx model and N3 regularizer. KBC produces state-of-the-art embeddings for graphs that can fit on a single GPU. Compared to KBC, PyTorch-BigGraph enables learning on very large graphs whose embeddings wouldnâ€™t fit in a single GPU or a single machine, but may not produce high-quality embeddings for small graphs without careful tuning.<br>PBGå¹¶æœªé’ˆå¯¹å°å‹å›¾å½¢è¿›è¡Œä¼˜åŒ–ã€‚å¦‚æœå›¾å°‘äº100,000ä¸ªèŠ‚ç‚¹ï¼Œè¯·è€ƒè™‘å°†KBCä¸ComplExæ¨¡å‹å’ŒN3æ­£åˆ™åŒ–å™¨ä¸€èµ·ä½¿ç”¨ã€‚ KBCä¸ºå¯æ”¾åœ¨å•ä¸ªGPUä¸Šçš„å›¾å½¢ç”Ÿæˆæœ€å…ˆè¿›çš„åµŒå…¥ã€‚ä¸KBCç›¸æ¯”ï¼ŒPyTorch-BigGraphæ”¯æŒåœ¨éå¸¸å¤§çš„å›¾ä¸Šè¿›è¡Œå­¦ä¹ ï¼Œè¿™äº›å›¾çš„åµŒå…¥æ— æ³•åœ¨å•ä¸ªGPUæˆ–å•ä¸ªæœºå™¨ä¸­å®Œæˆï¼Œä½†æ˜¯PBGå­˜åœ¨çš„ç¼ºç‚¹æ˜¯å…¶å¯èƒ½æ— æ³•ä¸ºå°å‹å›¾ç”Ÿæˆé«˜è´¨é‡çš„åµŒå…¥å¦‚æœæ²¡æœ‰å¾ˆå¥½çš„è°ƒå‚çš„è¯ã€‚</p><p>æºåœ°å€ï¼š<br><a href="https://github.com/facebookresearch/PyTorch-BigGraph">https://github.com/facebookresearch/PyTorch-BigGraph</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>PyTorch-BigGraph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Scrapy å®ä¾‹ - TripAdvisorä¿¡æ¯æŠ“å–</title>
    <link href="/2020/10/15/scrapy-example/"/>
    <url>/2020/10/15/scrapy-example/</url>
    
    <content type="html"><![CDATA[<h1 id="TripAdvisor-Scrapy-å®ä¾‹"><a href="#TripAdvisor-Scrapy-å®ä¾‹" class="headerlink" title="TripAdvisor Scrapy å®ä¾‹"></a>TripAdvisor Scrapy å®ä¾‹</h1><h2 id="çˆ¬è™«éœ€æ±‚"><a href="#çˆ¬è™«éœ€æ±‚" class="headerlink" title="çˆ¬è™«éœ€æ±‚"></a>çˆ¬è™«éœ€æ±‚</h2><p>çˆ¬å–æ´›æ‰çŸ¶åœ°åŒºçš„é¤å…å’Œé…’åº—çš„ç›¸å…³ä¿¡æ¯</p><p>é¤å…ä¿¡æ¯åŒ…æ‹¬:</p><ul><li>é¤å…åç§°</li><li>é¤å…è¯„æ˜Ÿï¼ˆå‡ é¢—æ˜Ÿï¼‰</li><li>é¤å…æ’åï¼ˆé’ˆå¯¹æ´›æ‰çŸ¶è€Œè¨€ï¼‰</li><li>é¤å…ä»·æ ¼åŒºé—´</li><li>é¤å…èœå“ç§ç±»</li><li>é¤å…åœ°ç‚¹</li><li>é™„è¿‘æ—…é¦†</li><li>é™„è¿‘é¤å…</li><li>é™„è¿‘æ™¯ç‚¹</li><li>ç”¨æˆ·è¯„ä»·</li></ul><p>é…’åº—ä¿¡æ¯åŒ…æ‹¬ï¼š</p><ul><li>é…’åº—åç§°</li><li>é…’åº—ä»·æ ¼åŒºé—´</li><li>é…’åº—æˆ¿é—´æ•°</li><li>é…’åº—è¯„æ˜Ÿ</li><li>é…’åº—è®¾æ–½</li><li>é…’åº—ç‰¹è‰²</li><li>é…’åº—æ˜Ÿçº§</li><li>é…’åº—æˆ¿é—´ç±»å‹</li><li>é…’åº—é£æ ¼</li><li>é…’åº—åœ°ç‚¹</li><li>é™„è¿‘é¤å…</li><li>é™„è¿‘æ™¯ç‚¹</li><li>ç”¨æˆ·è¯„ä»·</li></ul><h2 id="å®ç°"><a href="#å®ç°" class="headerlink" title="å®ç°"></a>å®ç°</h2><p>Scrapy + MongoDB<br>ä»£ç : xxxx</p><h2 id="æ³¨æ„äº‹é¡¹"><a href="#æ³¨æ„äº‹é¡¹" class="headerlink" title="æ³¨æ„äº‹é¡¹"></a>æ³¨æ„äº‹é¡¹</h2><ol><li>ä½¿ç”¨scrapd + spiderkeeper è¿›è¡Œå¯è§†åŒ–éƒ¨ç½²</li><li>logæ–‡ä»¶ä¿å­˜(settings.pyä¸­è®¾ç½®LOG_FILE  = â€œdebug.logâ€)</li><li>ä½¿ç”¨ scrapy shell è¿›è¡Œxpathè¯­æ³•è§„åˆ™çš„è°ƒè¯•ä»¥ç¡®ä¿å¾—åˆ°æƒ³è¦çš„ç»“æœ</li></ol><h2 id="ç»“æœ"><a href="#ç»“æœ" class="headerlink" title="ç»“æœ"></a>ç»“æœ</h2><p>10522 æ¡é¤å…æ•°æ® (50M)<br>1000 æ¡é…’åº—æ•°æ®  (100M)</p>]]></content>
    
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>Web Crawler</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Blocking and Relational Entity Resolution</title>
    <link href="/2020/10/11/Blocking-and-Relational-Entity-Resolution/"/>
    <url>/2020/10/11/Blocking-and-Relational-Entity-Resolution/</url>
    
    <content type="html"><![CDATA[<h1 id="å‰æƒ…æè¦"><a href="#å‰æƒ…æè¦" class="headerlink" title="å‰æƒ…æè¦"></a>å‰æƒ…æè¦</h1><p>Entity Resolution ä¸»è¦åˆ†æˆå¦‚ä¸‹å››ä¸ª</p><ol><li>Coreference     æ–‡æœ¬ä¸æ–‡æœ¬ä¹‹é—´æ‰¾åŒä¸€ä¸ªentity</li><li>Entity linking  æ–‡æœ¬ä¸KGä¸­æ‰¾å¯¹åº”entity     -&gt; Integrating New Candidates </li><li>Deduplication   ä¸€ä¸ªKGä¹‹é—´çš„èšç±»              -&gt; MergingÂ  Ambiguous Entities</li><li>Record linkage  ä¸¤ä¸ªä¸åŒKGä¹‹é—´entityçš„å¯¹åº”  -&gt; Combining KGs</li></ol><h1 id="Blocking"><a href="#Blocking" class="headerlink" title="Blocking"></a>Blocking</h1><h2 id="ä¸ºä»€ä¹ˆéœ€è¦Blocking-gt-reduce-the-number-of-comparisons"><a href="#ä¸ºä»€ä¹ˆéœ€è¦Blocking-gt-reduce-the-number-of-comparisons" class="headerlink" title="ä¸ºä»€ä¹ˆéœ€è¦Blocking -&gt; reduce the number of comparisons"></a>ä¸ºä»€ä¹ˆéœ€è¦Blocking -&gt; reduce the number of comparisons</h2><ul><li>Comparing each entity with all other entities is too computationally demanding â€“&gt; O(N^2)</li><li>If partition entities into N â€blocksâ€â€“ O(N)</li><li>Make only within block comparisons, so if largest block is log N in size â€“&gt; O(NlogN^2)</li></ul><h2 id="Blocking-åˆ†ç±»"><a href="#Blocking-åˆ†ç±»" class="headerlink" title="Blocking åˆ†ç±»"></a>Blocking åˆ†ç±»</h2><p>Disjoint Blocking: Each mention appears in one block.(=Set Partition)<br>Non-disjoint Blocking: Mentions can appear in more than one block. </p><h2 id="Blockingä¸€èˆ¬çš„æƒ…å½¢"><a href="#Blockingä¸€èˆ¬çš„æƒ…å½¢" class="headerlink" title="Blockingä¸€èˆ¬çš„æƒ…å½¢"></a>Blockingä¸€èˆ¬çš„æƒ…å½¢</h2><p><img src="/image/blocking_scenario.png"></p><h2 id="Blockingè¡¡é‡æŒ‡æ ‡"><a href="#Blockingè¡¡é‡æŒ‡æ ‡" class="headerlink" title="Blockingè¡¡é‡æŒ‡æ ‡"></a>Blockingè¡¡é‡æŒ‡æ ‡</h2><ul><li>Efficiency: Blue/Grey</li><li>Recall:     Green/Yellow</li><li>Precision:  Green/Blue</li><li>Max Canopy Size: åŒ…å«mentionsä¸ªæ•°æœ€å¤šçš„blockçš„mentionsä¸ªæ•°</li></ul><h2 id="Blockingæ–¹å¼"><a href="#Blockingæ–¹å¼" class="headerlink" title="Blockingæ–¹å¼"></a>Blockingæ–¹å¼</h2><h3 id="Feature-based-blocking-keys"><a href="#Feature-based-blocking-keys" class="headerlink" title="Feature-based blocking keys"></a>Feature-based blocking keys</h3><p>æ€æƒ³: é€šè¿‡é€‰æ‹©å®ä½“çš„æŸä¸€ä¸ªæˆ–è€…å¤šä¸ªå±æ€§ä½œä¸ºkeyï¼Œå°†åŒ…å«è¯¥keyçš„å®ä½“æ”¾åœ¨åŒä¸€ä¸ªblockä¸‹ï¼Œå¯¹æ¯ä¸ªblockå†è¿›è¡Œentity resolution</p><p>ä¾‹å­:<br>First three characters of last name<br>City + State + Zip<br>Character or Token n-grams<br>Minimum infrequent n-grams</p><h3 id="Clustering-or-sorting"><a href="#Clustering-or-sorting" class="headerlink" title="Clustering or sorting"></a>Clustering or sorting</h3><ol><li><p>Sorted Neighborhood Blocking<br>æ€æƒ³: é€šè¿‡é€‰æ‹©å®ä½“çš„æŸä¸€ä¸ªå±æ€§,æ ¹æ®è¯¥å±æ€§å¯¹å®ä½“è¿›è¡Œæ’åºï¼Œä½¿ç”¨ä¸€ä¸ªçª—æ ¼ï¼Œçª—æ ¼å†…çš„å®ä½“åˆ’åˆ†åˆ°ä¸€ä¸ªblockä¸­å»</p></li><li><p>Canopy Clustering<br>Input: Mentions M, x is an entity<br>d(x,y), a distance metric<br>thresholds T1 &gt; T2</p></li></ol><p>æ€æƒ³:</p><ol><li>Pick a random element x from M</li><li>Create new canopy Cx using mentions y s.t. d(x,y) &lt; T1</li><li>Delete all mentions y from M s.t. d(x,y) &lt; T2 </li><li>Return to Step 1 if M is not empty</li></ol><p><img src="/image/canopy_cluster.png"></p><h3 id="Hashing"><a href="#Hashing" class="headerlink" title="Hashing"></a>Hashing</h3><p>æ€æƒ³:</p><ol><li>Each block Ci is associated with a hash key hi.</li><li>Mention x is hashed to Ci if hash(x) = hi.</li><li>Within a block, all pairs are compared.</li><li>Each hash function results in disjoint blocks.</li></ol><h2 id="Blockingé€‰æ‹©è€ƒè™‘å› ç´ "><a href="#Blockingé€‰æ‹©è€ƒè™‘å› ç´ " class="headerlink" title="Blockingé€‰æ‹©è€ƒè™‘å› ç´ "></a>Blockingé€‰æ‹©è€ƒè™‘å› ç´ </h2><ul><li>keyçš„é€‰æ‹©:learn the keys, or use expert knowledge/heuristics?</li><li>Schema awareness: what do we know about the attributes?</li><li>Key type: exact equality, similarity-based, or hybrid ç›¸åŒçš„keyæ”¾åˆ°ä¸€ä¸ªblockè¿˜æ˜¯ç›¸ä¼¼æ”¾ä¸€ä¸ªblock</li><li>Redundancy: entity in one or multiple blocks? Does matching in multiple blocks increase the match probability</li><li>Frequency limits</li><li>Adaptive keys based on frequency</li><li>Learning keys based on data </li></ul><h2 id="Learning-to-block"><a href="#Learning-to-block" class="headerlink" title="Learning to block"></a>Learning to block</h2><p>Using one or more blocking predicates may be insufficient =&gt; Construct blocking predicates by combining simple predicates</p><h1 id="Collective-Relational-Entity-Resolution"><a href="#Collective-Relational-Entity-Resolution" class="headerlink" title="Collective Relational Entity Resolution"></a>Collective Relational Entity Resolution</h1><h2 id="ç­–ç•¥-Using-PSL-for-collective-KG-ER"><a href="#ç­–ç•¥-Using-PSL-for-collective-KG-ER" class="headerlink" title="ç­–ç•¥: Using PSL for collective KG ER"></a>ç­–ç•¥: Using PSL for collective KG ER</h2><ol><li>Encode ER dependencies in a set of rules</li><li>Use soft-logic values to capture similarities</li><li>Use logic to capture the constraints</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>Knowledge Graph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>çŸ¥è¯†å›¾è°±è¯†åˆ«</title>
    <link href="/2020/10/11/Probabilistic-Models-for-KG-Construction/"/>
    <url>/2020/10/11/Probabilistic-Models-for-KG-Construction/</url>
    
    <content type="html"><![CDATA[<h1 id="å‰æƒ…æè¦"><a href="#å‰æƒ…æè¦" class="headerlink" title="å‰æƒ…æè¦"></a>å‰æƒ…æè¦</h1><p>åœ¨çŸ¥è¯†å›¾è°±ä¸­ï¼Œä¸»è¦éœ€è¦è§£å†³çš„æœ‰ä¸‰ä¸ªé—®é¢˜:  (èŠ‚ç‚¹ï¼Œå±æ€§ï¼Œå…³ç³»)</p><ol><li>Who are the entities (nodes) in the graph?</li><li>What are their attributes and types (labels)?</li><li>How are they related (edges)?<br><img src="/image/KG-problem.png"></li></ol><p>çŸ¥è¯†å›¾è°±çš„æ„å»ºä¸»è¦å°±æ˜¯é€šè¿‡IEå°†äº’è”ç½‘ä¸Šå„å¼å„æ ·çš„èµ„æºè¿›è¡Œæå–ï¼Œæ•´åˆå¾—åˆ°ç»“æ„åŒ–çš„æ•°æ®(è¯´èµ·æ¥å®¹æ˜“ï¼Œåšèµ·æ¥éš¾ï¼)</p><p><img src="/image/build-KG.png"></p><p>æå–åˆ°çš„çŸ¥è¯†å¯èƒ½å­˜åœ¨çš„ä¸€äº›é—®é¢˜:</p><ol><li>ambiguous (ä¸€èˆ¬æˆ‘ä»¬è¯´ambiguous æŒ‡çš„æ˜¯å¤šä¸ªentityæŒ‡å‘ä¸€ä¸ªåå­—ï¼Œ variantæŒ‡çš„æ˜¯ä¸€ä¸ªentityæœ‰å¤šä¸ªåå­—)<ul><li>Beetles, beetles, Beatles è¿™ä¸‰ä¸ªnameå¯èƒ½éƒ½æ˜¯æŒ‡å‘ä¸€ä¸ªå®ä½“ç”²å£³è™«ï¼Œä½†æ˜¯åå­—ä¸åŒ</li><li>citizenOf, livedIn, bornIn è¿™ä¸‰ä¸ªpropertyå¯èƒ½éƒ½æ˜¯æŒ‡å‘ä¸€ä¸ªå®ä½“ï¼Œè¡¨è¾¾çš„æ„æ€ä¸ºè¯¥å®ä½“ä½åœ¨æŸä¸€ä¸ªåœ°æ–¹</li></ul></li><li>incomplete<ul><li>missing relationship; missing labels; missing entities</li></ul></li><li>inconsistent<ul><li>exclusive labels (alive, dead), æå–åˆ°çš„çŸ¥è¯†è¡¨æ˜ä¸€ä¸ªäººæ—¢å·²ç»å»ä¸–åˆè¿˜åœ¨äººä¸–</li><li>domain-range constraintsï¼Œæå–åˆ°ä¸€ä¸ªrelationshipä¾‹å¦‚äººçš„å¹´é¾„ä¸ºä¸€æœµèŠ±çš„åå­—(ageå±æ€§ä¸€èˆ¬ä¸ºint)</li><li>ä¸€ä¸ªäººçš„é…å¶æœ‰å¤šä¸ªå­˜åœ¨(common sense: ä¸€èˆ¬è®¤ä¸ºé…å¶ä¸ºä¸€å¯¹)</li></ul></li></ol><p>ä¾‹å­: NELLåœ¨çŸ¥è¯†æå–ä¸­å­˜åœ¨çš„é—®é¢˜:<br>NELL: Never-Ending Language Learner CMUç ”ç©¶çš„ä¸€ä¸ªäººå·¥æ™ºèƒ½è¯­è¨€å­¦ä¹ ç¨‹åº,ä»Webæ–‡æœ¬ä¸­è·å–çŸ¥è¯†ï¼Œå¹¶å°†å…¶æ·»åŠ åˆ°å†…éƒ¨çŸ¥è¯†åº“å†… ,ä½¿ç”¨æœºå™¨å­¦ä¹ ç®—æ³•å­¦ä¹ æ–°å…¥åº“çš„çŸ¥è¯†ï¼Œå·©å›ºå¯¹çŸ¥è¯†çš„ç†è§£ã€‚<br>ç‰¹ç‚¹: Large-scale IE project; Lifelong learning: aims to â€œread the webâ€; Ontology of known labels and relations; Knowledge base contains millions of facts</p><p>å­˜åœ¨é—®é¢˜:</p><ol><li>Entity co-reference errors, ä¾‹å¦‚å¯¹äºKyrgyzstan(å‰å°”å‰æ–¯æ–¯å¦,ä¸­äºšçš„ä¸€ä¸ªå›½å®¶)è¿™æ ·ä¸€ä¸ªå®ä½“ï¼Œä»–å…·æœ‰è®¸å¤šçš„variants(Kyrgystan, Kyrgistan, Kyrghyzstan, Kyrgzstan, Kyrgyz Republic), NELLä¸èƒ½å¾ˆå¥½å°†è¿™äº›variantå®Œå…¨æ˜ å°„åˆ°åŒä¸€ä¸ªå®ä½“ä¸Šã€‚</li><li>Missing and spurious labels, ä¾‹å¦‚Kyrgyzstanè¢«æ ‡æ³¨ä¸ºé¸Ÿæˆ–è€…å›½å®¶</li><li>Missing and spurious relations, ä¾‹å¦‚Kyrgyzstançš„ä½ç½®ï¼Œé€šè¿‡IEå¯èƒ½å¾—åˆ°ä¸åŒçš„åœ°åŒºå½’å±ã€‚</li><li>Violations of ontological knowledge </li></ol><blockquote><p>ç”±äºçŸ¥è¯†æå–è¿‡ç¨‹ä¸­çš„è¯¸å¤šé—®é¢˜ï¼Œæƒ³è¦å¾ˆå¥½çš„è§£å†³è¿™äº›é—®é¢˜éœ€è¦jointly considering multiple extractions.</p></blockquote><p>å›¾è°±æ„å»ºæ–¹æ³•:</p><ol><li>Clean and complete extraction graph</li><li>Incorporate ontological constraints and relational patterns</li><li>Discover statistical relationships within knowledge graph</li></ol><h1 id="PSL-Probabilistic-soft-logic-æ¦‚ç‡è½¯é€»è¾‘"><a href="#PSL-Probabilistic-soft-logic-æ¦‚ç‡è½¯é€»è¾‘" class="headerlink" title="PSL (Probabilistic soft logic) æ¦‚ç‡è½¯é€»è¾‘"></a>PSL (Probabilistic soft logic) æ¦‚ç‡è½¯é€»è¾‘</h1><blockquote><p>Itâ€™s not a black-and-white issue.</p></blockquote><h2 id="ä»ä¸€ä¸ªä¾‹å­è¯´èµ·-ç¾å›½é€‰æ°‘æ´¾åˆ«åˆ†ç±»-Voter-Party-Classification"><a href="#ä»ä¸€ä¸ªä¾‹å­è¯´èµ·-ç¾å›½é€‰æ°‘æ´¾åˆ«åˆ†ç±»-Voter-Party-Classification" class="headerlink" title="ä»ä¸€ä¸ªä¾‹å­è¯´èµ·, ç¾å›½é€‰æ°‘æ´¾åˆ«åˆ†ç±» (Voter Party Classification)"></a>ä»ä¸€ä¸ªä¾‹å­è¯´èµ·, ç¾å›½é€‰æ°‘æ´¾åˆ«åˆ†ç±» (Voter Party Classification)</h2><p><img src="/image/vote-classification.png"></p><p>å„ä¸ªè§’åº¦çš„ä¿¡æ¯æ¥åˆ†æä¸€åç¾å›½é€‰æ°‘çš„æ”¿æ²»æ€åº¦:</p><p><img src="/image/voter_attitude.png"></p><p>IDEA: <strong>Collective Classification</strong></p><p>å‡è®¾åˆ†æAçš„æ”¿æ²»æ€åº¦ï¼Œå¯ä»¥é€šè¿‡å…¶é…å¶çš„æ”¿æ²»æ€åº¦ï¼Œå…¶tweetç²‰ä¸çš„è§‚ç‚¹ï¼Œä¸ªäººçš„è¡Œä¸ºæ¥è¿›è¡Œåˆ†æï¼Œé€šè¿‡åˆ¶å®šä¸€äº›è§„åˆ™æ¥ç¡®å®šè¿™ä¸ªäººæ˜¯æ”¯æŒå…±å’Œå…šè¿˜æ˜¯æ°‘ä¸»å…šã€‚<br><img src="/image/vote_opinion.png"></p><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs livescript">Collective Classification <span class="hljs-keyword">with</span> PSL<br>è§„åˆ™: å¦‚æœA<span class="hljs-function"> -&gt;</span> é‚£ä¹ˆB <br><br><span class="hljs-comment">/* Local rules */</span><br><span class="hljs-number">5.0</span>: Donates<span class="hljs-function"><span class="hljs-params">(A, P)</span> -&gt;</span> Votes(A, P)<br><span class="hljs-number">0.3</span>: Mentions<span class="hljs-function"><span class="hljs-params">(A, â€œAffordable Healthâ€)</span> -&gt;</span> Votes(A, â€œDemocratâ€)<br><span class="hljs-number">0.3</span>: Mentions<span class="hljs-function"><span class="hljs-params">(A, â€œTax Cutsâ€)</span> -&gt;</span> Votes(A, â€œRepublicanâ€)<br><br><span class="hljs-comment">/* Relational rules */</span><br><span class="hljs-number">1.0</span>: Votes<span class="hljs-function"><span class="hljs-params">(A,P)</span> &amp; <span class="hljs-title">Spouse</span><span class="hljs-params">(B,A)</span> -&gt;</span> Votes(B,P)<br><span class="hljs-number">0.3</span>: Votes<span class="hljs-function"><span class="hljs-params">(A,P)</span> &amp; <span class="hljs-title">Friend</span><span class="hljs-params">(B,A)</span> -&gt;</span> Votes(B,P)<br><span class="hljs-number">0.1</span>: Votes<span class="hljs-function"><span class="hljs-params">(A,P)</span> &amp; <span class="hljs-title">Colleague</span><span class="hljs-params">(B,A)</span> -&gt;</span> Votes(B,P)<br><br><span class="hljs-comment">/* Range constraint */</span><br>Votes(A, â€œRepublicanâ€) + Votes(A, â€œDemocratâ€) = <span class="hljs-number">1.0</span> .<br></code></pre></td></tr></table></figure><h2 id="ä¸ºä»€ä¹ˆéœ€è¦PSL"><a href="#ä¸ºä»€ä¹ˆéœ€è¦PSL" class="headerlink" title="ä¸ºä»€ä¹ˆéœ€è¦PSL"></a>ä¸ºä»€ä¹ˆéœ€è¦PSL</h2><p>é€šè¿‡ä¸Šé¢çš„ä¾‹å­ï¼Œå¯ä»¥å‘ç°ï¼Œé€šè¿‡åˆ¶å®šä¸€äº›æ¯”è¾ƒå¥½çš„è§„åˆ™ï¼Œå¯ä»¥ä¸ºæå–çš„ä¿¡æ¯è¿›è¡Œä¸€äº›æ¯”è¾ƒé«˜è´¨é‡çš„æ ‡æ³¨ã€‚</p><p>å­˜åœ¨é—®é¢˜: </p><ol><li><p>è§„åˆ™çš„åˆ¶å®šä¾èµ–äºæå–åˆ°çš„ä¿¡æ¯ï¼Œå¦‚æœæå–åˆ°çš„çŸ¥è¯†å­˜åœ¨é—®é¢˜ï¼Œé‚£ä¹ˆä¸€å®šæ˜¯garbage in - garbage out.<br> ä¾‹å­:<br> Lbl(Socrates, Man) &amp; Sub(Man, Mortal) -&gt; Lbl(Socrates, Mortal)<br> å‡å¦‚æå–åˆ°çš„çŸ¥è¯†æ²¡æœ‰æ­£ç¡®çš„å°†Socratesæ ‡æ³¨ä¸ºç”·æ€§ï¼Œé‚£ä¹ˆæ°¸è¿œä¹Ÿå¾—ä¸åˆ°Lbl(Socrates, Mortal)è¿™æ ·çš„çŸ¥è¯†ã€‚</p><p> è§£å†³æªæ–½: probabilistic models  =&gt; P(new facts|extraction infos)<br> P(Lbl(Socrates, Mortal)|Lbl(Socrates,Man)=0.9)</p></li><li><p>å¤šæ¡è§„åˆ™ä¹‹é—´å¯èƒ½äº§ç”Ÿå†²çª<br> ä¾‹å­:<br> Bçš„æ­£ç¡®æ€§æ— æ³•ç¡®å®š:<br> A -&gt; B ç¬¦åˆ<br> C -&gt; B ä¸ç¬¦åˆ<br> D -&gt; B ç¬¦åˆ</p><p> è§£å†³æªæ–½: Soft Logic<br> A -&gt; B ç¬¦åˆ 0.7<br> C -&gt; B ä¸ç¬¦åˆ 0.2<br> D -&gt; B ç¬¦åˆ 0.9</p></li></ol><h2 id="Soft-Probability"><a href="#Soft-Probability" class="headerlink" title="Soft Probability"></a>Soft Probability</h2><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs properties"><span class="hljs-attr">P</span> <span class="hljs-string">-&gt; Q</span><br><span class="hljs-meta">/*</span> <span class="hljs-string">Soft Logic Penalty */</span><br><span class="hljs-attr">if</span> <span class="hljs-string">P &lt; Q</span><br><span class="hljs-attr">return</span> <span class="hljs-string">satisfication</span><br><span class="hljs-attr">else</span>:<span class="hljs-string"></span><br><span class="hljs-attr">return</span> <span class="hljs-string">P-Q</span><br><br><span class="hljs-attr">Closed</span> <span class="hljs-string">Form å°é—­ä¸–ç•ŒåŸåˆ™</span><br><span class="hljs-comment">!Q = 1-Q</span><br><span class="hljs-attr">P</span> <span class="hljs-string">-&gt; Q = max(0, P-Q)</span><br><span class="hljs-attr">P</span> <span class="hljs-string">&amp;  Q = max(0, P+Q-1)</span><br><span class="hljs-attr">P</span> <span class="hljs-string">|  Q = min(1, P+Q)</span><br><br></code></pre></td></tr></table></figure><h2 id="PSL-model"><a href="#PSL-model" class="headerlink" title="PSL model"></a>PSL model</h2><ul><li>PSL finds optimal assignment for all unknowns</li><li>Optimal = minimizes the soft-logic penalty</li><li>Fast, joint convex optimization using ADMM</li><li>Supports learning rule weights and latent variables</li></ul><h1 id="å›¾è°±æ¨¡å‹çš„å»ºç«‹"><a href="#å›¾è°±æ¨¡å‹çš„å»ºç«‹" class="headerlink" title="å›¾è°±æ¨¡å‹çš„å»ºç«‹"></a>å›¾è°±æ¨¡å‹çš„å»ºç«‹</h1><p>æ­¥éª¤:<br>Define joint probability distribution on knowledge graphs<br>Each candidate fact in the knowledge graph is a variable<br>Statistical signals, ontological knowledge and rules parameterize the dependencies between variables<br>Find most likely knowledge graph by optimization/sampling</p><h2 id="Knowledge-Graph-Identification-KGI"><a href="#Knowledge-Graph-Identification-KGI" class="headerlink" title="Knowledge Graph Identification (KGI)"></a>Knowledge Graph Identification (KGI)</h2><p>Knowledge Graph Identification (KGI): è§£å†³å›¾è°±ä¸­å­˜åœ¨çš„ä¸€ç³»åˆ—é—®é¢˜çš„æ–¹æ¡ˆ</p><ul><li>Performs graph identification:<ul><li>entity resolution</li><li>collective classification</li><li>link prediction</li></ul></li><li>Enforces ontological constraints</li><li>Incorporates multiple uncertain sources</li></ul><p>P(Who, What, How | Extractions)</p><h2 id="å›¾è°±ä¸­probabilityçš„è·å¾—"><a href="#å›¾è°±ä¸­probabilityçš„è·å¾—" class="headerlink" title="å›¾è°±ä¸­probabilityçš„è·å¾—"></a>å›¾è°±ä¸­probabilityçš„è·å¾—</h2><p>Statistical signals from text extractors and classifiers<br>    ex:<br>    P(R(John,Spouse,Yoko))=0.75; P(R(John,Spouse,Cynthia))=0.25<br>    LevenshteinSimilarity(Beatles, Beetles) = 0.9</p><p>Ontological knowledge about domain<br>    ex:<br>    Functional(Spouse) &amp; R(A,Spouse,B) -&gt; !R(A,Spouse,C)<br>    Range(Spouse, Person) &amp; R(A,Spouse,B) -&gt; Type(B, Person)</p><p>Rules and patterns mined from data<br>    ex:<br>    R(A, Spouse, B) &amp; R(A, Lives, L) -&gt; R(B, Lives, L)<br>    R(A, Spouse, B) &amp; R(A, Child, C) -&gt; R(B, Child, C)</p><h2 id="å®šä¹‰ä¸€ä¸ªgraphical-models"><a href="#å®šä¹‰ä¸€ä¸ªgraphical-models" class="headerlink" title="å®šä¹‰ä¸€ä¸ªgraphical models"></a>å®šä¹‰ä¸€ä¸ªgraphical models</h2><p>æœ‰è®¸å¤šç§æ–¹å¼å»å®šä¸€ä¸ªå›¾æ¨¡å‹ï¼Œè¿™é‡Œä½¿ç”¨PSL(ä½¿ç”¨è§„åˆ™)<br>PSL infers a â€œtruth valueâ€ for each fact via optimization</p><h3 id="Rules-for-KG-Model"><a href="#Rules-for-KG-Model" class="headerlink" title="Rules for KG Model"></a>Rules for KG Model</h3><figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs livescript"><br><span class="hljs-number">100</span>: Subsumes<span class="hljs-function"><span class="hljs-params">(L1,L2)</span>   &amp; <span class="hljs-title">Label</span><span class="hljs-params">(E,L1)</span>      -&gt;</span>  Label(E,L2)<br><span class="hljs-number">100</span>:Exclusive<span class="hljs-function"><span class="hljs-params">(L1,L2)</span>  &amp; <span class="hljs-title">Label</span><span class="hljs-params">(E,L1)</span>      -&gt;</span> !Label(E,L2)<br><br><span class="hljs-number">100</span>:Inverse<span class="hljs-function"><span class="hljs-params">(R1,R2)</span>    &amp; <span class="hljs-title">Relation</span><span class="hljs-params">(R1,E,O)</span> -&gt;</span>  Relation(R2,O,E)<br><span class="hljs-number">100</span>:Subsumes<span class="hljs-function"><span class="hljs-params">(R1,R2)</span>   &amp; <span class="hljs-title">Relation</span><span class="hljs-params">(R1,E,O)</span> -&gt;</span>  Relation(R2,E,O)<br><span class="hljs-number">100</span>:Exclusive<span class="hljs-function"><span class="hljs-params">(R1,R2)</span>  &amp; <span class="hljs-title">Relation</span><span class="hljs-params">(R1,E,O)</span> -&gt;</span> !Relation(R2,E,O)<br><br><span class="hljs-number">100</span>:Domain<span class="hljs-function"><span class="hljs-params">(R,L)</span>       &amp; <span class="hljs-title">Relation</span><span class="hljs-params">(R,E,O)</span>  -&gt;</span>  Label(E,L)<br><span class="hljs-number">100</span>:Range<span class="hljs-function"><span class="hljs-params">(R,L)</span>        &amp; <span class="hljs-title">Relation</span><span class="hljs-params">(R,E,O)</span>  -&gt;</span>  Label(O,L)<br><br><span class="hljs-number">10</span>:SameEntity<span class="hljs-function"><span class="hljs-params">(E1,E2)</span> &amp; <span class="hljs-title">Label</span><span class="hljs-params">(E1,L)</span>      -&gt;</span>  Label(E2,L)<br><span class="hljs-number">10</span>: SameEntity<span class="hljs-function"><span class="hljs-params">(E1,E2)</span> &amp; <span class="hljs-title">Relation</span><span class="hljs-params">(R,E1,O)</span> -&gt;</span>  Relation(R,E2,O)<br><br><span class="hljs-number">1</span>:Label_OBIE<span class="hljs-function"><span class="hljs-params">(E,L)</span>                      -&gt;</span>  Label(E,L)<br><span class="hljs-number">1</span>:Label_OpenIE<span class="hljs-function"><span class="hljs-params">(E,L)</span>                    -&gt;</span>  Label(E,L)<br><span class="hljs-number">1</span>:Relation_Pattern<span class="hljs-function"><span class="hljs-params">(R,E,O)</span>              -&gt;</span>  Relation(R,E,O)<br><span class="hljs-number">1</span>:                                        !Relation(R,E,O)<br><span class="hljs-number">1</span>:                                        !Label(E,L)<br><br></code></pre></td></tr></table></figure><h3 id="Rules-to-Distributions"><a href="#Rules-to-Distributions" class="headerlink" title="Rules to Distributions"></a>Rules to Distributions</h3><p>Rules are grounded by substituting literals into formulas<br>Ground rules provide a joint probability distribution over knowledge graph facts, conditioned on the extractions</p>]]></content>
    
    
    
    <tags>
      
      <tag>Knowledge Graph</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DSCI558 Building Knowledge Graphs</title>
    <link href="/2020/10/11/DSCI558-outline/"/>
    <url>/2020/10/11/DSCI558-outline/</url>
    
    <content type="html"><![CDATA[<h2 id="DSCI558-Building-Knowledge-Graphs"><a href="#DSCI558-Building-Knowledge-Graphs" class="headerlink" title="DSCI558 - Building Knowledge Graphs"></a>DSCI558 - Building Knowledge Graphs</h2><h3 id=""><a href="#" class="headerlink" title=""></a><a href="/2020/12/01/558intro/" title="çŸ¥è¯†å›¾è°±ç®€ä»‹">çŸ¥è¯†å›¾è°±ç®€ä»‹</a></h3><h3 id="-1"><a href="#-1" class="headerlink" title=""></a><a href="/2020/12/01/558data-acq/" title="çŸ¥è¯†å›¾è°±æ•°æ®è·å–ä¸çŸ¥è¯†äº§æƒ">çŸ¥è¯†å›¾è°±æ•°æ®è·å–ä¸çŸ¥è¯†äº§æƒ</a></h3><h3 id="-2"><a href="#-2" class="headerlink" title=""></a><a href="/2020/12/01/558info-extra/" title="çŸ¥è¯†å›¾è°±æ•°æ®æå–">çŸ¥è¯†å›¾è°±æ•°æ®æå–</a></h3><h3 id="-3"><a href="#-3" class="headerlink" title=""></a><a href="/2020/12/01/558kg-rep/" title="çŸ¥è¯†å›¾è°±è¡¨ç¤º">çŸ¥è¯†å›¾è°±è¡¨ç¤º</a></h3><h3 id="-4"><a href="#-4" class="headerlink" title=""></a><a href="/2020/12/01/558ent-res/" title="çŸ¥è¯†å›¾è°±å®ä½“è§£æ">çŸ¥è¯†å›¾è°±å®ä½“è§£æ</a></h3><h3 id="-5"><a href="#-5" class="headerlink" title=""></a><a href="/2020/12/01/558query-kg/" title="çŸ¥è¯†å›¾è°±æŸ¥è¯¢">çŸ¥è¯†å›¾è°±æŸ¥è¯¢</a></h3><h3 id="-6"><a href="#-6" class="headerlink" title=""></a><a href="/2020/12/01/558ent-link/" title="çŸ¥è¯†å›¾è°±å®ä½“é“¾æ¥">çŸ¥è¯†å›¾è°±å®ä½“é“¾æ¥</a></h3><h3 id="-7"><a href="#-7" class="headerlink" title=""></a><a href="/2020/12/01/558str-match/" title="çŸ¥è¯†å›¾è°±å­—ç¬¦ä¸²åŒ¹é…">çŸ¥è¯†å›¾è°±å­—ç¬¦ä¸²åŒ¹é…</a></h3><h3 id="-8"><a href="#-8" class="headerlink" title=""></a><a href="/2020/10/11/Probabilistic-Models-for-KG-Construction/" title="çŸ¥è¯†å›¾è°±è¯†åˆ«">çŸ¥è¯†å›¾è°±è¯†åˆ«</a></h3><h3 id="-9"><a href="#-9" class="headerlink" title=""></a><a href="/2020/12/02/558blk-RER/" title="çŸ¥è¯†å›¾è°±Blocking&amp;å…³ç³»å‹å®ä½“è§£æ">çŸ¥è¯†å›¾è°±Blocking&amp;å…³ç³»å‹å®ä½“è§£æ</a></h3><h3 id="-10"><a href="#-10" class="headerlink" title=""></a><a href="/2020/12/03/558ont-rea/" title="çŸ¥è¯†å›¾è°±æœ¬ä½“ä¸æ¨ç†">çŸ¥è¯†å›¾è°±æœ¬ä½“ä¸æ¨ç†</a></h3><h3 id="-11"><a href="#-11" class="headerlink" title=""></a><a href="/2020/12/03/558rdfa/" title="çŸ¥è¯†å›¾è°±RDFa">çŸ¥è¯†å›¾è°±RDFa</a></h3><h3 id="-12"><a href="#-12" class="headerlink" title=""></a><a href="/2020/12/03/558-table-und/" title="çŸ¥è¯†å›¾è°±è¡¨æ ¼ç†è§£">çŸ¥è¯†å›¾è°±è¡¨æ ¼ç†è§£</a></h3><h3 id="-13"><a href="#-13" class="headerlink" title=""></a><a href="/2020/12/03/558kg-emb/" title="çŸ¥è¯†å›¾è°±å›¾åµŒå…¥">çŸ¥è¯†å›¾è°±å›¾åµŒå…¥</a></h3><h3 id="-14"><a href="#-14" class="headerlink" title=""></a><a href="/2020/12/03/558ld-sw/" title="çŸ¥è¯†å›¾è°±é”®è¿æ•°æ®ä¸è¯­ä¹‰ç½‘ç»œ">çŸ¥è¯†å›¾è°±é”®è¿æ•°æ®ä¸è¯­ä¹‰ç½‘ç»œ</a></h3><h3 id="-15"><a href="#-15" class="headerlink" title=""></a><a href="/2020/12/03/558overview/" title="çŸ¥è¯†å›¾è°±å¤ä¹ å¤§çº²">çŸ¥è¯†å›¾è°±å¤ä¹ å¤§çº²</a></h3><!-- ### <a href="/2020/10/11/Blocking-and-Relational-Entity-Resolution/" title="Blocking and Relational Entity Resolution">Blocking and Relational Entity Resolution</a>   -->]]></content>
    
    
    
    <tags>
      
      <tag>Course</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>æ¨èç³»ç»Ÿæ€»è§ˆ</title>
    <link href="/2020/10/03/recommendation-system/"/>
    <url>/2020/10/03/recommendation-system/</url>
    
    <content type="html"><![CDATA[<h1 id="æ•ˆç”¨çŸ©é˜µ-utility-matrix"><a href="#æ•ˆç”¨çŸ©é˜µ-utility-matrix" class="headerlink" title="æ•ˆç”¨çŸ©é˜µ (utility matrix)"></a>æ•ˆç”¨çŸ©é˜µ (utility matrix)</h1><p>ä¸€èˆ¬çš„æ¨èç³»ç»Ÿä¸­æœ‰ä¸¤ç±»å…ƒç´ ï¼Œä¸€ç±»æ˜¯userï¼Œä¸€ç±»æ˜¯item(ä¾‹å¦‚ç”µå½±ã€éŸ³ä¹â€¦)ï¼Œå¯ä»¥ç”¨ä¸€ä¸ªçŸ©é˜µè¡¨ç¤ºè¿™äº›æ•°æ®<br>æ¯ä¸€è¡Œè¡¨ç¤ºæ¯ä¸€ä¸ªuserï¼Œæ¯ä¸€åˆ—è¡¨ç¤ºä¸€ä¸ªitem, <code>M[i][j]</code>è¡¨ç¤ºç¬¬iä¸ªç”¨æˆ·å¯¹ç¬¬jé¡¹çš„è¯„åˆ†ã€‚</p><p>ä¸€èˆ¬æ•ˆç”¨çŸ©é˜µéƒ½æ˜¯ç¨€ç–çš„ï¼Œéœ€è¦åšçš„å°±æ˜¯å¡«å……è¿™äº›ç¼ºå¤±å€¼</p><ul><li>Gathering known ratings for matrix</li><li>Extrapolate unknown ratings from the known ones</li><li>Evaluating extrapolation methods</li></ul><h1 id="é•¿å°¾æ•ˆåº”-The-Long-tail"><a href="#é•¿å°¾æ•ˆåº”-The-Long-tail" class="headerlink" title="é•¿å°¾æ•ˆåº” (The Long tail)"></a>é•¿å°¾æ•ˆåº” (The Long tail)</h1><p>ç‰©ç†ä¸–ç•Œå’Œåœ¨çº¿ä¸–ç•Œçš„å·®åˆ«ç§°ä¸ºé•¿å°¾ç°è±¡ï¼Œé•¿å°¾ç°è±¡è¦æ±‚äº’è”ç½‘å¿…é¡»å¯¹æ¯ä¸ªç”¨æˆ·è¿›è¡Œæ¨èã€‚</p><ul><li>å®é™…çš„ç‰©ç†å®ä½“åº—ä¸­å—é™äºç©ºé—´ï¼Œåªèƒ½æ¨èç•…é”€é¡¹ç›®ã€‚</li><li>äº’è”ç½‘æ¨èç³»ç»Ÿä¸å—ç©ºé—´é™åˆ¶ï¼Œå¯ä»¥æ¨èæ‰€æœ‰é¡¹ç›®ã€‚</li></ul><p>å…³äºåœ¨çº¿ä¸–ç•Œä¸ç‰©ç†ä¸–ç•Œå·®å¼‚çš„ä¾‹å­:<br>What percentage of the top 10,000 titles in any online media store (Netflix, iTunes, Amazon, or any other) will rent or sell at least once a month?<br>Most people guess 20 percent.(80-20 rule, also known as Paretoâ€™s principle (1896))<br>The right answer: 99 percent.(Demand for nearly every one of those top 10,000 titles.)</p><h1 id="æ¨èç®—æ³•åˆ†ç±»"><a href="#æ¨èç®—æ³•åˆ†ç±»" class="headerlink" title="æ¨èç®—æ³•åˆ†ç±»"></a>æ¨èç®—æ³•åˆ†ç±»</h1><h2 id="åŸºäºå†…å®¹-Content-based"><a href="#åŸºäºå†…å®¹-Content-based" class="headerlink" title="åŸºäºå†…å®¹(Content based)"></a>åŸºäºå†…å®¹(Content based)</h2><blockquote><p>æ€æƒ³:å…³æ³¨itemçš„å±æ€§ï¼Œè®¡ç®—å„ä¸ªitemä¹‹é—´çš„ç›¸ä¼¼åº¦æ¥è¿›è¡Œæ¨èã€‚ Recommend items to customer x that are similar to previous items rated highly by x.</p></blockquote><p><img src="/image/content-based.png"></p><h3 id="å·¥ä½œåŸç†"><a href="#å·¥ä½œåŸç†" class="headerlink" title="å·¥ä½œåŸç†"></a>å·¥ä½œåŸç†</h3><p>åŸºäºå†…å®¹çš„æ¨èç³»ç»Ÿæ˜¯å»ºç«‹åœ¨ç”¨æˆ·ç»™å‡ºçš„æ•°æ®ä¹‹ä¸Šçš„ï¼Œç”¨æˆ·ç»™å‡ºçš„æ•°æ®è¦ä¹ˆæ˜¯å¯¹ç‰©å“çš„ç›´æ¥è¯„åˆ†æˆ–è€…æ˜¯ç‚¹å‡»æˆ–è€…æµè§ˆç‰©å“ï¼Œé€šè¿‡è¿™äº›æ•°æ®å¯ä»¥å»ºç«‹å‡ºåŸºäºè¿™ä¸ªç”¨æˆ·çš„åŸºæœ¬ä¿¡æ¯(user profile),åç»­å¯¹è¯¥ç”¨æˆ·ç‰©å“æ¨èæ˜¯åŸºäºå…¶user profileï¼Œuser profileè¶Šå®Œå–„ï¼Œæ¨èç³»ç»Ÿçš„æ•ˆæœè¶Šå¥½ã€‚</p><h3 id="å·¥ä½œæµç¨‹"><a href="#å·¥ä½œæµç¨‹" class="headerlink" title="å·¥ä½œæµç¨‹"></a>å·¥ä½œæµç¨‹</h3><ul><li>Construct item profiles  (æ„å»ºæè¿°itemçš„å‘é‡)<ul><li>ç‰¹å¾å¯ä»¥æ˜¯æ˜ç¡®çš„å±æ€§å€¼ï¼Œä¹Ÿå¯ä»¥æ˜¯ä»æ–‡æ¡£ä¸­æå–å‡ºæ¥çš„ç‰¹å¾</li></ul></li><li>Construct user profiles ï¼ˆæ„å»ºæè¿°userå–œå¥½çš„å‘é‡ï¼‰<ul><li>å°†userçš„åå¥½ä¹Ÿè¡¨ç¤ºæˆåŒä¸€ç©ºé—´ä¸‹çš„å‘é‡</li></ul></li><li>Recommend items to users based on content</li></ul><h3 id="ä¼˜åŠ£"><a href="#ä¼˜åŠ£" class="headerlink" title="ä¼˜åŠ£"></a>ä¼˜åŠ£</h3><p>ä¼˜ç‚¹ï¼š</p><ol><li>ä¸éœ€è¦å…¶ä»–userçš„æ•°æ®</li><li>å¯ä»¥æ ¹æ®userçš„ç‹¬ç‰¹å–œå¥½æ¥æ¨èitemï¼Œä¹Ÿå°±æ˜¯è¯´å¯ä»¥æ¨èä¸€äº›å°ä¼—çš„item</li><li>æ¨èçš„åŸå› å¯ä»¥å¾ˆå®¹æ˜“è¢«è§£é‡Š<br>ç¼ºç‚¹ï¼š</li><li>å†…å®¹çš„ç‰¹å¾æå–çš„é—®é¢˜ï¼Œå¦‚ä½•æ‰èƒ½æå–å‡ºæœ€æœ‰ç”¨çš„ç‰¹å¾ï¼ˆrequires a lot of domain knowledge.ï¼‰</li><li>åªèƒ½æ¨èä¸ç”¨æˆ·å†å²æ•°æ®ä¸­ç›¸ä¼¼çš„itemï¼ˆmodel has limited ability to expand on the usersâ€™ existing interestsï¼‰</li><li>æ— æ³•åˆ©ç”¨å…¶ä»–ç”¨æˆ·çš„æ•°æ®</li></ol><h2 id="ååŒè¿‡æ»¤-Collaborative-filtering"><a href="#ååŒè¿‡æ»¤-Collaborative-filtering" class="headerlink" title="ååŒè¿‡æ»¤(Collaborative filtering)"></a>ååŒè¿‡æ»¤(Collaborative filtering)</h2><blockquote><p>æ€æƒ³:å…³æ³¨itemä¸userä¹‹é—´çš„å…³ç³»ï¼Œå…ˆè¯†åˆ«ç›¸ä¼¼ç”¨æˆ·ï¼Œç„¶ååŸºäºç›¸ä¼¼ç”¨æˆ·è¿›è¡Œç›¸ä¼¼é¡¹ç›®è¿›è¡Œæ¨èã€‚ Suggestions made to a user utilizing information across the entire user base</p></blockquote><p><img src="/image/CF.png"></p><h3 id="å·¥ä½œåŸç†-1"><a href="#å·¥ä½œåŸç†-1" class="headerlink" title="å·¥ä½œåŸç†"></a>å·¥ä½œåŸç†</h3><p>åŸºäºååŒè¿‡æ»¤çš„æ¨èç³»ç»Ÿæ˜¯å»ºç«‹åœ¨è®¸å¤šç”¨æˆ·çš„æ•°æ®ä¹‹ä¸Šçš„ï¼Œé€šè¿‡åˆ†æè¿™äº›ç”¨æˆ·ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œå‘æ˜ç›¸ä¼¼çš„ç”¨æˆ·,ï¼ˆå‡è®¾ç”¨æˆ·Aå’ŒBç›¸ä¼¼ï¼‰ï¼Œæ¨èAä¸€äº›Bä¹°è¿‡çš„ä¸œè¥¿ã€‚å…¶ä¸»è¦ç²¾é«“åœ¨äº:ç‰©ä»¥ç±»èš(item-based)ï¼Œäººä»¥ç¾¤åˆ†(user-based)ã€‚<br>Itâ€™s based on the idea that people who agree in their evaluations of certain items in the past are likely to agree again in the future.</p><p>å…³äºä¸€ç‚¹æ€è€ƒï¼šUsers only see what they are expected to like.</p><h3 id="ååŒè¿‡æ»¤çš„ä¸¤ç±»ç®—æ³•"><a href="#ååŒè¿‡æ»¤çš„ä¸¤ç±»ç®—æ³•" class="headerlink" title="ååŒè¿‡æ»¤çš„ä¸¤ç±»ç®—æ³•"></a>ååŒè¿‡æ»¤çš„ä¸¤ç±»ç®—æ³•</h3><h4 id="Memory-based-approach"><a href="#Memory-based-approach" class="headerlink" title="Memory-based approach"></a>Memory-based approach</h4><p><img src="/image/CF-2.png"></p><h5 id="User-based-CF-k-nearest-neighbor-collaborative-filtering"><a href="#User-based-CF-k-nearest-neighbor-collaborative-filtering" class="headerlink" title="User-based CF (k-nearest neighbor collaborative filtering)"></a>User-based CF (k-nearest neighbor collaborative filtering)</h5><ul><li>æ€æƒ³: ä¸ºç”¨æˆ·Aæ‰¾åˆ°ç›¸ä¼¼ç”¨æˆ·ï¼Œç„¶ååŸºäºç›¸ä¼¼ç”¨æˆ·è¿›è¡Œç›¸ä¼¼é¡¹ç›®æ¨è</li><li>æ­¥éª¤:<ul><li>æ ¹æ®ä¸Açš„ç›¸ä¼¼åº¦æ¥ä¸ºAçš„ç›¸ä¼¼ç”¨æˆ·åˆ†é…æƒé‡ </li><li>é€‰æ‹©topkç›¸ä¼¼ç”¨æˆ· </li><li>åŸºäºtopkç›¸ä¼¼ç”¨æˆ·å¯¹äºitemçš„è¯„åˆ†å»é¢„æµ‹Aå¯¹itemçš„è¯„åˆ† </li></ul></li><li>ä¾‹å­: å‡è®¾Aæœ‰3ä¸ªç›¸ä¼¼ç”¨æˆ·ï¼ŒB(sim=0.8, rating(h)=5),C(sim=0.3,rating(h)=4),D(sim=0.5,rating(h)=3) é¢„æµ‹Aå¯¹äºhçš„è¯„åˆ†<ul><li>r_a(h) = 0.8x5+0.3x4+0.5x3 / (0.8+0.3+0.5) = 4.2</li></ul></li></ul><h5 id="Item-based-CF"><a href="#Item-based-CF" class="headerlink" title="Item-based CF"></a>Item-based CF</h5><ul><li>æ€æƒ³: ä¸ºç‰©å“xæ‰¾ç›¸ä¼¼ç‰©å“ï¼Œç„¶ååŸºäºç”¨æˆ·ä¹‹å‰å–œæ¬¢/ä¹°è¿‡çš„ç‰©å“ä¸ºå…¶æ¨èæœ€ç›¸ä¼¼çš„ç‰©å“</li><li>ä¾‹å­: ä¸ºç”µå½±è¿›è¡Œè¯„åˆ†æ—¶, similar items will be rated similarly by the same user</li></ul><h4 id="Model-based-approaches"><a href="#Model-based-approaches" class="headerlink" title="Model-based approaches"></a>Model-based approaches</h4><p><img src="/image/model-based-CF.png"></p><h5 id="çŸ©é˜µåˆ†è§£"><a href="#çŸ©é˜µåˆ†è§£" class="headerlink" title="çŸ©é˜µåˆ†è§£"></a>çŸ©é˜µåˆ†è§£</h5><p><img src="/image/MF.png"></p><h3 id="CFä¼˜åŠ£"><a href="#CFä¼˜åŠ£" class="headerlink" title="CFä¼˜åŠ£"></a>CFä¼˜åŠ£</h3><p>ä¼˜ç‚¹ï¼š</p><ol><li>åˆ©ç”¨äº†åˆ«çš„userçš„æ•°æ®</li><li>ä¸éœ€è¦ç‰¹å¾é€‰æ‹©ï¼ˆä¸éœ€è¦domain knowledgeï¼‰</li></ol><p>ç¼ºç‚¹ï¼š</p><ol><li>éœ€è¦è¶³å¤Ÿçš„æ•°æ®æ”¯æŒ</li><li>ç¨€ç–ï¼Œæ„å»ºå‡ºçš„utility matrixç¨€ç–ä¸”åºå¤§</li><li>æ— æ³•æ¨èä»æœªè¢«è¯„çº§çš„item</li><li>ä¸èƒ½æ ¹æ®æŸä¸ªç”¨æˆ·çš„ç‰¹æœ‰å“ä½è¿›è¡Œæ¨è</li></ol><h2 id="æ··åˆæ–¹æ³•-Hybrid"><a href="#æ··åˆæ–¹æ³•-Hybrid" class="headerlink" title="æ··åˆæ–¹æ³•(Hybrid)"></a>æ··åˆæ–¹æ³•(Hybrid)</h2>]]></content>
    
    
    
    <tags>
      
      <tag>æ¨èç³»ç»Ÿ</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Scrapyå­¦ä¹ </title>
    <link href="/2020/09/22/Scrapy-learning/"/>
    <url>/2020/09/22/Scrapy-learning/</url>
    
    <content type="html"><![CDATA[<h3 id="Scrapy-æ¶æ„"><a href="#Scrapy-æ¶æ„" class="headerlink" title="Scrapy æ¶æ„"></a>Scrapy æ¶æ„</h3><p><img src="/image/scrapy.png"></p><ol><li>The Engine gets the initial Requests to crawl from the Spider.(è·å–è¦çˆ¬çš„url)</li><li>The Engine schedules the Requests in the Scheduler and asks for the next Requests to crawl.ï¼ˆè°ƒåº¦requeståˆ°è°ƒåº¦å™¨ä¸­ï¼Œå½¢æˆä¸€äº›åˆ—çš„urlè°ƒåº¦é˜Ÿåˆ—ï¼‰</li><li>The Scheduler returns the next Requests to the Engine.ï¼ˆè°ƒåº¦å™¨è°ƒåº¦å®Œæˆï¼Œå‘é€ç¬¬ä¸€ä¸ªrequestç»™å¼•æ“ï¼‰</li><li>The Engine sends the Requests to the Downloader, passing through the Downloader Middlewares (see process_request()). ï¼ˆå¼•æ“å‘é€ç¬¬ä¸€ä¸ªrequestç»™ä¸‹è½½å™¨ï¼‰</li><li>Once the page finishes downloading the Downloader generates a Response (with that page) and sends it to the Engine, passing through the Downloader Middlewares (see process_response()).ï¼ˆä¸‹è½½å™¨å¾—åˆ°è¯¥requestçš„responseï¼Œè¿”å›ç»™å¼•æ“ï¼‰</li><li>The Engine receives the Response from the Downloader and sends it to the Spider for processing, passing through the Spider Middleware (see process_spider_input()).ï¼ˆå¼•æ“å°†responseå‘ç»™spiderè¿›è¡Œè§£æï¼‰</li><li>The Spider processes the Response and returns scraped items and new Requests (to follow) to the Engine, passing through the Spider Middleware (see process_spider_output()).ï¼ˆspiderè§£æå¥½éœ€è¦çš„æ•°æ®ï¼šåŒ…æ‹¬ï¼šæå–éœ€è¦çš„å†…å®¹+æå–æ–°çš„urlè¯·æ±‚ï¼Œå°†å¤„ç†å¥½çš„æ•°æ®å‘ç»™å¼•æ“ï¼‰</li><li>The Engine sends processed items to Item Pipelines, then send processed Requests to the Scheduler and asks for possible next Requests to crawl.ï¼ˆä¸€æ–¹é¢å¼•æ“å°†å¾—åˆ°çš„å†…å®¹å‘ç»™itemï¼Œå°†å¾—åˆ°çš„urlè¯·æ±‚å‘ç»™è°ƒåº¦å™¨ï¼‰</li><li>The process repeats (from step 1) until there are no more requests from the Scheduler.</li></ol><p>æ‘˜è‡ª:<a href="https://docs.scrapy.org/en/latest/topics/architecture.html">https://docs.scrapy.org/en/latest/topics/architecture.html</a></p><h3 id="Scrapy-ä½¿ç”¨"><a href="#Scrapy-ä½¿ç”¨" class="headerlink" title="Scrapy ä½¿ç”¨"></a>Scrapy ä½¿ç”¨</h3><h4 id="ç¬¬ä¸€æ­¥-åˆ›å»ºçˆ¬è™«é¡¹ç›®ï¼›"><a href="#ç¬¬ä¸€æ­¥-åˆ›å»ºçˆ¬è™«é¡¹ç›®ï¼›" class="headerlink" title="ç¬¬ä¸€æ­¥: åˆ›å»ºçˆ¬è™«é¡¹ç›®ï¼›"></a>ç¬¬ä¸€æ­¥: åˆ›å»ºçˆ¬è™«é¡¹ç›®ï¼›</h4><p>$scrapy startproject project_name</p><h4 id="ç¬¬äºŒæ­¥-è®¾ç½®settings"><a href="#ç¬¬äºŒæ­¥-è®¾ç½®settings" class="headerlink" title="ç¬¬äºŒæ­¥: è®¾ç½®settings"></a>ç¬¬äºŒæ­¥: è®¾ç½®settings</h4><p>settingså…³é—­robots =ã€‹ POBOTSOXT_OBEY = True<br>â€¦</p><h4 id="ç¬¬ä¸‰æ­¥-å®šä¹‰itemä¿¡æ¯"><a href="#ç¬¬ä¸‰æ­¥-å®šä¹‰itemä¿¡æ¯" class="headerlink" title="ç¬¬ä¸‰æ­¥: å®šä¹‰itemä¿¡æ¯"></a>ç¬¬ä¸‰æ­¥: å®šä¹‰itemä¿¡æ¯</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><br><span class="hljs-keyword">import</span> scrapy<br><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Test1Item</span>(<span class="hljs-params">scrapy.Item</span>):</span> <span class="hljs-comment"># ==&gt;&gt;&gt;ä¿®æ”¹itemåç§°</span><br>    <span class="hljs-comment"># define the fields for your item here like:</span><br>    <span class="hljs-comment"># name = scrapy.Field()</span><br>    <span class="hljs-keyword">pass</span><br><br>    <span class="hljs-comment"># Items clearly define the common output data format in a separate file ,æœ‰çš„æ—¶å€™å¯èƒ½éœ€è¦å¯¹ä¼ è¿‡æ¥çš„æ•°æ®è¿›è¡Œè¿›ä¸€æ­¥å¤„ç†</span><br><br>    <span class="hljs-comment"># example:</span><br>    quote_content = Field(input_processor=MapCompose(remove_quotes),output_processor=TakeFirst())<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">remove_quotes</span>(<span class="hljs-params">text</span>):</span><br><span class="hljs-keyword">pass</span><br></code></pre></td></tr></table></figure><h4 id="ç¬¬å››æ­¥-ç¼–å†™ä»£ç é€»è¾‘"><a href="#ç¬¬å››æ­¥-ç¼–å†™ä»£ç é€»è¾‘" class="headerlink" title="ç¬¬å››æ­¥:ç¼–å†™ä»£ç é€»è¾‘"></a>ç¬¬å››æ­¥:ç¼–å†™ä»£ç é€»è¾‘</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><br>é¦–å…ˆåˆ›å»ºçˆ¬è™«æ–‡ä»¶<br>cd project_name<br>scrapy genspider spider_name url<br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse</span>(<span class="hljs-params">self, response</span>):</span><br><span class="hljs-comment">## ç¼–å†™ä»£ç é€»è¾‘</span><br>self.logger.info(<span class="hljs-string">&#x27;test...&#x27;</span>)<br><br>    <span class="hljs-comment">## ä¸€èˆ¬é€»è¾‘:</span><br>    res = response.xpath(<span class="hljs-string">&quot;xxx&quot;</span>).getall() <br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> res:<br>    <span class="hljs-keyword">yield</span>&#123;<br>    <span class="hljs-comment"># æ”¾å…¥itemä¸­ï¼Œæ›´åŠ å¤æ‚çš„å†™æ³•è§item itemloader</span><br>    &#125;<br>     <span class="hljs-comment">##å¦‚æœéœ€è¦æ·±åº¦æœç´¢ï¼Œå…·æœ‰ä¸‹ä¸€é¡µä¹‹ç±»çš„</span><br>     next_page = response.xpath(xxx).get()<br>    <span class="hljs-keyword">if</span> next_page <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>        next_page = response.urljoin(next_page)<br>        <span class="hljs-keyword">yield</span> scrapy.Request(next_page, callback=self.parse)  <span class="hljs-comment"># è¿™é‡Œçš„callback ä¹Ÿå¯ä»¥é‡æ–°å†™ä¸ªå‡½æ•°è¿›è¡Œå›è°ƒ crapy.Request(next_page, callback=self.parse2)</span><br>        <span class="hljs-comment"># å¦‚æœä¸è¿›è¡Œurlæ‹¼æ¥çš„è¯ï¼Œä¹Ÿå¯ä»¥ç›´æ¥</span><br>        <span class="hljs-keyword">yield</span> response.follow(a, callback=self.parse)<br><br><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse2</span>(<span class="hljs-params">self,response</span>):</span><br><span class="hljs-keyword">pass</span><br><br><span class="hljs-comment">#Ite/Itemloader</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> res:<br>loader = ItemLoader(item=Test1Item(), selector=i)<br>...<br><br>item = loader.load_item() <span class="hljs-comment"># æ­¤æ—¶itemä¾¿å¾—åˆ°äº†æå–çš„æ•°æ®</span><br><span class="hljs-keyword">yield</span> item<br></code></pre></td></tr></table></figure><h4 id="ç¬¬äº”æ­¥-è°ƒè¯•-è¾“å‡º"><a href="#ç¬¬äº”æ­¥-è°ƒè¯•-è¾“å‡º" class="headerlink" title="ç¬¬äº”æ­¥:è°ƒè¯• è¾“å‡º"></a>ç¬¬äº”æ­¥:è°ƒè¯• è¾“å‡º</h4><p>$ scrapy shell URL<br>response.xpath(xxx).getall()</p><p>$ scrapy crawl quotes -o xx.json</p>]]></content>
    
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>Web Crawler</tag>
      
      <tag>library</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>XML</title>
    <link href="/2020/09/18/File-Format/"/>
    <url>/2020/09/18/File-Format/</url>
    
    <content type="html"><![CDATA[<h3 id="Basic"><a href="#Basic" class="headerlink" title="Basic"></a>Basic</h3><ul><li>XMLï¼šeXtensible Markup Language</li><li>XML is a syntax (serialization format) for data sharing and exchange on the Web<ul><li>Can translate <em>any</em> data to XML</li><li>Can ship XML over the Web (HTTP)</li><li>Can input XML into any application</li></ul></li></ul><h3 id="XML-Structure"><a href="#XML-Structure" class="headerlink" title="XML Structure"></a>XML Structure</h3><p><img src="/image/XML.png"></p><ul><li>XML is self-describing</li><li>Schema elements become part of the data(å…³ç³»å‹æ•°æ®è®°å½•ä¸­schemaä¸ç®—æ˜¯å†…å®¹ï¼Œä½†æ˜¯åœ¨xmlä¸­èŠ‚ç‚¹è‡ªèº«ä¹Ÿæºå¸¦å†…å®¹ä¿¡æ¯) </li><li>XML is semi-structured <ul><li>missing attributes  (could be represented as null in table)</li><li>repeated attributes (impossible in table)</li><li>Attributes with different types in different objects</li><li>Nested structures</li><li>Heterogeneous contents</li></ul></li><li>an XML document has a single root element</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs xml">example:<br><span class="hljs-tag">&lt;<span class="hljs-name">bib</span>&gt;</span><br>...<br>  <span class="hljs-tag">&lt;<span class="hljs-name">book</span> <span class="hljs-attr">price</span>=<span class="hljs-string">&quot;35&quot;</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">publisher</span>&gt;</span>Addison-Wesley<span class="hljs-tag">&lt;/<span class="hljs-name">publisher</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">author</span>&gt;</span>Serge Abiteboul<span class="hljs-tag">&lt;/<span class="hljs-name">author</span>&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">author</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">first-name</span>&gt;</span>Rick<span class="hljs-tag">&lt;/<span class="hljs-name">first-name</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">last-name</span>&gt;</span>Hull<span class="hljs-tag">&lt;/<span class="hljs-name">last-name</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">author</span>&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">author</span> <span class="hljs-attr">age</span>=<span class="hljs-string">&quot;20&quot;</span>&gt;</span>Victor Vianu<span class="hljs-tag">&lt;/<span class="hljs-name">author</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">title</span>&gt;</span>Foundations of Databases<span class="hljs-tag">&lt;/<span class="hljs-name">title</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">year</span>&gt;</span>1995<span class="hljs-tag">&lt;/<span class="hljs-name">year</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">price</span>&gt;</span>38.8<span class="hljs-tag">&lt;/<span class="hljs-name">price</span>&gt;</span> <br>  <span class="hljs-tag">&lt;/<span class="hljs-name">book</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">book</span> <span class="hljs-attr">price</span>=<span class="hljs-string">&quot;55&quot;</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">publisher</span>&gt;</span>Freeman<span class="hljs-tag">&lt;/<span class="hljs-name">publisher</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">author</span>&gt;</span>Jeffrey D. Ullman<span class="hljs-tag">&lt;/<span class="hljs-name">author</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">title</span>&gt;</span>Principles of Database and Knowledge Base Systems<span class="hljs-tag">&lt;/<span class="hljs-name">title</span>&gt;</span> <br>    <span class="hljs-tag">&lt;<span class="hljs-name">year</span>&gt;</span>1998<span class="hljs-tag">&lt;/<span class="hljs-name">year</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">book</span>&gt;</span> <br>... <br><span class="hljs-tag">&lt;/<span class="hljs-name">bib</span>&gt;</span><br></code></pre></td></tr></table></figure><h3 id="Querying-XML-Data"><a href="#Querying-XML-Data" class="headerlink" title="Querying XML Data"></a>Querying XML Data</h3><h4 id="XPath-simple-navigation-through-the-tree"><a href="#XPath-simple-navigation-through-the-tree" class="headerlink" title="XPath: simple navigation through the tree"></a>XPath: simple navigation through the tree</h4><p><img src="/image/xpath.png"></p><h3 id="lxml"><a href="#lxml" class="headerlink" title="lxml"></a>lxml</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">$ pip install lxml<br><br><span class="hljs-keyword">from</span> lxml <span class="hljs-keyword">import</span> etree<br>f = open(<span class="hljs-string">&#x27;bibs.xml&#x27;</span>)<br>tree = etree.parse(f)<br>print(etree.tostring(tree, pretty_print=<span class="hljs-literal">True</span>))<br><br><span class="hljs-keyword">for</span> element <span class="hljs-keyword">in</span> tree.xpath(<span class="hljs-string">&quot;//author&quot;</span>): <br>    print(etree.tostring(element))<br>    print(element.tag, element.text)<br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>File Format</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Leetcode-äºŒå‰æ ‘</title>
    <link href="/2020/09/17/Algorithm-binarytree/"/>
    <url>/2020/09/17/Algorithm-binarytree/</url>
    
    <content type="html"><![CDATA[<h2 id="äºŒå‰æ ‘çš„ä¸€äº›æ€æƒ³"><a href="#äºŒå‰æ ‘çš„ä¸€äº›æ€æƒ³" class="headerlink" title="äºŒå‰æ ‘çš„ä¸€äº›æ€æƒ³"></a>äºŒå‰æ ‘çš„ä¸€äº›æ€æƒ³</h2><ul><li>å‰åºéå†(preOrder)  root-&gt;left-&gt;right </li><li>ä¸­åºéå†(inOrder)    left-&gt; root-&gt;right äºŒå‰æœç´¢æ ‘ä¸­ï¼Œå…¶éå†ç»“æœä¸ºæœ‰åºæ•°ç»„</li><li>ååºéå†(postOrder) left-&gt;right-&gt;root </li><li>å¹¿åº¦ä¼˜å…ˆæœç´¢(BFS)</li><li>æ·±åº¦ä¼˜å…ˆæœç´¢(DFS)</li><li>é€’å½’(Recursion)ï¼Œæ ¹æ®è¦æ±‚é€‰æ‹©ä½¿ç”¨å‰åºï¼Œä¸­åºï¼Œååºçš„é€’å½’æ¡†æ¶æ¥è§£å†³é—®é¢˜</li></ul><h4 id="897-é€’å¢é¡ºåºæŸ¥æ‰¾æ ‘"><a href="#897-é€’å¢é¡ºåºæŸ¥æ‰¾æ ‘" class="headerlink" title="897. é€’å¢é¡ºåºæŸ¥æ‰¾æ ‘"></a><a href="https://leetcode-cn.com/problems/increasing-order-search-tree/">897. é€’å¢é¡ºåºæŸ¥æ‰¾æ ‘</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># æ€è·¯1: ä¸­åºéå†å½¢æˆæœ‰åºåˆ—è¡¨ + é‡æ–°ç”Ÿæˆæ ‘</span><br><span class="hljs-comment"># æ€è·¯2: ä½¿ç”¨é€’å½’,æ”¹å˜æ ‘å½¢çŠ¶ï¼Œä¸ç”Ÿæˆæ–°çš„æ ‘</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">increasingBST</span>(<span class="hljs-params">self, root: TreeNode</span>) -&gt; TreeNode:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dfs</span>(<span class="hljs-params">root</span>):</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root: <span class="hljs-keyword">return</span> <br>        dfs(root.left)<br>        <span class="hljs-comment">### å¯¹æ ¹èŠ‚ç‚¹çš„æ“ä½œ ###</span><br>        root.left = <span class="hljs-literal">None</span><br>        self.cur.right = root<br>        self.cur = root<br>        <span class="hljs-comment">###################</span><br>        dfs(root.right)<br>    res = self.cur = TreeNode(<span class="hljs-literal">None</span>)<br>    dfs(root)<br>    <span class="hljs-keyword">return</span> res.right<br></code></pre></td></tr></table></figure><h4 id="226-ç¿»è½¬äºŒå‰æ ‘"><a href="#226-ç¿»è½¬äºŒå‰æ ‘" class="headerlink" title="226. ç¿»è½¬äºŒå‰æ ‘"></a><a href="https://leetcode-cn.com/problems/invert-binary-tree/">226. ç¿»è½¬äºŒå‰æ ‘</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">invertTree</span>(<span class="hljs-params">self, root</span>):</span><br>    <span class="hljs-comment"># å…ˆåºéå†  ï¼ˆååºéå†ä¹Ÿå¯ï¼‰</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root: <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br>    <span class="hljs-comment">### å¯¹æ ¹èŠ‚ç‚¹çš„æ“ä½œ ###</span><br>    root.left,root.right = root.right,root.left<br>    <span class="hljs-comment">### å¯¹æ ¹èŠ‚ç‚¹çš„æ“ä½œ ###</span><br>    root.left = self.invertTree(root.left)  <br>    root.right = self.invertTree(root.right)<br>    <span class="hljs-comment"># å‡½æ•°è¿”å›æ—¶å°±è¡¨ç¤ºå½“å‰è¿™ä¸ªèŠ‚ç‚¹ï¼Œä»¥åŠå®ƒçš„å·¦å³å­æ ‘éƒ½å·²ç»äº¤æ¢å®Œäº†       </span><br>    <span class="hljs-keyword">return</span> root<br></code></pre></td></tr></table></figure><h4 id="617-åˆå¹¶äºŒå‰æ ‘"><a href="#617-åˆå¹¶äºŒå‰æ ‘" class="headerlink" title="617. åˆå¹¶äºŒå‰æ ‘"></a><a href="https://leetcode-cn.com/problems/merge-two-binary-trees/">617. åˆå¹¶äºŒå‰æ ‘</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mergeTrees</span>(<span class="hljs-params">self, t1: TreeNode, t2: TreeNode</span>) -&gt; TreeNode:</span><br>    <span class="hljs-comment">###### å¯¹æ ¹èŠ‚ç‚¹çš„æ“ä½œ #####</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> (t1 <span class="hljs-keyword">and</span> t2): <span class="hljs-comment"># ä¸èƒ½ç”¨ if not t1 and not t2</span><br>        <span class="hljs-keyword">return</span> t1 <span class="hljs-keyword">if</span> t1 <span class="hljs-keyword">else</span> t2<br>    t1.val+=t2.val<br>    <span class="hljs-comment">#########################</span><br>    t1.left = self.mergeTrees(t1.left,t2.left) <br>    t1.right = self.mergeTrees(t1.right,t2.right)<br><br>    <span class="hljs-keyword">return</span> t1<br></code></pre></td></tr></table></figure><h4 id="938-äºŒå‰æœç´¢æ ‘çš„èŒƒå›´å’Œ"><a href="#938-äºŒå‰æœç´¢æ ‘çš„èŒƒå›´å’Œ" class="headerlink" title="938. äºŒå‰æœç´¢æ ‘çš„èŒƒå›´å’Œ"></a><a href="https://leetcode-cn.com/problems/range-sum-of-bst/">938. äºŒå‰æœç´¢æ ‘çš„èŒƒå›´å’Œ</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">rangeSumBST</span>(<span class="hljs-params">self, root: TreeNode, L: int, R: int</span>) -&gt; int:</span><br>    <br>    self.res = <span class="hljs-number">0</span> <span class="hljs-comment"># éœ€è¦ä½¿ç”¨ä¸€ä¸ªå…¨å±€å˜é‡è¿›è¡Œç»“æœçš„ä¿å­˜</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dfs</span>(<span class="hljs-params">root,L,R</span>):</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root: <span class="hljs-keyword">return</span> <br>        <span class="hljs-comment">###### å¯¹æ ¹èŠ‚ç‚¹çš„æ“ä½œ #####</span><br>        <span class="hljs-keyword">if</span> L&lt;= root.val &lt;=R:<br>            self.res+=root.val<br>        <span class="hljs-comment">#########################</span><br>        dfs(root.left,L,R)<br>        dfs(root.right,L,R)<br><br>    dfs(root,L,R)<br>    <span class="hljs-keyword">return</span> self.res<br><br></code></pre></td></tr></table></figure><h4 id="104-äºŒå‰æ ‘çš„æœ€å¤§æ·±åº¦"><a href="#104-äºŒå‰æ ‘çš„æœ€å¤§æ·±åº¦" class="headerlink" title="104. äºŒå‰æ ‘çš„æœ€å¤§æ·±åº¦"></a><a href="https://leetcode-cn.com/problems/maximum-depth-of-binary-tree/">104. äºŒå‰æ ‘çš„æœ€å¤§æ·±åº¦</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">maxDepth</span>(<span class="hljs-params">self, root: TreeNode</span>) -&gt; int:</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root:<span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>    <span class="hljs-comment"># ååºéå†</span><br>    <span class="hljs-keyword">return</span> max(self.maxDepth(root.left),self.maxDepth(root.right)) +<span class="hljs-number">1</span><br>    <span class="hljs-comment"># ä¹Ÿå¯ä»¥ä½¿ç”¨BFSå¾—åˆ°é«˜åº¦</span><br></code></pre></td></tr></table></figure><h4 id="590-Nå‰æ ‘çš„ååºéå†-å‰åºéå†"><a href="#590-Nå‰æ ‘çš„ååºéå†-å‰åºéå†" class="headerlink" title="590. Nå‰æ ‘çš„ååºéå†/å‰åºéå†"></a><a href="https://leetcode-cn.com/problems/n-ary-tree-postorder-traversal/">590. Nå‰æ ‘çš„ååºéå†</a>/<a href="https://leetcode-cn.com/problems/n-ary-tree-preorder-traversal/">å‰åºéå†</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">postorder</span>(<span class="hljs-params">self, root: <span class="hljs-string">&#x27;Node&#x27;</span></span>) -&gt; List[int]:</span><br>    self.res = []<br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">helper</span>(<span class="hljs-params">root</span>):</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root:<span class="hljs-keyword">return</span><br>        <span class="hljs-keyword">for</span> child <span class="hljs-keyword">in</span> root.children:<br>            helper(child)<br>        <span class="hljs-comment">###### å¯¹æ ¹èŠ‚ç‚¹çš„æ“ä½œ #####</span><br>        self.res.append(root.val)<br>        <span class="hljs-comment">###### å¯¹æ ¹èŠ‚ç‚¹çš„æ“ä½œ #####</span><br>    helper(root)<br>    <span class="hljs-keyword">return</span> self.res<br></code></pre></td></tr></table></figure><h4 id="700-äºŒå‰æœç´¢æ ‘ä¸­çš„æœç´¢"><a href="#700-äºŒå‰æœç´¢æ ‘ä¸­çš„æœç´¢" class="headerlink" title="700. äºŒå‰æœç´¢æ ‘ä¸­çš„æœç´¢"></a><a href="https://leetcode-cn.com/problems/search-in-a-binary-search-tree/">700. äºŒå‰æœç´¢æ ‘ä¸­çš„æœç´¢</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">searchBST</span>(<span class="hljs-params">self, root: TreeNode, val: int</span>) -&gt; TreeNode:</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root:<span class="hljs-keyword">return</span> <br>    <span class="hljs-comment">###### å¯¹æ ¹èŠ‚ç‚¹çš„æ“ä½œ #####</span><br>    <span class="hljs-keyword">if</span> root.val == val:<br>        <span class="hljs-keyword">return</span> root<br>    <span class="hljs-comment">#########################</span><br>    <span class="hljs-keyword">if</span> root.val &lt; val:<br>        <span class="hljs-keyword">return</span> self.searchBST(root.right,val) <span class="hljs-comment"># è®°ä½éœ€è¦return</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> self.searchBST(root.left,val)<br></code></pre></td></tr></table></figure><h4 id="108-å°†æœ‰åºæ•°ç»„è½¬æ¢ä¸ºäºŒå‰æœç´¢æ ‘"><a href="#108-å°†æœ‰åºæ•°ç»„è½¬æ¢ä¸ºäºŒå‰æœç´¢æ ‘" class="headerlink" title="108. å°†æœ‰åºæ•°ç»„è½¬æ¢ä¸ºäºŒå‰æœç´¢æ ‘"></a><a href="https://leetcode-cn.com/problems/convert-sorted-array-to-binary-search-tree/">108. å°†æœ‰åºæ•°ç»„è½¬æ¢ä¸ºäºŒå‰æœç´¢æ ‘</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sortedArrayToBST</span>(<span class="hljs-params">self, nums: List[int]</span>) -&gt; TreeNode:</span><br>    <span class="hljs-comment">###### å¯¹æ ¹èŠ‚ç‚¹çš„æ“ä½œ #####</span><br>    <span class="hljs-keyword">if</span> len(nums) == <span class="hljs-number">0</span> : <span class="hljs-keyword">return</span> <br>    mid = len(nums)//<span class="hljs-number">2</span><br>    root = TreeNode(nums[mid])<br>    <span class="hljs-comment">##########################</span><br>    root.left = self.sortedArrayToBST(nums[:mid])<br>    root.right = self.sortedArrayToBST(nums[mid+<span class="hljs-number">1</span>:])<br>    <br>    <span class="hljs-keyword">return</span> root<br></code></pre></td></tr></table></figure><h4 id="897-é€’å¢é¡ºåºæŸ¥æ‰¾æ ‘-1"><a href="#897-é€’å¢é¡ºåºæŸ¥æ‰¾æ ‘-1" class="headerlink" title="897. é€’å¢é¡ºåºæŸ¥æ‰¾æ ‘"></a><a href="https://leetcode-cn.com/problems/increasing-order-search-tree/">897. é€’å¢é¡ºåºæŸ¥æ‰¾æ ‘</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">increasingBST</span>(<span class="hljs-params">self, root: TreeNode</span>) -&gt; TreeNode:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">dfs</span>(<span class="hljs-params">root</span>):</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root: <span class="hljs-keyword">return</span> <br>        dfs(root.left)<br>        <span class="hljs-comment">### å¯¹æ ¹èŠ‚ç‚¹çš„æ“ä½œ #####</span><br>        root.left = <span class="hljs-literal">None</span><br>        self.cur.right = root<br>        self.cur = root<br>        <span class="hljs-comment">#####################</span><br>        dfs(root.right)<br>    res = self.cur = TreeNode(<span class="hljs-literal">None</span>)<br>    dfs(root)<br>    <span class="hljs-keyword">return</span> res.right<br></code></pre></td></tr></table></figure><h4 id="559-Nå‰æ ‘çš„æœ€å¤§æ·±åº¦"><a href="#559-Nå‰æ ‘çš„æœ€å¤§æ·±åº¦" class="headerlink" title="559. Nå‰æ ‘çš„æœ€å¤§æ·±åº¦"></a><a href="https://leetcode-cn.com/problems/maximum-depth-of-n-ary-tree/">559. Nå‰æ ‘çš„æœ€å¤§æ·±åº¦</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">maxDepth</span>(<span class="hljs-params">self, root: <span class="hljs-string">&#x27;Node&#x27;</span></span>) -&gt; int:</span><br>    <br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root:<span class="hljs-keyword">return</span>  <span class="hljs-number">0</span>   <br>    <span class="hljs-keyword">return</span> max([self.maxDepth(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span>  root.children]+[<span class="hljs-number">0</span>])+<span class="hljs-number">1</span> <span class="hljs-comment"># æ³¨æ„éœ€è¦ +[0] =&gt; æ²¡æœ‰0çš„è¯ä¼šæŠ¥é”™: max() arg is an empty sequence</span><br></code></pre></td></tr></table></figure><h4 id="å‰‘æŒ‡-Offer-68-II-äºŒå‰æ ‘çš„æœ€è¿‘å…¬å…±ç¥–å…ˆ"><a href="#å‰‘æŒ‡-Offer-68-II-äºŒå‰æ ‘çš„æœ€è¿‘å…¬å…±ç¥–å…ˆ" class="headerlink" title="å‰‘æŒ‡ Offer 68 - II. äºŒå‰æ ‘çš„æœ€è¿‘å…¬å…±ç¥–å…ˆ"></a><a href="https://leetcode-cn.com/problems/er-cha-shu-de-zui-jin-gong-gong-zu-xian-lcof/">å‰‘æŒ‡ Offer 68 - II. äºŒå‰æ ‘çš„æœ€è¿‘å…¬å…±ç¥–å…ˆ</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">lowestCommonAncestor</span>(<span class="hljs-params">self, root: TreeNode, p: TreeNode, q: TreeNode</span>) -&gt; TreeNode:</span><br><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root <span class="hljs-keyword">or</span> p == root <span class="hljs-keyword">or</span> q == root: <span class="hljs-keyword">return</span> root<br><br>    left = self.lowestCommonAncestor(root.left,p,q)<br>    right = self.lowestCommonAncestor(root.right,p,q)<br>    <span class="hljs-comment">### å¯¹æ ¹èŠ‚ç‚¹çš„æ“ä½œ #####</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> left <span class="hljs-keyword">and</span> <span class="hljs-keyword">not</span> right: <span class="hljs-keyword">return</span>  <span class="hljs-comment"># å·¦å³å­æ ‘å‡ä¸ºç©º</span><br>    <span class="hljs-keyword">elif</span> <span class="hljs-keyword">not</span> left: <span class="hljs-keyword">return</span> right        <span class="hljs-comment"># å³ç©ºï¼Œå·¦ä¸ç©º</span><br>    <span class="hljs-keyword">elif</span> <span class="hljs-keyword">not</span> right:<span class="hljs-keyword">return</span> left         <span class="hljs-comment"># å·¦ç©ºï¼Œå³ä¸ç©º</span><br>    <span class="hljs-keyword">else</span>: <span class="hljs-keyword">return</span> root                  <span class="hljs-comment"># å·¦å³å‡ä¸ç©º</span><br>    <span class="hljs-comment">### å¯¹æ ¹èŠ‚ç‚¹çš„æ“ä½œ #####</span><br></code></pre></td></tr></table></figure><h4 id="637-äºŒå‰æ ‘çš„å±‚å¹³å‡å€¼"><a href="#637-äºŒå‰æ ‘çš„å±‚å¹³å‡å€¼" class="headerlink" title="637. äºŒå‰æ ‘çš„å±‚å¹³å‡å€¼"></a><a href="https://leetcode-cn.com/problems/average-of-levels-in-binary-tree/">637. äºŒå‰æ ‘çš„å±‚å¹³å‡å€¼</a></h4>]]></content>
    
    
    <categories>
      
      <category>Algorithm</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Leetcode</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Network File System</title>
    <link href="/2020/09/11/NFS/"/>
    <url>/2020/09/11/NFS/</url>
    
    <content type="html"><![CDATA[<h3 id="Basic"><a href="#Basic" class="headerlink" title="Basic"></a>Basic</h3><p>The Network File System (NFS) is a client/server application that lets a computer user view and optionally store and update files on a remote computer as though they were on the userâ€™s own computer. NFS is a distributed file system(DFS).</p><h4 id="Client-server-architecture"><a href="#Client-server-architecture" class="headerlink" title="Client/server architecture"></a>Client/server architecture</h4><p><img src="/image/C-S.png"></p><p>Advantage</p><ul><li>Easy sharing of data across clients</li><li>Centralized administration</li><li>Security</li></ul><p>Disadvantage:</p><ul><li>Network overhead</li><li>More components to fail</li></ul><h3 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a>DFS</h3><h4 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h4><p><img src="/image/DFS.png"></p><h4 id="Stateless-æ— çŠ¶æ€åè®®"><a href="#Stateless-æ— çŠ¶æ€åè®®" class="headerlink" title="Stateless  - æ— çŠ¶æ€åè®®"></a>Stateless  - æ— çŠ¶æ€åè®®</h4><ul><li>Server does not keep track of states of clients<ul><li>Which files are currently open at which clients</li><li>Current position/offset of file</li><li>Which clients have read/cached which blocks</li></ul></li><li>Requests from clients must make sure:<ul><li>the server can deliver all the information needed to complete the requests</li><li>do not rely on previous requests</li></ul></li></ul><h4 id="file-handle"><a href="#file-handle" class="headerlink" title="file handle"></a>file handle</h4><ul><li>Volume (file system) identifier<ul><li>Which volume? (e.g. partition C or D if NTFS)</li></ul></li><li>Inode number<ul><li>Which file in the volume?</li></ul></li><li>Generation number<ul><li>Needed since inode number may be reused at the server (e.g., after file has been deleted by other clients)</li></ul></li></ul><p><strong>Client uses file handle to communication with server</strong><br><img src="/image/file-handle.png"></p><h4 id="RPC-Remote-procedure-call"><a href="#RPC-Remote-procedure-call" class="headerlink" title="RPC - Remote procedure call"></a>RPC - Remote procedure call</h4><ul><li>Remote server publishes a set of procedures, for example f(args)<ul><li>example: NFSPROC_LOOKUP for lookup file handle ,read, write, create, remove, etc.</li></ul></li><li>In making RPC calls,(å®¢æˆ·ç«¯è°ƒç”¨)<ul><li>Client notifies remote server of executing f &amp; sends over arguments args for f</li><li>Server executes f(args) =&gt; results </li><li>Server sends back results</li></ul></li></ul><h3 id="Operations-on-remote-file"><a href="#Operations-on-remote-file" class="headerlink" title="Operations on remote file"></a>Operations on remote file</h3><p>All CRUD operations use <u>file handle</u></p><h4 id="Read"><a href="#Read" class="headerlink" title="Read"></a>Read</h4><p><u>First obtain file handle via lookup</u></p><ul><li>File handle for the root directory may be obtained via the mount protocol</li></ul><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs pgsql">Look up &quot;/foo/more/bar.txt&quot;<br>â€“ First, use / file handle <span class="hljs-keyword">to</span> obtain foo<span class="hljs-string">&#x27;s handle  </span><br><span class="hljs-string">File handle for the root directory may be obtained via the mount protocol</span><br><span class="hljs-string">â€“ Next, use foo&#x27;</span>s handle <span class="hljs-keyword">to</span> obtain mor<span class="hljs-string">e&#x27;s handle</span><br><span class="hljs-string">â€“ Finally, use more&#x27;</span>s handle <span class="hljs-keyword">to</span> obtain bar.txt handle<br></code></pre></td></tr></table></figure><p><u>Then use file handle to read data</u></p><figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs livecodeserver">NFSPROC_READ(<span class="hljs-built_in">file</span> handle, <span class="hljs-built_in">offset</span>, count)<br>- <span class="hljs-built_in">offset</span> here is explicit<br>â€“ Return: data + <span class="hljs-built_in">file</span> attributes<br>â€“ File attributes <span class="hljs-built_in">include</span> modification <span class="hljs-built_in">time</span>, useful <span class="hljs-keyword">for</span> client-size cache validation<br><br>Compared <span class="hljs-built_in">to</span> <span class="hljs-built_in">local</span> <span class="hljs-built_in">file</span> <span class="hljs-keyword">system</span><br>- n = <span class="hljs-built_in">read</span>(fd, buffer, size)<br>â€“ n is <span class="hljs-keyword">the</span> <span class="hljs-built_in">number</span> <span class="hljs-keyword">of</span> <span class="hljs-keyword">bytes</span> actually <span class="hljs-built_in">read</span><br></code></pre></td></tr></table></figure><h4 id="Write"><a href="#Write" class="headerlink" title="Write"></a>Write</h4><p><u>First obtain file handle via lookup</u></p><p><u>Then use file handle to write data</u></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs routeros">NFSPROC_WRITE(file handle, offset, count, data)<br>â€“ Return: file attributes<br>â€“<span class="hljs-built_in"> Note </span>again explicit offset is specified <span class="hljs-keyword">in</span> the call<br><br>Compared <span class="hljs-keyword">to</span> local file system<br>â€“ n = write(fd, buffer, size)<br>â€“ Offset is again implicit (current position)<br></code></pre></td></tr></table></figure><h4 id="Create"><a href="#Create" class="headerlink" title="Create"></a>Create</h4><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"><span class="hljs-constructor">NFSPROC_CREATE(<span class="hljs-params">directory</span> <span class="hljs-params">file</span> <span class="hljs-params">handle</span>, <span class="hljs-params">name</span> <span class="hljs-params">of</span> <span class="hljs-params">file</span> <span class="hljs-params">in</span> <span class="hljs-params">the</span> <span class="hljs-params">directory</span>, <span class="hljs-params">attributes</span>)</span><br>â€“ Return: file handle<br></code></pre></td></tr></table></figure><h4 id="Remove"><a href="#Remove" class="headerlink" title="Remove"></a>Remove</h4><figure class="highlight reasonml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs reasonml"><span class="hljs-constructor">NFSPROC_REMOVE(<span class="hljs-params">directory</span> <span class="hljs-params">file</span> <span class="hljs-params">handle</span>, <span class="hljs-params">name</span> <span class="hljs-params">of</span> <span class="hljs-params">file</span> <span class="hljs-params">to</span> <span class="hljs-params">be</span> <span class="hljs-params">removed</span>)</span><br>â€“ Return: Nothing<br></code></pre></td></tr></table></figure><h3 id="Failures"><a href="#Failures" class="headerlink" title="Failures"></a>Failures</h3><h4 id="Cases"><a href="#Cases" class="headerlink" title="Cases"></a>Cases</h4><p>Case1: request lost<br>Case2: Server down<br>Case3: Reply lost on way back from Sever</p><h3 id="More-details"><a href="#More-details" class="headerlink" title="More details"></a>More details</h3><p>å­¦ä¹ èµ„æº: <a href="https://tools.ietf.org/html/rfc1094">https://tools.ietf.org/html/rfc1094</a></p>]]></content>
    
    
    
    <tags>
      
      <tag>Operating System</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>File systems</title>
    <link href="/2020/09/10/File-Systems/"/>
    <url>/2020/09/10/File-Systems/</url>
    
    <content type="html"><![CDATA[<h3 id="Basic"><a href="#Basic" class="headerlink" title="Basic"></a>Basic</h3><blockquote><p>A filesystem is the methods and data structures that an operating system uses to keep track of files on a disk or partition; that is, the way the files are organized on the disk.</p></blockquote><ul><li>File content stored in blocks on storage device</li><li>Files are organized into directories (folders)<br><img src="/image/file-system.png"></li></ul><h3 id="Detail-about-file"><a href="#Detail-about-file" class="headerlink" title="Detail about file"></a>Detail about file</h3><h4 id="File-descriptor"><a href="#File-descriptor" class="headerlink" title="File descriptor"></a>File descriptor</h4><p>A file descriptor is a number that uniquely identifies an open file in a computerâ€™s operating system. It describes a data resource, and how that resource may be accessed.<br>ç®€å•çš„è¯´ï¼Œæ ¹æ®Linuxä¸€åˆ‡çš†æ–‡ä»¶çš„æ¦‚å¿µæ¥çœ‹ï¼Œå½“è¿›ç¨‹æ‰“å¼€æˆ–è€…åˆ›å»ºæ–‡ä»¶çš„æ—¶å€™ï¼Œå†…æ ¸ä¼šå‘è¿›ç¨‹è¿”å›ä¸€ä¸ªæ•°å­—ï¼Œè¿™ä¸ªæ•°å­—å°±æ˜¯æ–‡ä»¶æè¿°ç¬¦ï¼Œæ‰€æœ‰æ‰§è¡ŒI/Oæ“ä½œçš„ç³»ç»Ÿè°ƒç”¨éƒ½é€šè¿‡æ–‡ä»¶æè¿°ç¬¦æ¥è¿›è¡Œã€‚</p><h4 id="Hard-link-and-symbolic-link-soft-link"><a href="#Hard-link-and-symbolic-link-soft-link" class="headerlink" title="Hard link and symbolic link/soft link"></a>Hard link and symbolic link/soft link</h4><p>A hard link is essentially a synced carbon copy of a file that refers directly to the inode of a file. Symbolic links on the other hand refer directly to the file which refers to the inode, a shortcut.</p><p><img src="/image/hard-soft-link.png"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ ln a.txt b.txt    <span class="hljs-comment"># åˆ›å»ºç¡¬é“¾æ¥ - å‰¯æœ¬</span><br>$ ln -s a.txt c.txt <span class="hljs-comment"># åˆ›å»ºè½¯é“¾æ¥ - æ›¿èº«ï¼ˆå¿«æ·æ–¹å¼ï¼‰</span><br>$ unlink c.txt      <span class="hljs-comment"># å–æ¶ˆé“¾æ¥</span><br></code></pre></td></tr></table></figure><h4 id="File-permission-mode"><a href="#File-permission-mode" class="headerlink" title="File permission mode"></a>File permission mode</h4><p>3ç§æ¨¡å¼  r:read w:write x:execute<br>3ç§èº«ä»½: user group others<br>3*3 = 27 ç§è®¿é—®æƒé™<br>rw-râ€“râ€“ =&gt; 110 (owner permission) 100 (group) 100 (others)<br>å¯ä»¥ä½¿ç”¨<code>chomod</code> æ¥è¿›è¡Œæƒé™çš„ä¿®æ”¹</p><h4 id="Inode"><a href="#Inode" class="headerlink" title="Inode"></a>Inode</h4><p>The inode (index node) is a data structure in a Unix-style file system that describes a file-system object such as a file or a directory. <a href="http://www.ruanyifeng.com/blog/2011/12/inode.html">æ›´å¤šinodeç»†èŠ‚</a> </p><ul><li>Stores metadata/attributes about the file ( use <code>stat file</code> to check the metadata )</li><li>Also stores locations of blocks holding the content of the file</li></ul><h5 id="metadata"><a href="#metadata" class="headerlink" title="metadata"></a>metadata</h5><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs awk">More details about the file metadata<br><br>struct stat &#123;<br>dev_t st_dev; <span class="hljs-regexp">/* ID of device containing file */</span><br>ino_t st_ino; <span class="hljs-regexp">/* inode number */</span><br>mode_t st_mode; <span class="hljs-regexp">/* protection */</span><br>nlink_t st_nlink; <span class="hljs-regexp">/* number of (hard) links */</span><br>uid_t st_uid; <span class="hljs-regexp">/* user ID of owner */</span><br>gid_t st_gid; <span class="hljs-regexp">/* group ID of owner */</span><br>dev_t st_rdev; <span class="hljs-regexp">/* device ID (if special device file, e.g., /</span>etc<span class="hljs-regexp">/tty) */</span> <br>off_t st_size; <span class="hljs-regexp">/* total size, in bytes */</span><br>blksize_t st_blksize; <span class="hljs-regexp">/* blocksize for filesystem I/</span>O */<br>blkcnt_t st_blocks; <span class="hljs-regexp">/* number of blocks allocated */</span><br>time_t st_atime; <span class="hljs-regexp">/* last time file content was accessed */</span><br>time_t st_mtime; <span class="hljs-regexp">/* last time file content was modified */</span> <br>time_t st_ctime; <span class="hljs-regexp">/* last time inode was changed */</span><br>&#125;;<br><br>time_t st_atime; <span class="hljs-regexp">/* last time file content was accessed */</span> å…³äºè¿™ä¸€é¡¹çš„æ€è€ƒï¼š<br>è¿™ä¸€é¡¹è¡¨æ˜äº†ä¸è®ºå¯¹æ–‡ä»¶æ˜¯ä»€ä¹ˆæ“ä½œï¼Œéƒ½ä¼šè¿›è¡Œinodeçš„ä¿®æ”¹ï¼Œæœ‰çš„æ—¶å€™ä¸ºäº†æå‡I/Oæ€§èƒ½ï¼Œä¼šåœ¨æŒ‚è½½æ–‡ä»¶ç³»ç»Ÿçš„æ—¶å€™æŒ‡å®šâ€œnoatime,nodiratimeâ€å‚æ•°ï¼Œæ„å‘³ç€å½“è®¿é—®ä¸€ä¸ªæ–‡ä»¶å’Œç›®å½•çš„æ—¶å€™ï¼Œaccess timeéƒ½ä¸ä¼šæ›´æ–°<br>å¯ä»¥é€šè¿‡ cat <span class="hljs-regexp">/etc/</span>fstab æŸ¥çœ‹å…·ä½“ä¿¡æ¯<br></code></pre></td></tr></table></figure><p><img src="/image/inode.png"></p><h5 id="locations-of-data"><a href="#locations-of-data" class="headerlink" title="locations of data"></a>locations of data</h5><p>An inode has:</p><ul><li>A number of direct pointers,each points to a data block<br>example: a inode has 8 pointers, each pointer points to a 4K block, then this inode is enogh for 8*4K = 32KB size of file</li><li>Also has a slot for indirect pointer : a pointer points to a data block storing direct pointers<br>example: 1 blockâ€™s size: 4KB, pointer size: 4 bytes, then a block can hold 1024 pointers =&gt; Now file can have (8 + 1024) blocks , enough for 4MB size of file</li></ul><p>How to store larger files? - Multi-level index</p><ul><li>Pointers may be organized into multiple levels (double,triple,â€¦n times) </li></ul><p><img src="/image/double-indirect-pointers.png"><br>1 direct pointer =&gt; 1 block (4KB)<br>1 indirect pointer =&gt; 2^10 direct pointer  =  2^10*4KB  = 4MB<br>1 double indirect pointer =&gt; 2^10 indirect pointers =&gt; 2^20 direct pointers  =&gt; 2^20*4KB = 4GB</p><h4 id="Organization-of-blocks"><a href="#Organization-of-blocks" class="headerlink" title="Organization of blocks"></a>Organization of blocks</h4><p>Assumption:(ä¾¿äºç†è§£ï¼Œåšäº›å‡è®¾)</p><ol><li>Disk consists of a list of blocks and they are array-based.(other forms:Tree-based, e.g., SGI XFS -Blocks are organized into variable-length extents)</li><li>a disk with 64 blocks<ul><li>4KB/block   =&gt;æ–‡ä»¶ç³»ç»Ÿçš„æœ€å°å•å…ƒ</li><li>512B/sector =&gt;å­˜å‚¨ç³»ç»Ÿçš„æœ€å°å•å…ƒ </li><li>so there are 2^12/2^9 = 2^3 = 8 sectors/block and capacity of disk = 64 * 4KB = 256KB</li></ul></li></ol><p>Structure about these blocks: </p><ol><li>Data region (56 blocks (#8-63))</li><li>Inode table (5 blocks #3 â€“ #7) å…ƒæ•°æ®+æ–‡ä»¶å†…å®¹åœ°å€<ul><li>assume 256 bytes/inode 5 blocks, 4KB/block</li><li>=&gt; 80 inodes total  (4KB/256B * 5)</li><li>=&gt; File system can store at most 80 files</li></ul></li><li>Bitmaps (#1, #2)  a vector of bits, 0 for free (inode/block), 1 for in-use<ul><li>Inode bitmap (imap):keep track of which inodes in the inode table are available  (è¿™é‡Œ4KBä¸€ä¸ªblock 1byte=8bitï¼Œæ‰€ä»¥ä¸€ä¸ªblockçš„è¯æœ€å¤šä»¥å­˜å‚¨80Kä¸ªinodeçš„çŠ¶æ€)</li><li>Data bitmap (dmap):keep track of which blocks in data region are available</li></ul></li><li>Superblock(#0): Track where i/d blocks and inode table are; Indicate type of FS &amp; inumber of its root dir; Will be read first when file system is mounted</li></ol><p><img src="/image/block_info_fs.png"></p><h4 id="Inumber"><a href="#Inumber" class="headerlink" title="Inumber"></a>Inumber</h4><p>Each inode is identified by a number: Low-level number of file name<br>Can figure out location of inode from inumber é€šè¿‡inumberå¯ä»¥å¯»å€åˆ°å…¶ä»£è¡¨çš„inodeæ‰€åœ¨çš„sector<br>Location:  âŒŠ(inodeStartAddress + inumber âˆ— inode size)/sector sizeâŒ‹</p><p>example: inumber = 32<br>Address:12K+32*256=20K<br>Sector #: 20K/512 = 40<br><img src="/image/inumber.png"></p><p>æ€»ç»“inumber,inode,dataä¸€å¥è¯æ¥è¯´å°±æ˜¯inumber =&gt; inode =&gt; data</p><h3 id="Detail-about-directory"><a href="#Detail-about-directory" class="headerlink" title="Detail about directory"></a>Detail about directory</h3><h4 id="Basic-1"><a href="#Basic-1" class="headerlink" title="Basic"></a>Basic</h4><ul><li>Directory itself stored as a file</li><li>For each file in the directory, it stores:<ul><li>name, inumber, record length, string length</li></ul></li><li>If file is deleted (using rm command) or a name is unlinked (using unlink command),then inumber in its directory entry set to 0 (reserved for empty entry)<ul><li>File is finally deleted when its last (hard) link is removed<br><img src="/image/directory.png"></li></ul></li></ul><h4 id="Storing-a-directory"><a href="#Storing-a-directory" class="headerlink" title="Storing a directory"></a>Storing a directory</h4><ul><li>Also as a file with its own inode + data block</li><li>inode:<ul><li>file type: directory (instead of regular file)</li><li>pointer to block(s) in data region storing directory entries</li></ul></li></ul><h3 id="Operations-on-file"><a href="#Operations-on-file" class="headerlink" title="Operations on file"></a>Operations on file</h3><ul><li>Create: open(), write()</li><li>Read:  open(),read(), lseek()</li><li>Update: write(), lseek()</li><li>Delete: unlink()</li></ul><p>Note: è¿™äº›å‡½æ•°éƒ½æ˜¯æ“ä½œç³»ç»Ÿè‡ªå¸¦æä¾›çš„ç³»ç»Ÿè°ƒç”¨å‡½æ•°</p><h4 id="Read"><a href="#Read" class="headerlink" title="Read"></a>Read</h4><ul><li>User interface via GUI or touch command in Linux</li><li>Implementation, e.g., via a C program with a system call: open()</li><li>open() returns a file descriptor. Reserved fds: stdin 0, stdout, 1, stderr 2</li><li>After getting the file descriptor of file, start read() <figure class="highlight vhdl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs vhdl">fd = <span class="hljs-keyword">open</span>(<span class="hljs-string">&quot;/foo/bar&quot;</span>, O_RDONLY)<br>- Need <span class="hljs-keyword">to</span> locate inode <span class="hljs-keyword">of</span> the <span class="hljs-keyword">file</span> <span class="hljs-string">&quot;/foo/bar&quot;</span><br>- <span class="hljs-keyword">Assume</span> inumber <span class="hljs-keyword">of</span> root, say <span class="hljs-number">2</span>, <span class="hljs-keyword">is</span> known (e.g., <span class="hljs-keyword">when</span> the <span class="hljs-keyword">file</span> system <span class="hljs-keyword">is</span> mounted)<br><br>step1: read inode <span class="hljs-keyword">and</span> content <span class="hljs-keyword">of</span> /  (<span class="hljs-number">2</span> reads)<br>- Look <span class="hljs-keyword">for</span> <span class="hljs-string">&quot;foo&quot;</span> <span class="hljs-keyword">in</span> / -&gt; foo<span class="hljs-symbol">&#x27;s</span> inumber<br><br>step2: read inode <span class="hljs-keyword">and</span> content <span class="hljs-keyword">of</span> /foo (<span class="hljs-number">2</span> reads)<br>- Look <span class="hljs-keyword">for</span> <span class="hljs-string">&quot;bar&quot;</span> <span class="hljs-keyword">in</span> /foo -&gt; bar<span class="hljs-symbol">&#x27;s</span> inumber<br><br>step3: read inode <span class="hljs-keyword">of</span> /foo/bar (<span class="hljs-number">1</span> read)<br>â€“ Permission check + allocate <span class="hljs-keyword">file</span> descriptor<br><br><span class="hljs-keyword">open</span>-<span class="hljs-keyword">file</span> table per <span class="hljs-keyword">process</span>(ç»´æŠ¤è¿™äº›è¿›ç¨‹ï¼Œç³»ç»Ÿæœ‰ä¸€ä¸ª <span class="hljs-keyword">open</span>-<span class="hljs-keyword">file</span> table)<br><br><br>read(fd, <span class="hljs-keyword">buffer</span>, size)<br>â€“ <span class="hljs-literal">Note</span> fd <span class="hljs-keyword">is</span> maintained <span class="hljs-keyword">in</span> per-<span class="hljs-keyword">process</span> <span class="hljs-keyword">open</span>-<span class="hljs-keyword">file</span> table<br>â€“ Table translates fd -&gt; inumber <span class="hljs-keyword">of</span> <span class="hljs-keyword">file</span><br><br>step1: consult bar<span class="hljs-symbol">&#x27;s</span> inode <span class="hljs-keyword">to</span> locate a <span class="hljs-keyword">block</span><br>step2: read the <span class="hljs-keyword">block</span><br>step3: update inode <span class="hljs-keyword">with</span> newest <span class="hljs-keyword">file</span> <span class="hljs-keyword">access</span> <span class="hljs-built_in">time</span><br>step4: update <span class="hljs-keyword">open</span>-<span class="hljs-keyword">file</span> table <span class="hljs-keyword">with</span> <span class="hljs-keyword">new</span> offset<br>step5: repeat above steps <span class="hljs-keyword">until</span> done(<span class="hljs-keyword">with</span> reading data <span class="hljs-keyword">of</span> given size)<br><br></code></pre></td></tr></table></figure><img src="/image/read.png"></li></ul><p>I/O cost for open(): 5 reads<br>I/O cost for reading a block: 2 reads + 1 write</p><h4 id="Write"><a href="#Write" class="headerlink" title="Write"></a>Write</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs sql">int fd = open(&quot;/foo/bar&quot;, O_WRONLY)<br>â€“ Or int fd = <span class="hljs-keyword">create</span>((<span class="hljs-string">&quot;/foo/bar&quot;</span>)<br>â€“ Assume bar <span class="hljs-keyword">is</span> a <span class="hljs-keyword">new</span> <span class="hljs-keyword">file</span> <span class="hljs-keyword">under</span> foo<br><br>step1: <span class="hljs-keyword">read</span><span class="hljs-string">&#x27;/&#x27;</span>inode &amp; <span class="hljs-keyword">content</span> -&gt; obtain foo<span class="hljs-string">&#x27;s inumber</span><br><span class="hljs-string">step2: read&#x27;</span>/foo<span class="hljs-string">&#x27;inode &amp; content -&gt; check if bar exists</span><br><span class="hljs-string">step3: read imap,to find a free inode for bar</span><br><span class="hljs-string">step4: update imap,setting 1 for allocated inode</span><br><span class="hljs-string">step5: write bar&#x27;</span>s inode<br>step6: <span class="hljs-keyword">update</span> foo<span class="hljs-string">&#x27;s content block  - adding an entry for bar</span><br><span class="hljs-string">step7: update foo&#x27;</span>s inode  -<span class="hljs-keyword">update</span> its <span class="hljs-keyword">modification</span> <span class="hljs-built_in">time</span><br><br>write(fd, buffer, <span class="hljs-keyword">size</span>)<br>step1: <span class="hljs-keyword">read</span> inode <span class="hljs-keyword">of</span> bar(<span class="hljs-keyword">by</span> looking up its inumber <span class="hljs-keyword">in</span> the <span class="hljs-keyword">open</span>-<span class="hljs-keyword">file</span> <span class="hljs-keyword">table</span>)<br>step2: <span class="hljs-keyword">allocate</span> <span class="hljs-keyword">new</span> <span class="hljs-keyword">data</span> <span class="hljs-keyword">block</span> â€“ <span class="hljs-keyword">read</span> <span class="hljs-keyword">and</span> write bmap<br>step3: write <span class="hljs-keyword">to</span> <span class="hljs-keyword">data</span> <span class="hljs-keyword">block</span> <span class="hljs-keyword">of</span> bar<br>step4: <span class="hljs-keyword">update</span> bar node - <span class="hljs-keyword">new</span> <span class="hljs-keyword">modification</span> <span class="hljs-built_in">time</span>, <span class="hljs-keyword">add</span> pointer <span class="hljs-keyword">to</span> <span class="hljs-keyword">block</span><br></code></pre></td></tr></table></figure><p><img src="/image/write.png"></p>]]></content>
    
    
    
    <tags>
      
      <tag>Operating System</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>spaCyå­¦ä¹ </title>
    <link href="/2020/09/10/spacy-learning/"/>
    <url>/2020/09/10/spacy-learning/</url>
    
    <content type="html"><![CDATA[<h2 id="åŸºæœ¬æ¦‚å¿µ"><a href="#åŸºæœ¬æ¦‚å¿µ" class="headerlink" title="åŸºæœ¬æ¦‚å¿µ"></a>åŸºæœ¬æ¦‚å¿µ</h2><blockquote><p>spaCy (/speÉªËˆsiË/) is an open-source software library for advanced natural language processing written in the programming languages Python and Cython.</p></blockquote><p>å­¦ä¹ èµ„æº: <a href="https://spacy.io/">https://spacy.io/</a>  <a href="https://course.spacy.io/en">https://course.spacy.io/en</a></p><h3 id="æ•°æ®ç»“æ„"><a href="#æ•°æ®ç»“æ„" class="headerlink" title="æ•°æ®ç»“æ„"></a>æ•°æ®ç»“æ„</h3><ul><li>nlp   : contains the processing pipeline; includes language-specific rules for tokenization etc.</li><li>doc   : access information about the text in a structured way, and no information is lost.</li><li>token : tokens in a document â€“ for example, a word or a punctuation character.</li><li>span  : a slice of the document consisting of one or more tokens</li><li>lexical attributes : <code>token.i</code>, <code>token.text</code>, <code>token.is_alpha</code>, <code>token.is_punct</code>, <code>token.like_num</code>â€¦ They refer to the entry in the vocabulary and donâ€™t depend on the tokenâ€™s context.</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># å¯¼å…¥å¯¹åº”è¯­è¨€ç±» Note: Some language tokenizers require external dependencies. </span><br><span class="hljs-keyword">from</span> spacy.lang.zh <span class="hljs-keyword">import</span> Chinese   <span class="hljs-comment"># https://spacy.io/usage/models æŸ¥çœ‹langåé¢å¯¹åº”çš„å­—ç¬¦</span><br><br><span class="hljs-comment"># åˆ›å»ºnlpå®ä¾‹</span><br>nlp = Chinese() <br><br><span class="hljs-comment"># ä½¿ç”¨nlpå¯¹è±¡å¤„ç†ä¸€æ®µæ–‡æœ¬å¹¶ç”Ÿæˆdocå®ä¾‹</span><br><span class="hljs-comment"># When you call nlp on a string, spaCy first tokenizes the text and creates a document object.  </span><br>doc = nlp(<span class="hljs-string">&quot;è¿™æ˜¯ä¸€ä¸ªå¥å­ã€‚&quot;</span>) <span class="hljs-comment"># åº•å±‚è°ƒç”¨ __call__æ–¹æ³•</span><br>  <br><span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> doc:  <span class="hljs-comment"># éå†docå®ä¾‹ä¸­çš„token</span><br>    print(token.text)  <br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">è¿™æ˜¯</span><br><span class="hljs-string">ä¸€ä¸ª</span><br><span class="hljs-string">å¥å­</span><br><span class="hljs-string">ã€‚</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment"># ä½¿ç”¨ç´¢å¼•è·å¾—æŸä¸€ä¸ªtoken</span><br>specific_token = doc[<span class="hljs-number">1</span>]<br><br><span class="hljs-comment"># ä½¿ç”¨åˆ‡ç‰‡è·å¾—docç‰‡æ®µ</span><br>span = doc[<span class="hljs-number">1</span>:<span class="hljs-number">3</span>]<br><br><span class="hljs-comment"># tokençš„ä¸€äº›å±æ€§</span><br>doc = nlp(<span class="hljs-string">&quot;æˆ‘èŠ±äº†20Â¥ä¹°äº†ä¸€ä¸ªæ±‰å ¡åŒ…ã€‚&quot;</span>)<br>print(<span class="hljs-string">&quot;Index:   &quot;</span>, [token.i <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> doc])<br>print(<span class="hljs-string">&quot;Text:    &quot;</span>, [token.text <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> doc])<br>print(<span class="hljs-string">&quot;is_alpha:&quot;</span>, [token.is_alpha <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> doc])<br>print(<span class="hljs-string">&quot;is_punct:&quot;</span>, [token.is_punct <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> doc])<br>print(<span class="hljs-string">&quot;like_num:&quot;</span>, [token.like_num <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> doc])<br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">Index:    [0, 1, 2, 3, 4, 5, 6, 7, 8]</span><br><span class="hljs-string">Text:     [&#x27;æˆ‘èŠ±&#x27;, &#x27;äº†&#x27;, &#x27;20&#x27;, &#x27;Â¥&#x27;, &#x27;ä¹°&#x27;, &#x27;äº†&#x27;, &#x27;ä¸€ä¸ª&#x27;, &#x27;æ±‰å ¡åŒ…&#x27;, &#x27;ã€‚&#x27;]</span><br><span class="hljs-string">is_alpha: [True, True, False, False, True, True, True, True, False]</span><br><span class="hljs-string">is_punct: [False, False, False, False, False, False, False, False, True]</span><br><span class="hljs-string">like_num: [False, False, True, False, False, False, False, False, False]</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><h3 id="ç»Ÿè®¡æ¨¡å‹"><a href="#ç»Ÿè®¡æ¨¡å‹" class="headerlink" title="ç»Ÿè®¡æ¨¡å‹"></a>ç»Ÿè®¡æ¨¡å‹</h3><p>æ¥æº: Models are trained on large datasets of labeled example texts.<br>ä½œç”¨: è¯æ€§æ ‡æ³¨ (Part-of-speech tags), ä¾å­˜å…³ç³»è§£æ (Syntactic dependencies), å‘½åå®ä½“è¯†åˆ« (Named entities)<br>ä¼˜åŒ–: Can be updated with more examples to fine-tune predictions</p><h3 id="æ¨¡å‹åŒ…"><a href="#æ¨¡å‹åŒ…" class="headerlink" title="æ¨¡å‹åŒ…"></a>æ¨¡å‹åŒ…</h3><p>spaCyæä¾›äº†å¾ˆå¤šé¢„è®­ç»ƒå¥½çš„æ¨¡å‹åŒ…ï¼Œå¯ä»¥ä½¿ç”¨<code>spacy download</code>è¿›è¡Œä¸‹è½½ <a href="https://spacy.io/usage/models">https://spacy.io/usage/models</a></p><p>The package provides </p><ul><li>binary weights that enable spaCy to make predictions;</li><li>vocabulary, and meta information to tell spaCy which language class to use;</li><li>how to configure the processing pipeline;</li></ul><p>å¯¼å…¥æ¨¡å‹åŒ…å’Œé€šè¿‡åˆå§‹åŒ–è¯­è¨€ç±»çš„nlpå®ä¾‹åŒºåˆ«ï¼Ÿ</p><ul><li>spacy.lang.xxxä¸­åŒ…å«å…¶å®æ˜¯ç‰¹å®šè¯­è¨€çš„ä»£ç å’Œè§„åˆ™ï¼ŒåŒ…æ‹¬åœç”¨è¯ï¼Œæ•°å­—ä¹‹ç±»,ç®€å•è®¤ä¸ºå°±æ˜¯æœ€åŸºç¡€çš„ä¸€äº›è§„åˆ™</li><li>æ¨¡å‹åŒ…æ˜¯å»ºç«‹åœ¨å·²ç»å¯¹å¤§é‡çš„æ ‡è®°æ•°æ®è¿›è¡Œè®­ç»ƒåå¾—åˆ°çš„ç»Ÿè®¡æ¨¡å‹ï¼Œç®€å•è®¤ä¸ºæ˜¯åŸºäºspacy.lang.xxxä¸­æŸä¸€ç§è¯­è¨€æœ€åŸºç¡€è§„åˆ™ä¹‹ä¸Š,å¯¹å¤§é‡æ•°æ®è¿›è¡Œè®­ç»ƒå­¦ä¹ å¾—åˆ°çš„æ›´å¤šè§„åˆ™</li></ul><h3 id="è¯æ€§æ ‡æ³¨-Part-of-speech-tags"><a href="#è¯æ€§æ ‡æ³¨-Part-of-speech-tags" class="headerlink" title="è¯æ€§æ ‡æ³¨ (Part-of-speech tags)"></a>è¯æ€§æ ‡æ³¨ (Part-of-speech tags)</h3><p>é€šè¿‡æ ‡æ³¨æ¯ä¸€ä¸ªtokençš„è¯æ€§ï¼Œä¸ºåäºæ–‡æœ¬å¤„ç†æä¾›åŸºç¡€ä¿è¯ï¼Œ<code>.pos_</code>å±æ€§è¿”å›è¯æ€§æ ‡æ³¨çš„ç»“æœ</p><h3 id="ä¾å­˜å…³ç³»è§£æ-Syntactic-dependencies"><a href="#ä¾å­˜å…³ç³»è§£æ-Syntactic-dependencies" class="headerlink" title="ä¾å­˜å…³ç³»è§£æ (Syntactic dependencies)"></a>ä¾å­˜å…³ç³»è§£æ (Syntactic dependencies)</h3><p>ç”±äºå·²ç»å¯¹äºtokenåšäº†è¯æ€§æ ‡æ³¨ï¼Œç”±æ­¤å¯ä»¥è¿›ä¸€æ­¥æ¥è¿›è¡Œè¯ä¸è¯ä¹‹é—´çš„å…³ç³»çš„é¢„æµ‹ã€‚æ¯”å¦‚ä¸€ä¸ªè¯æ˜¯æŸä¸€ä¸ªå¥å­æˆ–è€…ç‰©ä½“çš„ä¸»è¯­ã€‚<code>.dep_</code>å±æ€§è¿”å›é¢„æµ‹çš„ä¾å­˜å…³ç³»æ ‡æ³¨,<code>.head</code>å±æ€§è¿”å›å½“å‰tokençš„parent token(ä¹Ÿå°±æ˜¯ä¾å­˜çš„é‚£ä¸€ä¸ªtoken)</p><p>å…³äºä¾å­˜å…³ç³»:<br>20ä¸–çºª70å¹´ä»£ï¼ŒRobinsonæå‡ºä¾å­˜è¯­æ³•ä¸­å…³äºä¾å­˜å…³ç³»çš„å››æ¡å…¬ç†ï¼š</p><ul><li>ä¸€ä¸ªå¥å­ä¸­åªæœ‰ä¸€ä¸ªæˆåˆ†æ˜¯ç‹¬ç«‹çš„ï¼›</li><li>å…¶å®ƒæˆåˆ†ç›´æ¥ä¾å­˜äºæŸä¸€æˆåˆ†ï¼›</li><li>ä»»ä½•ä¸€ä¸ªæˆåˆ†éƒ½ä¸èƒ½ä¾å­˜ä¸ä¸¤ä¸ªæˆ–ä¸¤ä¸ªä»¥ä¸Šçš„æˆåˆ†ï¼›</li><li>å¦‚æœAæˆåˆ†ç›´æ¥ä¾å­˜äºBæˆåˆ†ï¼Œè€ŒCæˆåˆ†åœ¨å¥ä¸­ä½äºAå’ŒBä¹‹é—´ï¼Œé‚£ä¹ˆCæˆ–è€…ç›´æ¥ä¾å­˜äºBï¼Œæˆ–è€…ç›´æ¥ä¾å­˜äºAå’ŒBä¹‹é—´çš„æŸä¸€æˆåˆ†ï¼›</li></ul><p>ä¾å­˜ç»“æ„æ˜¯åŠ æ ‡ç­¾çš„æœ‰å‘å›¾ï¼Œç®­å¤´ä»ä¸­å¿ƒè¯æŒ‡å‘ä»å±ï¼Œå…·ä½“æ¥è¯´ï¼Œç®­å¤´æ˜¯ä»headæŒ‡å‘child,ä¸¾ä¸ªä¾‹å­ï¼š I love you,ä¸­ I ä¾å­˜äº love,æ‰€ä»¥ä¼šæœ‰ä¸€æ¡æœ‰å‘è¾¹ä»loveæŒ‡å‘I<br><img src="/image/dependency_scapy.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># å¯è§†åŒ–ä¾å­˜å…³ç³»å›¾</span><br><span class="hljs-keyword">from</span> spacy <span class="hljs-keyword">import</span> displacy<br>options = &#123;<span class="hljs-string">&quot;distance&quot;</span>: <span class="hljs-number">120</span>&#125;<br>displacy.render(doc, style=<span class="hljs-string">&quot;dep&quot;</span>, options=options)<br></code></pre></td></tr></table></figure><p>å¸¸ç”¨çš„ä¾å­˜æ ‡ç­¾ï¼š<br>root:  ä¸­å¿ƒè¯,ä¸€èˆ¬ä¸ºåŠ¨è¯<br>nsubj: nominal subject,åè¯æ€§ä¸»è¯­<br>dobj:  direct object, ç›´æ¥å®¾è¯­<br>prep: ä»‹è¯<br>pobj: ä»‹è¯å®¾è¯­<br>cc: è¿è¯<br>compound: å¤åˆè¯<br>advmod: çŠ¶è¯­<br>det: é™å®šè¯<br>amod: å½¢å®¹è¯ä¿®é¥°è¯­</p><h3 id="å‘½åå®ä½“è¯†åˆ«-Named-entities"><a href="#å‘½åå®ä½“è¯†åˆ«-Named-entities" class="headerlink" title="å‘½åå®ä½“è¯†åˆ« (Named entities)"></a>å‘½åå®ä½“è¯†åˆ« (Named entities)</h3><p><code>doc.ents</code>è¯»å–æ¨¡å‹é¢„æµ‹å‡ºçš„æ‰€æœ‰å‘½åå®ä½“,ä¾‹å¦‚Bill Gates,ä½¿ç”¨<code>.label_</code>å±æ€§æ‰“å°å‡ºå®ä½“æ ‡ç­¾ï¼Œä¾‹å¦‚Person</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><code class="hljs python">$ python -m spacy download zh_core_web_sm <br><br><span class="hljs-keyword">import</span> spacy<br>nlp = spacy.load(<span class="hljs-string">&quot;en_core_web_md&quot;</span>)  <span class="hljs-comment"># load a model package by name and returns an nlp object.</span><br><br><span class="hljs-comment"># Process a text</span><br>doc = nlp(<span class="hljs-string">&quot;I love you!&quot;</span>)<br><br><span class="hljs-comment"># Iterate over the tokens</span><br><span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> doc:<br>    <span class="hljs-comment"># Print the text and the predicted part-of-speech tag</span><br>    print(token.text, token.pos_)<br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">I PRON</span><br><span class="hljs-string">love VERB</span><br><span class="hljs-string">you PRON</span><br><span class="hljs-string">! PUNCT</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> doc:<br>    print(token.text, token.pos_, token.dep_, token.head.text)<br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">I PRON nsubj love</span><br><span class="hljs-string">love VERB ROOT love</span><br><span class="hljs-string">you PRON dobj love</span><br><span class="hljs-string">! PUNCT punct love</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment"># Process a text</span><br>doc = nlp(<span class="hljs-string">&quot;Apple is looking at buying U.K. startup for $1 billion&quot;</span>)<br><br><span class="hljs-comment"># Iterate over the predicted entities</span><br><span class="hljs-keyword">for</span> ent <span class="hljs-keyword">in</span> doc.ents:<br>    <span class="hljs-comment"># Print the entity text and its label</span><br>    print(ent.text, ent.label_)<br><br><span class="hljs-comment"># Process a text</span><br>doc = nlp(<span class="hljs-string">&quot;Microsoft Corporation is an American multinational technology company with headquarters in Redmond, Washington.&quot;</span>)<br><br><span class="hljs-comment"># Iterate over the predicted entities</span><br><span class="hljs-keyword">for</span> ent <span class="hljs-keyword">in</span> doc.ents:<br>    <span class="hljs-comment"># Print the entity text and its label</span><br>    print(ent.text, ent.label_)<br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">Microsoft Corporation ORG</span><br><span class="hljs-string">American NORP</span><br><span class="hljs-string">Redmond GPE</span><br><span class="hljs-string">Washington GPE</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><br><span class="hljs-comment"># Get quick definitions of the most common tags and labels.</span><br>spacy.explain(<span class="hljs-string">&#x27;NORP&#x27;</span>)<br><span class="hljs-string">&#x27;Nationalities or religious or political groups&#x27;</span><br></code></pre></td></tr></table></figure><h3 id="åŸºäºè§„åˆ™çš„åŒ¹é…æŠ½å–"><a href="#åŸºäºè§„åˆ™çš„åŒ¹é…æŠ½å–" class="headerlink" title="åŸºäºè§„åˆ™çš„åŒ¹é…æŠ½å–"></a>åŸºäºè§„åˆ™çš„åŒ¹é…æŠ½å–</h3><p>ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹çš„ç¼ºé™·ï¼šæ¨¡å‹çš„é¢„æµ‹æ˜¯å¦æ­£ç¡®å–å†³äºè®­ç»ƒæ•°æ®å’Œå¤„ç†çš„æ–‡æœ¬ï¼Œå¦‚æœå¤„ç†çš„æ–‡æœ¬ä¸­è®¸å¤šè§„åˆ™æ²¡æœ‰è¢«æ¨¡å‹åŒ…å«ï¼Œåˆ™é¢„æµ‹çš„ç²¾åº¦ä¸ä¼šå¾ˆé«˜ã€‚<br>è§£å†³æ–¹æ¡ˆ: ä½¿ç”¨é¢„è®­ç»ƒçš„æ¨¡å‹ + æ·»åŠ ç›¸åº”çš„è§„åˆ™</p><p>Match patterns</p><ul><li>Lists of dictionaries, one per token  [{},{},{}]</li><li>Match exact token texts</li><li>Match lexical attributes</li><li>Match any token attributes </li></ul><p>Match step:</p><ol><li>Import the <code>Matcher</code> from <code>spacy.matcher</code>.</li><li>Initialize it with the <code>nlp</code> objectâ€™s shared <code>vocab</code>.</li><li>Create patterns</li><li>Use the <code>matcher.add</code> to add the pattern to the matcher.</li><li>Call the matcher on the <code>doc</code> and store the result in the variable matches.</li><li>Iterate over the matches and get the matched span from the <code>start</code> to the <code>end</code> index.</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> spacy<br><span class="hljs-keyword">from</span> spacy.matcher <span class="hljs-keyword">import</span> Matcher <span class="hljs-comment"># # Import the Matcher</span><br><br>nlp = spacy.load(<span class="hljs-string">&quot;en_core_web_md&quot;</span>)<br><br><span class="hljs-comment"># Initialize the matcher with the shared vocab</span><br>matcher = Matcher(nlp.vocab)<br><br><span class="hljs-comment"># Add the pattern to the matcher</span><br>pattern = [&#123;<span class="hljs-string">&quot;TEXT&quot;</span>: <span class="hljs-string">&quot;iPhone&quot;</span>&#125;, &#123;<span class="hljs-string">&quot;TEXT&quot;</span>: <span class="hljs-string">&quot;X&quot;</span>&#125;]<br>matcher.add(<span class="hljs-string">&quot;IPHONE_PATTERN&quot;</span>, <span class="hljs-literal">None</span>, pattern)<br><br><br><span class="hljs-comment"># å…¶å®ä¸€ä¸ªpatternå°±æ˜¯ä¸€ä¸ªæˆ–è€…å¤šä¸ªtokençš„ç»„åˆï¼Œç„¶å&#123;&#125;è¡¨ç¤ºè¿™ä¸ªtokenéœ€è¦æ»¡è¶³çš„æ¡ä»¶</span><br><span class="hljs-comment">#ä¾‹å­ï¼š</span><br>pattern_example = [<br>    &#123;<span class="hljs-string">&quot;LEMMA&quot;</span>: <span class="hljs-string">&quot;like&quot;</span>, <span class="hljs-string">&quot;POS&quot;</span>: <span class="hljs-string">&quot;VERB&quot;</span>&#125;,<br>    &#123;<span class="hljs-string">&quot;POS&quot;</span>: <span class="hljs-string">&quot;NOUN&quot;</span>&#125;<br>]<br><br><span class="hljs-comment"># Process some text</span><br>doc = nlp(<span class="hljs-string">&quot;Upcoming iPhone X release date leaked&quot;</span>)<br><br><span class="hljs-comment"># Call the matcher on the doc</span><br>matches = matcher(doc)<br><br><span class="hljs-comment"># Iterate over the matches</span><br><span class="hljs-keyword">for</span> match_id, start, end <span class="hljs-keyword">in</span> matches:<br>    <span class="hljs-comment"># Get the matched span</span><br>    matched_span = doc[start:end]<br>    print(matched_span.text)<br>    print(nlp.vocab.strings[match_id])  <span class="hljs-comment"># é€šè¿‡match_id è·å–å½“åˆåŠ å…¥patternçš„åç§°)</span><br><br><span class="hljs-string">&#x27;iPhone X&#x27;</span><br><span class="hljs-string">&#x27;IPHONE_PATTERN&#x27;</span><br><br><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">&#123;&quot;OP&quot;: &quot;!&quot;&#125;Negation: match 0 times</span><br><span class="hljs-string">&#123;&quot;OP&quot;: &quot;?&quot;&#125;Optional: match 0 or 1 times</span><br><span class="hljs-string">&#123;&quot;OP&quot;: &quot;+&quot;&#125;Match 1 or more times</span><br><span class="hljs-string">&#123;&quot;OP&quot;: &quot;*&quot;&#125;Match 0 or more times</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><h2 id="è¿›é˜¶"><a href="#è¿›é˜¶" class="headerlink" title="è¿›é˜¶"></a>è¿›é˜¶</h2><h3 id="Vocab-å…±äº«è¯æ±‡è¡¨"><a href="#Vocab-å…±äº«è¯æ±‡è¡¨" class="headerlink" title="Vocab:å…±äº«è¯æ±‡è¡¨"></a>Vocab:å…±äº«è¯æ±‡è¡¨</h3><ul><li>spaCyæŠŠæ‰€æœ‰å…±äº«æ•°æ®éƒ½å­˜åœ¨ä¸€ä¸ªè¯æ±‡è¡¨Vocabä¸­</li><li>æ‰€æœ‰çš„å­—ç¬¦ä¸²éƒ½è¢«ç¼–ç æˆå“ˆå¸ŒID</li><li>Vocabåº“ä¸ºä¸€ä¸ªåŒå‘çš„æŸ¥è¯¢è¡¨ï¼Œå­—ç¬¦ä¸²-&gt;hashå€¼ï¼› hashå€¼-&gt;å­—ç¬¦ä¸²</li><li>å“ˆå¸Œä¸èƒ½é€†æ±‚è§£,é€šè¿‡hashå€¼æ£€ç´¢æŸä¸€ä¸ªä¸åœ¨Vocabä¸­çš„å­—ç¬¦ä¸²ä¼šæŠ¥é”™</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">doc = nlp(<span class="hljs-string">&quot;I love you&quot;</span>)<br>print(<span class="hljs-string">&quot;hash value:&quot;</span>, nlp.vocab.strings[<span class="hljs-string">&quot;love&quot;</span>])<br>print(<span class="hljs-string">&quot;string value:&quot;</span>, nlp.vocab.strings[<span class="hljs-number">3702023516439754181</span>])<br><br><span class="hljs-comment">#ä¸€ä¸ªDocå®ä¾‹ä¹Ÿå¯ä»¥æš´éœ²å‡ºå®ƒçš„è¯æ±‡è¡¨å’Œå­—ç¬¦ä¸²</span><br><span class="hljs-comment">#å¦ä¸€ç§æ–¹å¼</span><br>print(<span class="hljs-string">&quot;string value:&quot;</span>, doc.vocab.strings[<span class="hljs-number">3702023516439754181</span>])<br></code></pre></td></tr></table></figure><h3 id="Lexeme-è¯­ç´ "><a href="#Lexeme-è¯­ç´ " class="headerlink" title="Lexeme:è¯­ç´ "></a>Lexeme:è¯­ç´ </h3><p>Lexemeï¼ˆè¯­ç´ ï¼‰æ˜¯è¯æ±‡è¡¨ä¸­å’Œè¯­å¢ƒæ— å…³çš„å…ƒç´ ,ä»£è¡¨ç€ä¸€ä¸ªè¯çš„å’Œè¯­å¢ƒæ— å…³çš„ä¿¡æ¯ï¼Œæ¯”å¦‚æ–‡æœ¬æœ¬èº«ï¼Œæˆ–è€…æ˜¯è¿™ä¸ªè¯æ˜¯å¦åŒ…å«äº†è‹±æ–‡å­—æ¯,Lexemeä¸­æ²¡æœ‰è¯æ€§æ ‡æ³¨ã€ä¾å­˜å…³ç³»æˆ–è€…å®ä½“æ ‡ç­¾è¿™äº›å’Œè¯­å¢ƒå…³è”çš„ä¿¡æ¯ã€‚<br>åœ¨è¯æ±‡è¡¨ä¸­æŸ¥è¯¢ä¸€ä¸ªå­—ç¬¦ä¸²æˆ–è€…ä¸€ä¸ªå“ˆå¸ŒIDå°±ä¼šè·å¾—ä¸€ä¸ªlexemeã€‚<code>lexeme.text</code>è¡¨ç¤ºå…¶æ–‡æœ¬, <code>lexeme.orth</code>è¡¨ç¤ºå…¶hashå€¼</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">doc = nlp(<span class="hljs-string">&quot;I love you&quot;</span>)<br>lexeme = nlp.vocab[<span class="hljs-string">&#x27;love&#x27;</span>]<br><br><span class="hljs-comment"># æ‰“å°è¯æ±‡çš„å±æ€§</span><br>print(lexeme.text, lexeme.orth, lexeme.is_alpha)<br></code></pre></td></tr></table></figure><p>ä¸€å¥è¯æ€»ç»“å°±æ˜¯ï¼šdocä¸­çš„æ¯ä¸€ä¸ªtokenå¯¹åº”ä¸€ä¸ªlexeme,å…¶ä¸­ä¿å­˜ç€å¯¹åº”çš„æ–‡æœ¬ä¿¡æ¯å’Œhashå€¼,è¦æ‹¿åˆ°æ–‡æœ¬ä¿¡æ¯ï¼Œé¦–å…ˆå»Vocabä¸­æŸ¥æ‰¾å¯¹åº”çš„hashå€¼ã€‚</p><h3 id="Doc-Spançš„æ‰‹åŠ¨åˆ›å»º"><a href="#Doc-Spançš„æ‰‹åŠ¨åˆ›å»º" class="headerlink" title="Doc, Spançš„æ‰‹åŠ¨åˆ›å»º"></a>Doc, Spançš„æ‰‹åŠ¨åˆ›å»º</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> spacy.tokens <span class="hljs-keyword">import</span> Doc,Span<br>words = [<span class="hljs-string">&quot;Hello&quot;</span>, <span class="hljs-string">&quot;world&quot;</span>, <span class="hljs-string">&quot;!&quot;</span>]<br>spaces = [<span class="hljs-literal">True</span>, <span class="hljs-literal">False</span>, <span class="hljs-literal">False</span>]<br>doc = Doc(nlp.vocab, words=words, spaces=spaces) <br><span class="hljs-comment"># ä¸‰ä¸ªå‚æ•°ï¼šå…±äº«çš„è¯æ±‡è¡¨ï¼Œè¯æ±‡å’Œç©ºæ ¼</span><br><br>span = Span(doc, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>)<br> <br><span class="hljs-comment"># åˆ›å»ºä¸€ä¸ªå¸¦æ ‡ç­¾çš„span  è¿™é‡Œçš„å¸¦æ ‡ç­¾å¾ˆæœ‰ç”¨ï¼</span><br>span_with_label = Span(doc, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>, label=<span class="hljs-string">&quot;GREETING&quot;</span>)<br><span class="hljs-comment"># æŠŠspanåŠ å…¥åˆ°doc.entsä¸­  doc.entsæ˜¯å¯å†™çš„,å¯ä»¥äººä¸ºæ·»åŠ </span><br>doc.ents = [span_with_label]<br></code></pre></td></tr></table></figure><h3 id="è¯­ä¹‰ç›¸ä¼¼åº¦"><a href="#è¯­ä¹‰ç›¸ä¼¼åº¦" class="headerlink" title="è¯­ä¹‰ç›¸ä¼¼åº¦"></a>è¯­ä¹‰ç›¸ä¼¼åº¦</h3><p><code>Doc.similarity()</code>ã€<code>Span.similarity()</code>å’Œ<code>Token.similarity()</code></p><p>ç›¸ä¼¼åº¦çš„è®¡ç®—æ–¹å¼:</p><ul><li>é€šè¿‡è¯å‘é‡è®¡ç®—çš„ï¼Œè¯å‘é‡æ˜¯ä¸€ä¸ªè¯æ±‡çš„å¤šç»´åº¦çš„è¯­ä¹‰è¡¨ç¤º</li><li>è¯å‘é‡æ˜¯ç”¨è¯¸å¦‚Word2Vecç®—æ³•åœ¨å¤§è§„æ¨¡è¯­æ–™ä¸Šé¢ç”Ÿæˆçš„</li><li>spaCyé»˜è®¤è¿”å›ä¸¤ä¸ªå‘é‡çš„ä½™å¼¦ç›¸ä¼¼åº¦</li><li>Docå’ŒSpançš„å‘é‡é»˜è®¤æ˜¯ç”±å…¶tokençš„å¹³å‡å€¼å¾—åˆ°çš„</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#æŸ¥çœ‹è¯å‘é‡</span><br>doc = nlp(<span class="hljs-string">&quot;I have a banana&quot;</span>)<br><span class="hljs-comment"># é€šè¿‡token.vectorå±æ€§è·å–å‘é‡</span><br>print(doc[<span class="hljs-number">3</span>].vector)<br><br><span class="hljs-comment">## æ–‡æ¡£å’Œæ–‡æ¡£ç›¸ä¼¼åº¦</span><br>doc1 = nlp(<span class="hljs-string">&quot;I like fast food&quot;</span>)<br>doc2 = nlp(<span class="hljs-string">&quot;I like pizza&quot;</span>)<br>print(doc1.similarity(doc2))<br><br><span class="hljs-comment">## tokenå’Œtokenç›¸ä¼¼åº¦</span><br>doc = nlp(<span class="hljs-string">&quot;I like pizza and pasta&quot;</span>)<br>token1 = doc[<span class="hljs-number">2</span>]<br>token2 = doc[<span class="hljs-number">4</span>]<br>print(token1.similarity(token2))<br><br><span class="hljs-comment">## æ–‡æ¡£å’Œtokenç›¸ä¼¼åº¦</span><br>doc = nlp(<span class="hljs-string">&quot;I like pizza&quot;</span>)<br>token = nlp(<span class="hljs-string">&quot;soap&quot;</span>)[<span class="hljs-number">0</span>]<br>print(doc.similarity(token))<br><br><span class="hljs-comment">## æ–‡æ¡£å’Œspanç›¸ä¼¼åº¦</span><br>span = nlp(<span class="hljs-string">&quot;I like pizza and pasta&quot;</span>)[<span class="hljs-number">2</span>:<span class="hljs-number">5</span>] <span class="hljs-comment"># span.text = pizza and pasta</span><br>doc = nlp(<span class="hljs-string">&quot;McDonalds sells burgers&quot;</span>)<br>print(span.similarity(doc))<br></code></pre></td></tr></table></figure><h3 id="æ¨¡å‹-è§„åˆ™"><a href="#æ¨¡å‹-è§„åˆ™" class="headerlink" title="æ¨¡å‹ + è§„åˆ™"></a>æ¨¡å‹ + è§„åˆ™</h3><blockquote><p>å°†ç»Ÿè®¡æ¨¡å‹ä¸è§„åˆ™ç³»ç»Ÿç»“åˆä½¿ç”¨ï¼Œæ˜¯è‡ªç„¶è¯­è¨€å¤„ç†å·¥å…·ç®±é‡Œé¢æœ€å¼ºå¤§çš„æ–¹æ³•ä¹‹ä¸€</p></blockquote><p>æ¨¡å‹: æ ¹æ®è®­ç»ƒè¯­æ–™åº“å¾—åˆ°ä¸€ç³»åˆ—è§„åˆ™çš„é›†åˆ,spaCyåŠŸèƒ½ä¸€èˆ¬åŒ…æ‹¬:å®ä½“è¯†åˆ«å™¨ã€ä¾å­˜å¥æ³•è¯†åˆ«å™¨ã€è¯æ€§æ ‡æ³¨å™¨<br>è§„åˆ™: äººä¸ºåˆ¶å®šçš„æ¨¡å¼åŒ¹é…ï¼Œé€‚ç”¨äºä¾‹å­è¾ƒå°‘çš„æƒ…å†µ, spaCyåŠŸèƒ½ä¸€èˆ¬åŒ…æ‹¬:åˆ†è¯å™¨, Matcher, PhraseMatcher</p><p>PhraseMatcher:ä¼ è¿›ä¸€ä¸ªDocå®ä¾‹è€Œä¸æ˜¯å­—å…¸åˆ—è¡¨ä½œä¸ºæ¨¡æ¿</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> spacy.matcher <span class="hljs-keyword">import</span> PhraseMatcher<br><br>matcher = PhraseMatcher(nlp.vocab)<br><br>pattern = nlp(<span class="hljs-string">&quot;Golden Retriever&quot;</span>)  <span class="hljs-comment"># å’ŒMatcherä¸åŒçš„åœ°æ–¹</span><br>matcher.add(<span class="hljs-string">&quot;DOG&quot;</span>, <span class="hljs-literal">None</span>, pattern)<br>doc = nlp(<span class="hljs-string">&quot;I have a Golden Retriever&quot;</span>)<br><br><span class="hljs-comment"># éå†åŒ¹é…ç»“æœ</span><br><span class="hljs-keyword">for</span> match_id, start, end <span class="hljs-keyword">in</span> matcher(doc):<br>    <span class="hljs-comment"># è·å–åŒ¹é…åˆ°çš„span</span><br>    span = doc[start:end]<br>    print(<span class="hljs-string">&quot;Matched span:&quot;</span>, span.text)<br><br><span class="hljs-comment"># å¤šä¸ªpatternå¦‚ä½•è¿›è¡Œadd</span><br><span class="hljs-comment"># ä¸‹é¢çš„ä»£ç æ¯”è¿™æ ·çš„è¡¨è¾¾æ–¹å¼æ›´å¿«ï¼š [nlp(country) for country in COUNTRIES]</span><br>patterns = list(nlp.pipe(COUNTRIES))<br>matcher.add(<span class="hljs-string">&quot;COUNTRY&quot;</span>, <span class="hljs-literal">None</span>, *patterns)<br><br><span class="hljs-comment">### ä¾‹å­ï¼š æ‰¾ç¬¦åˆpatternçš„ä¸€ä¸ªspan å¹¶ä¸”è·å–è¿™ä¸ªspanä¸­çš„rootï¼Œéšåæ‰¾åˆ°è¿™ä¸ªrootçš„head</span><br>span_root = span.root<br>span_root_head = span.root.head<br><span class="hljs-comment"># æ‰“å°è¿™ä¸ªspançš„æ ¹å¤´è¯ç¬¦çš„æ–‡æœ¬åŠspançš„æ–‡æœ¬</span><br>print(span_root_head.text, <span class="hljs-string">&quot;--&gt;&quot;</span>, span.text)<br></code></pre></td></tr></table></figure><h2 id="å¤„ç†æµç¨‹"><a href="#å¤„ç†æµç¨‹" class="headerlink" title="å¤„ç†æµç¨‹"></a>å¤„ç†æµç¨‹</h2><p><img src="/image/nlp_process.png"></p><p>è¯æ€§æ ‡æ³¨: token.tag, token.pos<br>ä¾å­˜å…³ç³»: token.dep, token.head<br>å‘½åå®ä½“: å°†æ£€æµ‹åˆ°çš„å®ä½“æ·»åŠ åˆ°doc.ents<br>æ–‡æœ¬åˆ†ç±»å™¨: é€‚ç”¨äºæ•´ä¸ªæ–‡æœ¬çš„ç±»åˆ«ï¼Œå°†å…¶åŠ å…¥doc.cats</p><p>æ‰€æœ‰é¢„è®­ç»ƒçš„æ¨¡å‹éƒ½åŒ…å«äº†ä¸€äº›æ–‡ä»¶å’Œä¸€ä¸ªmeta.jsonã€‚è¿™ä¸ªå…ƒæ•°æ®å®šä¹‰äº†è¯­ç§å’Œæµç¨‹ç­‰ç­‰ï¼Œå‘Šè¯‰spaCyåº”è¯¥å»åˆå§‹åŒ–é‚£äº›ç»„ä»¶ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python">print(nlp.pipe_names)  <span class="hljs-comment"># æµç¨‹ç»„ä»¶åçš„åˆ—è¡¨</span><br>print(nlp.pipeline)    <span class="hljs-comment"># (name, component)å…ƒç»„çš„åˆ—è¡¨</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">[(&#x27;tagger&#x27;, &lt;spacy.pipeline.Tagger&gt;),</span><br><span class="hljs-string"> (&#x27;parser&#x27;, &lt;spacy.pipeline.DependencyParser&gt;),</span><br><span class="hljs-string"> (&#x27;ner&#x27;, &lt;spacy.pipeline.EntityRecognizer&gt;)]</span><br><span class="hljs-string">&#x27;&#x27;&#x27;</span><br></code></pre></td></tr></table></figure><h2 id="å®šåˆ¶åŒ–æµç¨‹ç»„ä»¶"><a href="#å®šåˆ¶åŒ–æµç¨‹ç»„ä»¶" class="headerlink" title="å®šåˆ¶åŒ–æµç¨‹ç»„ä»¶"></a>å®šåˆ¶åŒ–æµç¨‹ç»„ä»¶</h2><p>å½“ä¸€ä¸ªæ–‡æœ¬å·²ç»è¢«åˆ†è¯ä¸”Docå®ä¾‹è¢«åˆ›å»ºåï¼Œæµç¨‹ç»„ä»¶ä¼šä¾æ¬¡è¢«è°ƒç”¨ã€‚ spaCyæ”¯æŒä¸€ç³»åˆ—çš„åŸç”Ÿç»„ä»¶ï¼Œä½†æ˜¯ä¹Ÿå¯ä»¥åœ¨å…¶ä¸­åŠ å…¥è‡ªå·±è®¾è®¡çš„ç»„ä»¶ï¼Œé€šè¿‡è‡ªå·±å®šåˆ¶å¯ä»¥ç»™docå’Œtokenæ·»åŠ ä¸€äº›å±æ€§ã€‚</p><blockquote><p>ä¸€ä¸ªæµç¨‹ç»„ä»¶å°±æ˜¯ä¸€ä¸ªå‡½æ•°æˆ–è€…callableï¼Œå®ƒè¯»å–ä¸€ä¸ªdocï¼Œä¿®æ”¹å’Œè¿”å›è¿™ä¸ªdocï¼Œä½œä¸ºä¸‹ä¸€ä¸ªæµç¨‹ç»„ä»¶çš„è¾“å…¥ã€‚</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">custom_component</span>(<span class="hljs-params">doc</span>):</span><br>    <span class="hljs-comment"># å¯¹docåšä¸€äº›å¤„ç†</span><br>    <span class="hljs-keyword">return</span> doc<br><br>nlp.add_pipe(custom_component)<br><br>nlp.add_pipe(component, last=<span class="hljs-literal">True</span>) <span class="hljs-comment"># ç»„ä»¶é¡ºåºæœ€å first=True ç»„ä»¶é¡ºåºæœ€å‰</span><br>nlp.add_pipe(component, before=<span class="hljs-string">&quot;ner&quot;</span>) <span class="hljs-comment"># æŒ‡å®šç»„ä»¶é¡ºåºä¹‹å‰ after=&quot;tagger&quot; æŒ‡å®šç»„ä»¶é¡ºåºä¹‹å</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Leetcode-æ»‘åŠ¨çª—å£</title>
    <link href="/2020/09/09/Algorithm-sliding-window/"/>
    <url>/2020/09/09/Algorithm-sliding-window/</url>
    
    <content type="html"><![CDATA[<h3 id="é¢˜ç›®è¦æ±‚"><a href="#é¢˜ç›®è¦æ±‚" class="headerlink" title="é¢˜ç›®è¦æ±‚"></a>é¢˜ç›®è¦æ±‚</h3><p><u>è¿ç»­</u>å­æ•°ç»„</p><h3 id="è§£é¢˜æ€è·¯"><a href="#è§£é¢˜æ€è·¯" class="headerlink" title="è§£é¢˜æ€è·¯"></a>è§£é¢˜æ€è·¯</h3><ul><li>æ ¹æ®è¦æ±‚ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªæ»¡è¶³æ¡ä»¶çš„çª—å£</li><li>è°ƒæ•´çª—å£(å³ç§»/å·¦ç§»)ä½¿å…¶ç»§ç»­æ»¡è¶³è¦æ±‚ï¼Œå¹¶è¿›è¡Œé‡å¤</li><li>å¾—åˆ°æœ€åˆé€‚çš„çª—å£å³ä¸ºç­”æ¡ˆ</li></ul><h3 id="Leetcodeä¾‹é¢˜"><a href="#Leetcodeä¾‹é¢˜" class="headerlink" title="Leetcodeä¾‹é¢˜"></a>Leetcodeä¾‹é¢˜</h3><h5 id="æ— é‡å¤å­—ç¬¦çš„æœ€é•¿å­ä¸²"><a href="#æ— é‡å¤å­—ç¬¦çš„æœ€é•¿å­ä¸²" class="headerlink" title="æ— é‡å¤å­—ç¬¦çš„æœ€é•¿å­ä¸²"></a><a href="https://leetcode-cn.com/problems/longest-substring-without-repeating-characters/">æ— é‡å¤å­—ç¬¦çš„æœ€é•¿å­ä¸²</a></h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">lengthOfLongestSubstring</span>(<span class="hljs-params">s</span>):</span><br>    <span class="hljs-keyword">if</span> len(s) == <span class="hljs-number">0</span>: <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>    window_start,res = <span class="hljs-number">0</span>,<span class="hljs-number">0</span><br>    dic = &#123;&#125;<br>    <span class="hljs-keyword">for</span> window_end <span class="hljs-keyword">in</span> range(len(s)):<br>        char = s[window_end]<br>        <span class="hljs-keyword">if</span> char <span class="hljs-keyword">in</span> dic <span class="hljs-keyword">and</span> dic[char]&gt;=window_start: <span class="hljs-comment"># æ³¨æ„è¿™é‡Œçš„ç¬¬äºŒä¸ªæ¡ä»¶dic[char]&gt;=window_startï¼ï¼ èµ·åˆ°ä¸€ä¸ªè¦†ç›–çš„ä½œç”¨</span><br>            window_start = dic[char] +<span class="hljs-number">1</span><br>        dic[char] = window_end<br>        width = window_end-window_start+<span class="hljs-number">1</span><br>        res = max(width,res)<br>    <span class="hljs-keyword">return</span> res  <br></code></pre></td></tr></table></figure><h5 id="å¤§å°ä¸º-K-ä¸”å¹³å‡å€¼å¤§äºç­‰äºé˜ˆå€¼çš„å­æ•°ç»„æ•°ç›®"><a href="#å¤§å°ä¸º-K-ä¸”å¹³å‡å€¼å¤§äºç­‰äºé˜ˆå€¼çš„å­æ•°ç»„æ•°ç›®" class="headerlink" title="å¤§å°ä¸º K ä¸”å¹³å‡å€¼å¤§äºç­‰äºé˜ˆå€¼çš„å­æ•°ç»„æ•°ç›®"></a><a href="https://leetcode-cn.com/problems/number-of-sub-arrays-of-size-k-and-average-greater-than-or-equal-to-threshold/">å¤§å°ä¸º K ä¸”å¹³å‡å€¼å¤§äºç­‰äºé˜ˆå€¼çš„å­æ•°ç»„æ•°ç›®</a></h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">numOfSubarrays</span>(<span class="hljs-params">arr,k,threshold</span>):</span><br>    <span class="hljs-keyword">if</span> arr == [] <span class="hljs-keyword">or</span> len(arr)&lt;k:<span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>    window_sum,window_start,res = <span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span><br>    temp = threshold*k<br>    <span class="hljs-keyword">for</span> window_end <span class="hljs-keyword">in</span> range(len(arr)):<br>        window_sum+=arr[window_end]<br>        <span class="hljs-keyword">if</span> window_end&gt;=k<span class="hljs-number">-1</span>:<br>            <span class="hljs-keyword">if</span> window_sum &gt;=temp:<br>                res+=<span class="hljs-number">1</span><br>            window_sum-=arr[window_start]<br>            window_start+=<span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> res<br></code></pre></td></tr></table></figure><h5 id="æ›¿æ¢åçš„æœ€é•¿é‡å¤å­—ç¬¦"><a href="#æ›¿æ¢åçš„æœ€é•¿é‡å¤å­—ç¬¦" class="headerlink" title="æ›¿æ¢åçš„æœ€é•¿é‡å¤å­—ç¬¦"></a><a href="https://leetcode-cn.com/problems/longest-repeating-character-replacement/">æ›¿æ¢åçš„æœ€é•¿é‡å¤å­—ç¬¦</a></h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><br></code></pre></td></tr></table></figure><h5 id="æœ€å°è¦†ç›–å­ä¸²"><a href="#æœ€å°è¦†ç›–å­ä¸²" class="headerlink" title="æœ€å°è¦†ç›–å­ä¸²"></a><a href="https://leetcode-cn.com/problems/minimum-window-substring/">æœ€å°è¦†ç›–å­ä¸²</a></h5><h5 id="æ»‘åŠ¨çª—å£ä¸­ä½æ•°"><a href="#æ»‘åŠ¨çª—å£ä¸­ä½æ•°" class="headerlink" title="æ»‘åŠ¨çª—å£ä¸­ä½æ•°"></a><a href="https://leetcode-cn.com/problems/sliding-window-median/">æ»‘åŠ¨çª—å£ä¸­ä½æ•°</a></h5><h5 id="æ»‘åŠ¨çª—å£æœ€å¤§å€¼"><a href="#æ»‘åŠ¨çª—å£æœ€å¤§å€¼" class="headerlink" title="æ»‘åŠ¨çª—å£æœ€å¤§å€¼"></a><a href="https://leetcode-cn.com/problems/sliding-window-maximum/">æ»‘åŠ¨çª—å£æœ€å¤§å€¼</a></h5>]]></content>
    
    
    <categories>
      
      <category>Algorithm</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Leetcode</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CSCI570-outline</title>
    <link href="/2020/09/08/CSCI570-outline/"/>
    <url>/2020/09/08/CSCI570-outline/</url>
    
    <content type="html"><![CDATA[<p>hello world!</p>]]></content>
    
    
    
    <tags>
      
      <tag>Course</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Storage systems</title>
    <link href="/2020/09/08/Storage-systems/"/>
    <url>/2020/09/08/Storage-systems/</url>
    
    <content type="html"><![CDATA[<h2 id="Storage-Device"><a href="#Storage-Device" class="headerlink" title="Storage Device"></a>Storage Device</h2><h3 id="Hierarchy"><a href="#Hierarchy" class="headerlink" title="Hierarchy"></a>Hierarchy</h3><p><img src="/image/storage_hierarchy.png"></p><h3 id="Characters"><a href="#Characters" class="headerlink" title="Characters"></a>Characters</h3><ul><li>Capacity(bytes) - How much data it can hold</li><li>Cost($) -  Price per byte of storage</li><li>Bandwidth(bytes/sec) - Number of bytes that can be transferred per second;  read and write bandwidth may be different</li><li>Latency(sec) - Time elapsed, waiting for response/delivery of data</li></ul><h3 id="Basic-Function-CRUD"><a href="#Basic-Function-CRUD" class="headerlink" title="Basic Function : CRUD"></a>Basic Function : CRUD</h3><ul><li>C(reate)/write</li><li>R(ead)</li><li>U(pdate)/overwrite</li><li>D(elete)</li></ul><h3 id="Some-terms"><a href="#Some-terms" class="headerlink" title="Some terms"></a>Some terms</h3><ul><li>Access times: Time taken before drive is ready to transfer data ä¸€èˆ¬æ¥è¯´ï¼Œç‰©ç†è®¾å¤‡ï¼ˆç¡¬ç›˜ï¼Œå†…å­˜..ï¼‰åœ¨è¿›è¡Œæ•°æ®çš„è½¬æ¢å‰éœ€è¦ç´¢å¼•åˆ°ç›®æ ‡ä½ç½®ï¼Œ å†…å­˜-çº³ç§’ SSD-å¾®ç§’ HDD-æ¯«ç§’</li><li>Access pattern: how storage read/write data <ul><li>Sequential: Data to be accessed are located next to each other or sequentially on the device</li><li>Random: Access data located randomly on storage device</li></ul></li><li>Completion Timeï¼šTime to complete an read/write operation <ul><li><strong>CompletionTime = Latency + Size/Bandwidth</strong></li><li>Depends on lots of factors(device, operation type, access patternâ€¦)</li></ul></li></ul><p>Note: è¿™é‡Œä¸»è¦è®¨è®ºHDDå’ŒSSD</p><h2 id="Hard-Disk-Drive"><a href="#Hard-Disk-Drive" class="headerlink" title="Hard Disk Drive"></a>Hard Disk Drive</h2><h3 id="Organization"><a href="#Organization" class="headerlink" title="Organization"></a>Organization</h3><p><img src="/image/hdd.png"></p><ul><li>One or more spinning magnetic platters, typically two surface per platter</li><li>Data stored in tracks</li><li>Disk arm positions over the radial positon - swings across tracks but donâ€™t extend</li><li>Data is read/written by disk head as platter spins</li></ul><p>Hard disk head movement while copying files between two foldersï¼š<br><a href="https://www.youtube.com/watch?v=BlB49F6ExkQ">https://www.youtube.com/watch?v=BlB49F6ExkQ</a></p><h3 id="Physical-characteristics"><a href="#Physical-characteristics" class="headerlink" title="Physical characteristics"></a>Physical characteristics</h3><ul><li>3.5â€ (diameter, common in desktops), 2.5â€ (common in laptops)</li><li>Rotational Speed: 4800/5400/7200/10000 RPM (rotations per minute)</li><li>Between 5-7 platters</li><li>Current capacity up to 10TB</li></ul><h3 id="Data-Storage"><a href="#Data-Storage" class="headerlink" title="Data Storage"></a>Data Storage</h3><ul><li>1 platter  is divided into a number of tracks</li><li>1 tracker is divided into N fixed size sectors<ul><li>sector size: 4KB</li><li>Entire sector is written â€œatomicallyâ€ -&gt; sectorä¸ºæœ€å°çš„æ“ä½œå•å…ƒï¼Œæ‰€ä»¥ä¸è®ºè¯»å†™éƒ½é¦–å…ˆè¿›è¡Œsectorçš„å¯»å€</li></ul></li></ul><h3 id="Address-Method-CHS-cylinder-head-sector"><a href="#Address-Method-CHS-cylinder-head-sector" class="headerlink" title="Address Method - CHS(cylinder-head-sector)"></a>Address Method - CHS(cylinder-head-sector)</h3><h4 id="overview"><a href="#overview" class="headerlink" title="overview"></a>overview</h4><p>CHS is an early way to address a sector. (LBA(Logical Block Addressing) is  more common now.) </p><p><img src="/image/CHS.png"></p><p>ä¸¾ä¸ªä¾‹å­ï¼š<br>#cylinders: 256<br>#heads: 16 (i.e., 8 platters, 2 heads/platter)<br>#sectors/track: 64<br>sector size = 4KB<br>=&gt; capacity of the drive:  2^8 * 2^6 * 2^2* 2^10 * 2^4 = 2^30 = 1GB</p><h4 id="address-step"><a href="#address-step" class="headerlink" title="address step"></a>address step</h4><p><strong>According to CHS, data can be located before transferring, then data can be transferred</strong></p><ol><li>Wait for the disk haed on right track    - seek time <ol><li>On average seek time is about  1â„3  max seek time</li><li><img src="/image/seek-time.png"></li></ol></li><li>wait for the right sector to rotate under the head. - rotational latency <ol><li>On average: about 1â„2 of time of a full rotation</li><li>example:  Assume 10,000 RPM (rotations per minute) 60000 ms/ 10000 rotations  = 6ms / rotation</li></ol></li></ol><h3 id="Data-Operation"><a href="#Data-Operation" class="headerlink" title="Data Operation"></a>Data Operation</h3><blockquote><p>T = T_seek + T_rotation + T_transfer<br>T_seek : Time to get the disk head on right track<br>T_rotation :Time to wait for the right sector to rotate under the head<br>T_transfer: Time to actually transfer data</p></blockquote><h4 id="T-transfer"><a href="#T-transfer" class="headerlink" title="T_transfer"></a>T_transfer</h4><p>Assume that data will be transferred:  512KB, 128 MB/sec transmission bandwidth<br>Transfer time:  512KB/128MB * 1000ms = 4ms</p><h4 id="Actual-Bandwidth"><a href="#Actual-Bandwidth" class="headerlink" title="Actual Bandwidth"></a>Actual Bandwidth</h4><p>Actual Bandwidth = data / actual time ï¼Œæ‰€ä»¥ä¸€èˆ¬æƒ…å†µä¸‹å®é™…å¸¦å®½ä¼šå°</p><h4 id="æ•°æ®ä¼ è¾“ä¸­çš„blockå’ŒsectoråŒºåˆ†"><a href="#æ•°æ®ä¼ è¾“ä¸­çš„blockå’ŒsectoråŒºåˆ†" class="headerlink" title="æ•°æ®ä¼ è¾“ä¸­çš„blockå’ŒsectoråŒºåˆ†"></a>æ•°æ®ä¼ è¾“ä¸­çš„blockå’ŒsectoråŒºåˆ†</h4><ul><li>Sector is the  basic unit of hard disk dirve</li><li>Block is the basic unit of file system</li><li>Block has 1 or more sectors  ï¼ˆin this course, assuming one block = one sectorï¼‰</li></ul><p>ç¡¬ç›˜æœ¬èº«æ²¡æœ‰blockçš„æ¦‚å¿µï¼Œblockæ¦‚å¿µå­˜åœ¨äºæ–‡ä»¶ç³»ç»Ÿçš„æ¦‚å¿µä¸­ï¼Œæ–‡ä»¶ç³»ç»Ÿæ˜¯ä¸€ä¸ªå—ä¸€ä¸ªå—çš„è¯»å–æ•°æ®ï¼Œå¦‚æœæ˜¯æŒ‰ç…§ä¸€ä¸ªsectorä¸€ä¸ªsectorçš„æ¥è¯»æ•°æ®ï¼Œå¤ªæ…¢äº†ï¼Œæ‰€ä»¥æ‰æœ‰äº†blockè¿™æ ·ä¸€ä¸ªé€»è¾‘å—çš„æ¦‚å¿µã€‚</p><h4 id="ä¸åŒaccess-patternå¯¹è¯»å†™çš„å½±å“"><a href="#ä¸åŒaccess-patternå¯¹è¯»å†™çš„å½±å“" class="headerlink" title="ä¸åŒaccess patternå¯¹è¯»å†™çš„å½±å“"></a>ä¸åŒaccess patternå¯¹è¯»å†™çš„å½±å“</h4><ul><li>Sequential operation:<ul><li>May assume all sectors involved are on the same track<br>â€“ need to seek to the right track or rotate to the first sector ï¼ˆä¸€æ¬¡seektimeï¼‰<br>â€“ But no rotation/seeking needed afterwardSSD</li></ul></li><li>Random operation:  <ul><li>May assume all sectors are on different tracks and sectors ï¼ˆå¤šæ¬¡seektimeï¼‰</li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">example: 7ms avg seek,  10,000 RPM  50 MB/sec transfer rate 4KB/block<br>Sequential access of 10 MB:<br>â€“ Completion time = 7ms + 60*1000/10000/2 ms + 10/50 *1000 ms = 210ms<br>â€“ Actual bandwidth = 10MB/210ms = 47.62 MB/s<br><br>Random access of 10 MB <br>â€“ block numbers: 10*1000/4 = 2500  (assume 1 block = 1 sector)<br>â€“ Completion time = 2500 * (7 + 3 + 4/50) = 25.2s<br>â€“ Actual bandwidth = 10MB / 25.2s = 0.397 MB/s<br></code></pre></td></tr></table></figure><h2 id="Soild-State-Drive"><a href="#Soild-State-Drive" class="headerlink" title="Soild State Drive"></a>Soild State Drive</h2><h3 id="Organization-1"><a href="#Organization-1" class="headerlink" title="Organization"></a>Organization</h3><p><img src="/image/ssd.png"></p><p>SSD contains a number of flash memory chips</p><p><img src="/image/chip.png"></p><p>chip -&gt; dies -&gt; planes -&gt; blocks -&gt; pages (rows) -&gt; cells</p><h3 id="Characteristics"><a href="#Characteristics" class="headerlink" title="Characteristics"></a>Characteristics</h3><ul><li>All electronic, made from flash memory</li><li>Limited lifetime, can only write a limited number of times.</li><li>More expensive, less capacity  - 3 times or more expensive</li><li>Significantly better latency: no seek or rotational delay</li><li>Much better performance on random (however, write has much higher latency than read )</li></ul><h3 id="Data-Storage-1"><a href="#Data-Storage-1" class="headerlink" title="Data Storage"></a>Data Storage</h3><ul><li>Cells are made of floating-gate transistors : By applying high positive/negative voltage to control gate, electrons can be attracted to or repelled from floating gate<ul><li>State = 1, if no electrons in the floating gate</li><li>State = 0, if there are electrons (negative charges)<br>â€“ Electrons stuck there even when power is off<br>â€“ So state is retained</li></ul></li><li>Data in SSD are represented by the â€˜01010â€¦â€™ formats, that is the state of the electrons</li></ul><p><img src="/image/floating-gate.png"></p><h3 id="Operations"><a href="#Operations" class="headerlink" title="Operations"></a>Operations</h3><h4 id="Read"><a href="#Read" class="headerlink" title="Read"></a>Read</h4><ul><li>Electrons on the floating gate affect the threshold voltage for the floating gate transistor to conduct</li><li>Higher voltage needed when gate has electrons</li></ul><p><img src="/image/ssd_read.png"></p><p>Steps: </p><ol><li>Apply Vint (intermediate voltage) </li><li>If the current is detected, gate has no electrons=&gt; bit = 1</li><li>If no current, gate must have electrons =&gt; bit = 0</li></ol><p><u><strong>Page is the smallest unit that can be read</strong></u></p><h4 id="Write-and-Erase"><a href="#Write-and-Erase" class="headerlink" title="Write and Erase"></a>Write and Erase</h4><h4 id="Write-and-erase"><a href="#Write-and-erase" class="headerlink" title="Write and erase"></a>Write and erase</h4><ul><li>Write: 1 =&gt; 0 (get electron)<ul><li>Apply high positive voltage (&gt;&gt; voltage for read) to the control gate</li><li>Attract electrons from channel to floating gate (through quantum tunneling)</li><li>Page is the smallest unit for write</li></ul></li><li>Erase: 0 =&gt; 1 (make electrons empty)<ul><li>Need to apply much higher negative voltage to the control gate</li><li>Get rid of electrons from floating gate</li><li>May stress surrounding cells(dangerous to do on individual pages)</li><li>Block is the smallest unit for erase</li></ul></li></ul><h3 id="P-E-cycle"><a href="#P-E-cycle" class="headerlink" title="P/E cycle"></a>P/E cycle</h3><blockquote><p>P/E cycle: Data is written to cells (P) and then erased (E)<br>Every write &amp; erase damages oxide layer surrounding the floating-gate to some extent</p></blockquote><ul><li>Page is the smallest unit for read and write (write is also called program, 1-&gt;0)</li><li>Block is the smallest unit for erase (0-&gt;1) â€“ i.e., make cells â€œemptyâ€ (i.e., no electrons)  (å…³äºä¸ºä»€ä¹ˆä½¿ç”¨blockä½œä¸ºæœ€å°æ“¦é™¤å•å…ƒï¼šSSDçš„ç‰©ç†ç»“æ„å¯¼è‡´ï¼Œæ“¦é™¤è¿‡ç¨‹ä¼šä½œç”¨åˆ°æ•´ä¸ªblockæ–½åŠ é«˜ç”µå‹ï¼Œå°†ç”µå­å¸å¼•å‡ºæ¥)</li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>Operating System</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>JSON-review</title>
    <link href="/2020/09/07/JSON-review/"/>
    <url>/2020/09/07/JSON-review/</url>
    
    <content type="html"><![CDATA[<h2 id="JSONæ¦‚è¿°"><a href="#JSONæ¦‚è¿°" class="headerlink" title="JSONæ¦‚è¿°"></a>JSONæ¦‚è¿°</h2><p><strong>JSON</strong>ï¼ˆ<strong>J</strong>ava<strong>S</strong>cript <strong>O</strong>bject <strong>N</strong>otation)ï¼Œç”±é“æ ¼æ‹‰æ–¯Â·å…‹ç½—å…‹ç¦ç‰¹æ„æƒ³å’Œè®¾è®¡ã€è½»é‡çº§çš„æ•°æ®äº¤æ¢è¯­è¨€,è¯¥è¯­è¨€ä»¥æ˜“äºè®©äººé˜…è¯»çš„æ–‡å­—ä¸ºåŸºç¡€ï¼Œç”¨æ¥<strong>ä¼ è¾“ç”±å±æ€§å€¼æˆ–è€…åºåˆ—æ€§çš„å€¼ç»„æˆçš„æ•°æ®å¯¹è±¡</strong>ã€‚å°½ç®¡JSONæ˜¯JavaScriptçš„ä¸€ä¸ªå­é›†ï¼Œä½†JSONæ˜¯ç‹¬ç«‹äºè¯­è¨€çš„æ–‡æœ¬æ ¼å¼ã€‚</p><ul><li>Light-weight data exchange format<br>Much simpler than XML; Language-independent; Inspired by the syntax of JavaScript object literals</li><li>Some differences from JavaScript objects<br><strong>String in JSON must be double-quoted</strong>; Okay to single-quote in JavaScript (&amp; Python)</li><li>JSON is case-sensitive</li></ul><p>ä¸€å¥è¯è¡¨è¾¾å°±æ˜¯ï¼ŒJSONæ˜¯ä¸€ç§æ ¼å¼ï¼ŒåŸºäºæ–‡æœ¬ï¼Œä¼˜äºè½»é‡ï¼Œç”¨äºäº¤æ¢æ•°æ®ï¼Œç”±äºå…¶ç”¨æ–‡æœ¬æ ¼å¼çš„ä¿å­˜æ–¹å¼ï¼Œæ‰€ä»¥ä¸€èˆ¬ä¹Ÿå«JSONå­—ç¬¦ä¸²ã€‚</p><h2 id="è¯­æ³•"><a href="#è¯­æ³•" class="headerlink" title="è¯­æ³•"></a>è¯­æ³•</h2><ul><li>value = string | number | object | array | true | false | null</li><li>object = {} | { members }<ul><li>members = pair | pair, members </li><li>pair = string : value</li></ul></li><li>array = [] | [ elements ]<ul><li>elements = value | value, elements</li></ul></li></ul><p>ä¸€èˆ¬æƒ…å†µä¸‹ï¼ŒJSONå¤§å¤šä¸ºä¸€ä¸ªarrayï¼Œarrayé‡Œçš„æ¯ä¸€ä¸ªå…ƒç´ ä¸ºä¸€ä¸ªobjectï¼Œobjectå¯ä»¥ç†è§£ä¸ºå­—å…¸<br>JSON åœ¨çº¿æ£€æŸ¥å™¨:   <a href="https://www.json.cn/">https://www.json.cn/</a></p><h2 id="Pythonä¸­ä½¿ç”¨JSON"><a href="#Pythonä¸­ä½¿ç”¨JSON" class="headerlink" title="Pythonä¸­ä½¿ç”¨JSON"></a>Pythonä¸­ä½¿ç”¨JSON</h2><h3 id="encode-decode"><a href="#encode-decode" class="headerlink" title="encode/decode"></a>encode/decode</h3><p>JSONæ“ä½œä¸»è¦åˆ†ä¸ºä¸¤ä¸ªï¼š</p><ol><li>encodeï¼Œå°†Pythonå¯¹è±¡è½¬åŒ–ä¸ºJSONæ–‡æœ¬ï¼Œä¸»è¦å‡½æ•° dump( ) dumps( )</li><li>decodeï¼Œå°†JSONæ–‡æœ¬è½¬åŒ–ä¸ºPythonå¯¹è±¡ï¼Œä¸»è¦å‡½æ•° load( ) loads( )</li></ol><h3 id="è½¬åŒ–è§„åˆ™"><a href="#è½¬åŒ–è§„åˆ™" class="headerlink" title="è½¬åŒ–è§„åˆ™"></a>è½¬åŒ–è§„åˆ™</h3><table><thead><tr><th align="center">Python</th><th align="center">JSON</th></tr></thead><tbody><tr><td align="center">list/tuple</td><td align="center">array</td></tr><tr><td align="center">dict</td><td align="center">object</td></tr><tr><td align="center">None</td><td align="center">null</td></tr><tr><td align="center">True</td><td align="center">true</td></tr><tr><td align="center">False</td><td align="center">false</td></tr><tr><td align="center">â€˜abcâ€™</td><td align="center">â€œabcâ€</td></tr></tbody></table><p>å…³äºPythonå­—å…¸è½¬JSONæ–‡æœ¬çš„è¯´æ˜ï¼š</p><ul><li>Keys in Python can be number, string, or tuple. </li><li>Number is also converted to string.</li><li>But tuple (with two or more components) is not acceptable by dumps()/dump()</li></ul><h3 id="ä»£ç "><a href="#ä»£ç " class="headerlink" title="ä»£ç "></a>ä»£ç </h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> json <span class="hljs-comment"># jsonåº“ä¸ºPythonè‡ªå¸¦çš„æ ‡å‡†åº“</span><br><br><span class="hljs-comment"># JSON encoder Python object =&gt; JSON document   </span><br>json.dumps([<span class="hljs-number">3</span>, <span class="hljs-string">&#x27;abc&#x27;</span>, <span class="hljs-literal">True</span>, <span class="hljs-literal">None</span>])  <span class="hljs-comment"># &#x27;[3, &quot;abc&quot;, true, null]&#x27;</span><br><br><span class="hljs-comment"># Python object =&gt; JSON file</span><br>data = &#123;<span class="hljs-string">&#x27;name&#x27;</span>:<span class="hljs-string">&#x27;Sam&#x27;</span>,<span class="hljs-string">&#x27;age&#x27;</span>:<span class="hljs-number">23</span>&#125;<br><span class="hljs-keyword">with</span> open(<span class="hljs-string">&#x27;user_info.json&#x27;</span>,<span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> out_file:<br>    json.dump(data,out_file)<br><br><span class="hljs-comment">## JSON decoder </span><br>json.loads(<span class="hljs-string">&#x27;[&quot;foo&quot;, &#123;&quot;bar&quot;:[&quot;baz&quot;, null, 1.0, 2]&#125;]&#x27;</span>) <span class="hljs-comment"># [&#x27;foo&#x27;, &#123;&#x27;bar&#x27;: [&#x27;baz&#x27;, None, 1.0, 2]&#125;]</span><br><br><span class="hljs-comment"># JSON file =&gt; Python object</span><br><span class="hljs-keyword">with</span> open(<span class="hljs-string">&#x27;user_info.json&#x27;</span>,<span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> in_file:<br>    data = json.load(in_file)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Python</tag>
      
      <tag>File Format</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Firebase rest &amp; web api</title>
    <link href="/2020/09/06/Firebase-rest-web-api/"/>
    <url>/2020/09/06/Firebase-rest-web-api/</url>
    
    <content type="html"><![CDATA[<h2 id="Firebase-æ¦‚è¿°ï¼ˆBaaSï¼‰"><a href="#Firebase-æ¦‚è¿°ï¼ˆBaaSï¼‰" class="headerlink" title="Firebase æ¦‚è¿°ï¼ˆBaaSï¼‰"></a>Firebase æ¦‚è¿°ï¼ˆBaaSï¼‰</h2><p>Firebaseè°·æ­Œçš„ä¸€æ¬¾åº”ç”¨åå°æœåŠ¡ã€‚å€ŸåŠ©Firebaseï¼Œåº”ç”¨å¼€å‘è€…ä»¬å¯ä»¥å¿«é€Ÿæ­å»ºåº”ç”¨åå°ã€‚</p><h3 id="äº§å“"><a href="#äº§å“" class="headerlink" title="äº§å“"></a>äº§å“</h3><ol><li>Firebase (realtime) database: Manage <strong>JSON</strong> documents + Real-time <strong>syncing</strong> data between users and devices</li><li>Firebase (cloud) storage: Store images, photos, videos</li><li>Firebase (user) authentication: Support sign in using Google, Facebook</li></ol><h3 id="ä½¿ç”¨"><a href="#ä½¿ç”¨" class="headerlink" title="ä½¿ç”¨"></a>ä½¿ç”¨</h3><ol><li>Create a Firebase account: first use Google account,then go to Firebase console: <a href="https://console.firebase.google.com/">https://console.firebase.google.com/</a></li><li>Click on â€œAdd projectâ€  to create a Firebase project</li><li>Add Firebase to your web app</li><li>any other interesting operation â€¦</li></ol><h3 id="å…³äº-Realtime-database"><a href="#å…³äº-Realtime-database" class="headerlink" title="å…³äº Realtime database"></a>å…³äº Realtime database</h3><ul><li>Data in JSON(Javascript Object Notation) format  <a href="/2020/09/07/JSON-review/" title="JSON-review">JSON-review</a> </li><li>When creating a real-time database, we should open up the access to allow us to read and write the data.</li><li>There are some difference between storing style from JSON file and Firebase real-time database<ol><li>JSONæ–‡ä»¶ä¸­çš„arrayå…ƒç´ åœ¨Realtime databaseä¸‹ä»¥objectçš„å½¢å¼å­˜åœ¨ï¼Œobjectå¯¹åº”çš„keyä¸ºæ•°ç»„å…ƒç´ çš„ç´¢å¼•</li><li>JSONæ–‡ä»¶å¯ä»¥ä¿å­˜valueä¸ºnullçš„é”®å€¼å¯¹ï¼ŒRealtime databaseåˆ™ä¼šå¿½ç•¥è¿™ä¸€å¯¹é”®å€¼å¯¹<br><img src="/image/firebase1.png"></li></ol></li></ul><h2 id="Firebase-REST-API"><a href="#Firebase-REST-API" class="headerlink" title="Firebase REST API"></a>Firebase REST API</h2><h3 id="å…³äºRESTful-API"><a href="#å…³äºRESTful-API" class="headerlink" title="å…³äºRESTful API"></a>å…³äºRESTful API</h3><p> RESTï¼šRepresentation State Transferï¼Œè¡¨ç°å±‚çŠ¶æ€è½¬ç§»<br> ä¸€å¥è¯è§£é‡Šçš„è¯å°±æ˜¯:é€šè¿‡URLå®šä½èµ„æºï¼Œç”¨HTTPåŠ¨è¯ï¼ˆGET, POST, PUT, DELETE)æè¿°æ“ä½œä»è€Œç”¨æ¥å®ç°å‰åç«¯æ•°æ®ä¼ è¾“çš„åè®®ã€‚</p><h3 id="å‘½ä»¤è¡Œè¿›è¡Œhttpæ•°æ®ä¼ è¾“ï¼šcurl"><a href="#å‘½ä»¤è¡Œè¿›è¡Œhttpæ•°æ®ä¼ è¾“ï¼šcurl" class="headerlink" title="å‘½ä»¤è¡Œè¿›è¡Œhttpæ•°æ®ä¼ è¾“ï¼šcurl"></a>å‘½ä»¤è¡Œè¿›è¡Œhttpæ•°æ®ä¼ è¾“ï¼šcurl</h3><p>  For command operation, itâ€™s convenient to use <strong>curl</strong> (Command line tool for data transfer)<br>  curlè¯¦ç»†ä½¿ç”¨ï¼š<a href="https://itbilu.com/linux/man/4yZ9qH_7X.html">https://itbilu.com/linux/man/4yZ9qH_7X.html</a><br>  æ³¨æ„ï¼Œcurlå¤§å°å†™æ•æ„Ÿï¼Œè¯·æ±‚çš„å‘½ä»¤å‚æ•°å‡ä¸ºå¤§å†™å­—ç¬¦</p><h3 id="curlä¾‹å­-CRUD"><a href="#curlä¾‹å­-CRUD" class="headerlink" title="curlä¾‹å­ - CRUD"></a>curlä¾‹å­ - CRUD</h3><p>  PUT &amp; POST (C), GET (R), PATCH (U) ,DELETE (D)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python">JSON tree:<br>&#123;<br>  <span class="hljs-string">&quot;firstName&quot;</span>: <span class="hljs-string">&quot;John&quot;</span>,<br>  <span class="hljs-string">&quot;lastName&quot;</span>: <span class="hljs-string">&quot;Smith&quot;</span>,<br>  <span class="hljs-string">&quot;isMarried&quot;</span>: false,<br>  <span class="hljs-string">&quot;age&quot;</span>: <span class="hljs-number">25</span>,<br>  <span class="hljs-string">&quot;height_cm&quot;</span>: <span class="hljs-number">167.6</span>,<br>  <span class="hljs-string">&quot;address&quot;</span>: &#123;<br>    <span class="hljs-string">&quot;streetAddress&quot;</span>: <span class="hljs-string">&quot;22nd Street&quot;</span>,<br>    <span class="hljs-string">&quot;city&quot;</span>: <span class="hljs-string">&quot;New York&quot;</span>,<br>    <span class="hljs-string">&quot;state&quot;</span>: <span class="hljs-string">&quot;NY&quot;</span>,<br>    <span class="hljs-string">&quot;postalCode&quot;</span>: <span class="hljs-string">&quot;10021-3100&quot;</span><br>  &#125;,<br>  <span class="hljs-string">&quot;phoneNumbers&quot;</span>: [<br>    &#123;<br>      <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;home&quot;</span>,<br>      <span class="hljs-string">&quot;number&quot;</span>: <span class="hljs-string">&quot;212 555-1234&quot;</span><br>    &#125;,<br>    &#123;<br>      <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;office&quot;</span>,<br>      <span class="hljs-string">&quot;number&quot;</span>: <span class="hljs-string">&quot;646 555-4567&quot;</span>,<br>      <span class="hljs-string">&quot;xyz&quot;</span>: null<br>    &#125;<br>  ],<br>  <span class="hljs-string">&quot;children&quot;</span>: [],<br>  <span class="hljs-string">&quot;spouse&quot;</span>: null,<br>  <span class="hljs-string">&quot;scores&quot;</span>: [<span class="hljs-number">8.5</span>, <span class="hljs-number">9</span>, <span class="hljs-number">7</span>, <span class="hljs-number">10</span>]<br>&#125;<br></code></pre></td></tr></table></figure><h4 id="GET-get-the-specific-resource"><a href="#GET-get-the-specific-resource" class="headerlink" title="GET: get the specific resource"></a>GET: get the specific resource</h4><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs powershell"><span class="hljs-variable">$</span> <span class="hljs-built_in">curl</span> <span class="hljs-literal">-X</span> GET <span class="hljs-string">&#x27;https://rest-apidemo.firebaseio.com/address/city.json&#x27;</span>   <span class="hljs-keyword">return</span>: <span class="hljs-string">&quot;New York&quot;</span>%  <br><span class="hljs-literal">-X</span>   å¯ä»¥çœç•¥ ç›´æ¥ <span class="hljs-built_in">curl</span> GET url; GET  å¯ä»¥çœç•¥ ç›´æ¥ <span class="hljs-built_in">curl</span> url<br><br><span class="hljs-variable">$</span> <span class="hljs-built_in">curl</span> <span class="hljs-string">&#x27;https://rest-apidemo.firebaseio.com/phoneNumbers/0.json&#x27;</span> <span class="hljs-comment">#refer to arr element by index</span><br><span class="hljs-keyword">return</span>:&#123;<span class="hljs-string">&quot;number&quot;</span>:<span class="hljs-string">&quot;212 555-1234&quot;</span>,<span class="hljs-string">&quot;type&quot;</span>:<span class="hljs-string">&quot;home&quot;</span>&#125;%  <br></code></pre></td></tr></table></figure><h4 id="PUT-write-a-given-value-e-g-â€œMaryâ€-to-a-specify-node-e-g-â€œspouseâ€"><a href="#PUT-write-a-given-value-e-g-â€œMaryâ€-to-a-specify-node-e-g-â€œspouseâ€" class="headerlink" title="PUT: write a given value (e.g., â€œMaryâ€) to a specify node (e.g., â€œspouseâ€)"></a>PUT: write a given value (e.g., â€œMaryâ€) to a specify node (e.g., â€œspouseâ€)</h4><figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs crmsh">Add if <span class="hljs-keyword">node</span> <span class="hljs-title">not</span> exists (could add embedded nodes) - æ·»åŠ æ•°æ®<br>Overwrite if <span class="hljs-keyword">node</span> <span class="hljs-title">already</span> has value               - é‡å†™æ•°æ®<br><br>$ curl -X PUT &#x27;https://rest-apidemo.firebaseio.com/spouse.json&#x27; -d &#x27;<span class="hljs-string">&quot;Mary&quot;</span>&#x27;  <span class="hljs-comment"># æ³¨æ„å¼•å·</span><br><br><span class="hljs-comment">#This will add a new node &quot;country&quot; (assuming it does not exist yet) </span><br><span class="hljs-comment">#and a child of this node with key &quot;province&quot; and content: &#123;&quot;name&quot;: &quot;Anhui&quot;&#125;</span><br>$ curl -X PUT &#x27;https://rest-apidemo.firebaseio.com/country/province.json&#x27; -d &#x27;&#123;<span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;Anhui&quot;</span>&#125;&#x27; <br>$ curl -X PUT &#x27;https://rest-apidemo.firebaseio.com/country.json&#x27; -d &#x27;&#123;<span class="hljs-string">&quot;province&quot;</span>: &#123;<span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;Anhui&quot;</span>&#125;&#125;&#x27;<br></code></pre></td></tr></table></figure><h4 id="POST-add-new-value-to-a-given-node"><a href="#POST-add-new-value-to-a-given-node" class="headerlink" title="POST: add new value to a given node"></a>POST: add new value to a given node</h4><figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs maxima">Automatically generates a <span class="hljs-built_in">new</span> <span class="hljs-built_in">key</span> &amp; <span class="hljs-keyword">then</span> stores the value <span class="hljs-keyword">for</span> the <span class="hljs-built_in">new</span> <span class="hljs-built_in">key</span><br>ç”±äºå¯¹äºæ·»åŠ çš„æ•°æ®ï¼Œå…¶è‡ªåŠ¨ç”Ÿæˆä¸€ä¸ª<span class="hljs-built_in">key</span>ï¼Œæ‰€ä»¥ä¿è¯ä¸ä¼šé‡å†™æ•°æ®(In contrast, PUT will simply overwrite the <span class="hljs-built_in">key</span>)<br> <br>$ curl -X POST &#x27;https://<span class="hljs-built_in">rest</span>-apidemo.firebaseio.com/country.json&#x27; -d &#x27;&#123;<span class="hljs-string">&quot;province&quot;</span>: &#123;<span class="hljs-string">&quot;name&quot;</span>: <span class="hljs-string">&quot;Anhui&quot;</span>&#125;&#125;&#x27;<br>$ curl -X POST &#x27;https://<span class="hljs-built_in">rest</span>-apidemo.firebaseio.com/country.json&#x27; -d  &#x27;<span class="hljs-string">&quot;Anhui&quot;</span>&#x27;<br></code></pre></td></tr></table></figure><h4 id="PATCH-upsert-a-value-to-a-given-node"><a href="#PATCH-upsert-a-value-to-a-given-node" class="headerlink" title="PATCH:  upsert a value to a given node"></a>PATCH:  upsert a value to a given node</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs sql">Performs the <span class="hljs-keyword">update</span> <span class="hljs-keyword">if</span> <span class="hljs-keyword">value</span> already <span class="hljs-keyword">exists</span>  -æ›´æ–°èŠ‚ç‚¹<br>Otherwise, it inserts the <span class="hljs-keyword">new</span> <span class="hljs-keyword">value</span>          -æ’å…¥æ–°èŠ‚ç‚¹<br><span class="hljs-keyword">PATCH</span>æœ¬è´¨ä¸Šæ˜¯ä¸€ä¸ªæ·±åº¦æœç´¢ç¬¦åˆèŠ‚ç‚¹çš„æ¡ä»¶è¿›è¡Œæ›´æ–°æˆ–è€…æ·»åŠ )<br><br>curl -X <span class="hljs-keyword">PATCH</span> <span class="hljs-string">&#x27;https://rest-apidemo.firebaseio.com/country.json&#x27;</span> -d <span class="hljs-string">&#x27;&#123;&quot;province&quot;: &#123;&quot;name&quot;: &quot;Hubei&quot;&#125;&#125;&#x27;</span><br><br><br>å¥½å¤„:ç›¸æ¯”äºPUTï¼ˆå¯¹äºå·²ç»å­˜åœ¨çš„èŠ‚ç‚¹è¿›è¡Œå…¨å±€çš„ä¿®æ”¹ï¼‰ï¼Œæœ¬è´¨ä¸Šæ¥è¯´<span class="hljs-keyword">PATCH</span>å®ç°çš„æ˜¯å¯¹è¯¥èŠ‚ç‚¹çš„å±€éƒ¨æ›´æ–°<br>æ³¨æ„:å½“éœ€è¦æ›´æ–°çš„èŠ‚ç‚¹æ²¡æœ‰å­èŠ‚ç‚¹ï¼ˆä»…ä»…æ˜¯ä¸€ä¸ª<span class="hljs-keyword">key</span>-<span class="hljs-keyword">value</span>æ ¼å¼ï¼‰ï¼Œæ— æ³•ä½¿ç”¨<span class="hljs-keyword">PATCH</span>ï¼Œå› ä¸º -d å‚æ•°åéœ€è¦ä¼ å…¥é”®å€¼å¯¹çš„æ ¼å¼<br>curl -X <span class="hljs-keyword">PATCH</span> <span class="hljs-string">&#x27;https://rest-apidemo.firebaseio.com/spouse.json&#x27;</span> -d <span class="hljs-string">&#x27;&quot;Sam&quot;&#x27;</span> <span class="hljs-comment"># fail</span><br>&#123;<br>  <span class="hljs-string">&quot;error&quot;</span> : <span class="hljs-string">&quot;Invalid data; couldn&#x27;t parse JSON object. Are you sending a JSON object with valid key names?&quot;</span><br>&#125;<br>curl -X PUT <span class="hljs-string">&#x27;https://rest-apidemo.firebaseio.com/spouse.json&#x27;</span> -d <span class="hljs-string">&#x27;&quot;Sam&quot;&#x27;</span> <span class="hljs-comment"># success</span><br></code></pre></td></tr></table></figure><h4 id="DELETE-delete-a-node"><a href="#DELETE-delete-a-node" class="headerlink" title="DELETE:  delete a node"></a>DELETE:  delete a node</h4><figure class="highlight sas"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sas">curl -<span class="hljs-meta">X</span> <span class="hljs-meta">DELETE</span> <span class="hljs-string">&#x27;https://rest-apidemo.firebaseio.com/spouse.json&#x27;</span><br></code></pre></td></tr></table></figure><h4 id="ä»æ•°æ®å¢åŠ ã€å‡å°‘ä¸Šå¯¹PUTã€PATCHå’ŒPOSTè¿›è¡Œæ¯”è¾ƒ"><a href="#ä»æ•°æ®å¢åŠ ã€å‡å°‘ä¸Šå¯¹PUTã€PATCHå’ŒPOSTè¿›è¡Œæ¯”è¾ƒ" class="headerlink" title="ä»æ•°æ®å¢åŠ ã€å‡å°‘ä¸Šå¯¹PUTã€PATCHå’ŒPOSTè¿›è¡Œæ¯”è¾ƒ"></a>ä»æ•°æ®å¢åŠ ã€å‡å°‘ä¸Šå¯¹PUTã€PATCHå’ŒPOSTè¿›è¡Œæ¯”è¾ƒ</h4><p>PUTå¯èƒ½é€ æˆæ•°æ®çš„å¢åŠ ï¼ˆæ·»åŠ æ–°èŠ‚ç‚¹ä¸‹çš„valueï¼‰å’Œå‡å°‘ï¼ˆoverwriteæ•´ä¸ªèŠ‚ç‚¹å¯¼è‡´å…¶å†…åµŒçš„èŠ‚ç‚¹è¢«åˆ é™¤ï¼‰ï¼›<br>PATCHå¯èƒ½é€ æˆæ•°æ®çš„å¢åŠ ï¼ˆæ·»åŠ æ–°èŠ‚ç‚¹ä¸‹çš„value)å’Œå‡å°‘ï¼ˆupdateèŠ‚ç‚¹çš„ç”¨æ›´å°‘çš„æ•°æ®å»å–ä»£åŸå…ˆçš„æ•°æ®ï¼‰<br>POSTä¸€å®šä¼šé€ æˆæ•°æ®çš„å¢åŠ ï¼ˆå› ä¸ºä¼šè‡ªåŠ¨åŠ ä¸Škeyï¼‰ï¼›</p><h4 id="data-querying-by-RESful-API"><a href="#data-querying-by-RESful-API" class="headerlink" title="data querying by RESful API"></a>data querying by RESful API</h4><ul><li>orderBy=â€$keyâ€  </li><li>orderBy=â€<path-to-child-key>â€œ</li><li>orderBy=â€$valueâ€  éœ€è¦åœ¨Realtime databaseçš„Ruleså…ˆå£°æ˜</li><li>startAt/endAt</li><li>equalTo</li><li>limitToFirst/limitToLast </li></ul><p>Specified in database rules:<br><a href="https://firebase.google.com/docs/database/security/indexing-data">https://firebase.google.com/docs/database/security/indexing-data</a></p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs rust">curl -X GET <span class="hljs-symbol">&#x27;https</span>:<span class="hljs-comment">//rest-apidemo.firebaseio.com/scores.json?orderBy=&quot;$key&quot;&amp;equalTo=&quot;1&quot;&#x27;</span><br>curl -X GET <span class="hljs-symbol">&#x27;https</span>:<span class="hljs-comment">//rest-apidemo.firebaseio.com/scores.json?orderBy=&quot;$key&quot;&amp;startAt=&quot;1&quot;&#x27;</span><br>curl -X GET <span class="hljs-symbol">&#x27;https</span>:<span class="hljs-comment">//rest-apidemo.firebaseio.com/scores.json?orderBy=&quot;$value&quot;&#x27;</span><br><br>Orders ascendingly:<br>null -&gt; <span class="hljs-literal">false</span> -&gt;<span class="hljs-literal">true</span> -&gt; number -&gt; string -&gt; object<br></code></pre></td></tr></table></figure><h2 id="REST-API-in-Python"><a href="#REST-API-in-Python" class="headerlink" title="REST API in Python"></a>REST API in Python</h2><figure class="highlight haskell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs haskell"><span class="hljs-keyword">import</span> requests<br><br><span class="hljs-title">url</span> = &#x27;xxxx&#x27;<br><span class="hljs-class"><span class="hljs-keyword">data</span> = &#x27;xxx&#x27;</span><br><br><span class="hljs-title">requests</span>.get(url) <br><span class="hljs-title">requests</span>.put(url, <span class="hljs-class"><span class="hljs-keyword">data</span>)</span><br><span class="hljs-title">requests</span>.patch(url, <span class="hljs-class"><span class="hljs-keyword">data</span>)</span><br><span class="hljs-title">requests</span>.delete(url)<br><span class="hljs-title">requests</span>.post(url, <span class="hljs-class"><span class="hljs-keyword">data</span>)</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    
    <tags>
      
      <tag>Commands</tag>
      
      <tag>Tools</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DSCI551 outline</title>
    <link href="/2020/09/06/DSCI551-outline/"/>
    <url>/2020/09/06/DSCI551-outline/</url>
    
    <content type="html"><![CDATA[<h2 id="DSCI551-Foundations-of-Data-Management"><a href="#DSCI551-Foundations-of-Data-Management" class="headerlink" title="DSCI551 - Foundations of Data Management"></a>DSCI551 - Foundations of Data Management</h2><h3 id=""><a href="#" class="headerlink" title=""></a><a href="/2020/09/06/Firebase-rest-web-api/" title="Firebase rest &amp; web api">Firebase rest &amp; web api</a></h3><h3 id="-1"><a href="#-1" class="headerlink" title=""></a><a href="/2020/09/07/JSON-review/" title="JSON-review">JSON-review</a></h3><h3 id="-2"><a href="#-2" class="headerlink" title=""></a><a href="/2020/09/08/Storage-systems/" title="Storage systems">Storage systems</a></h3><h3 id="-3"><a href="#-3" class="headerlink" title=""></a><a href="/2020/09/10/File-Systems/" title="File systems">File systems</a></h3><h3 id="-4"><a href="#-4" class="headerlink" title=""></a><a href="/2020/09/11/NFS/" title="Network File System">Network File System</a></h3><h3 id="-5"><a href="#-5" class="headerlink" title=""></a><a href="/2020/09/18/File-Format/" title="XML">XML</a></h3>]]></content>
    
    
    
    <tags>
      
      <tag>Course</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Leetcode-å‰‘æŒ‡Offer</title>
    <link href="/2020/09/05/Algorithm-jianzhioffer/"/>
    <url>/2020/09/05/Algorithm-jianzhioffer/</url>
    
    <content type="html"><![CDATA[<h4 id="å·¦æ—‹è½¬å­—ç¬¦ä¸²"><a href="#å·¦æ—‹è½¬å­—ç¬¦ä¸²" class="headerlink" title="å·¦æ—‹è½¬å­—ç¬¦ä¸²"></a><a href="https://leetcode-cn.com/problems/zuo-xuan-zhuan-zi-fu-chuan-lcof/">å·¦æ—‹è½¬å­—ç¬¦ä¸²</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reverseLeftWords</span>(<span class="hljs-params">s,n</span>):</span><br>    <span class="hljs-keyword">return</span> s[n:] + s[:n]<br></code></pre></td></tr></table></figure><h4 id="æ±‚1-2-â€¦-n"><a href="#æ±‚1-2-â€¦-n" class="headerlink" title="æ±‚1+2+â€¦+n"></a><a href="https://leetcode-cn.com/problems/qiu-12n-lcof/">æ±‚1+2+â€¦+n</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python">res = <span class="hljs-number">0</span><br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sumNums</span>(<span class="hljs-params">n</span>):</span><br>    <span class="hljs-keyword">global</span> res<br>    n &gt; <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> sumNums(n<span class="hljs-number">-1</span>) <span class="hljs-comment"># n=1 ç»ˆæ­¢é€’å½’çš„éœ€æ±‚ï¼Œå¯é€šè¿‡çŸ­è·¯æ•ˆåº”å®ç°</span><br>    res += n <br>    <span class="hljs-keyword">return</span> res<br></code></pre></td></tr></table></figure><h4 id="æ•°ç»„ä¸­é‡å¤çš„æ•°å­—"><a href="#æ•°ç»„ä¸­é‡å¤çš„æ•°å­—" class="headerlink" title="æ•°ç»„ä¸­é‡å¤çš„æ•°å­—"></a><a href="https://leetcode-cn.com/problems/shu-zu-zhong-zhong-fu-de-shu-zi-lcof/">æ•°ç»„ä¸­é‡å¤çš„æ•°å­—</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">findRepeatNumber</span>(<span class="hljs-params">nums</span>):</span><br>    fre_dict=&#123;&#125; <span class="hljs-comment"># ä½¿ç”¨å­—å…¸</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> nums:<br>        fre_dict[i] = fre_dict.get(i,<span class="hljs-number">0</span>)+<span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> fre_dict[i]&gt;<span class="hljs-number">1</span>:<br>            <span class="hljs-keyword">return</span> i<br>    <span class="hljs-comment"># å¦ä¸€ç§æ€è·¯ ï¼Œæ’åº æ‰¾nums[i] == nums[i-1]</span><br></code></pre></td></tr></table></figure><h4 id="æ•°ç»„ä¸­æ•°å­—å‡ºç°çš„æ¬¡æ•°"><a href="#æ•°ç»„ä¸­æ•°å­—å‡ºç°çš„æ¬¡æ•°" class="headerlink" title="æ•°ç»„ä¸­æ•°å­—å‡ºç°çš„æ¬¡æ•°"></a><a href="https://leetcode-cn.com/problems/shu-zu-zhong-shu-zi-chu-xian-de-ci-shu-lcof/">æ•°ç»„ä¸­æ•°å­—å‡ºç°çš„æ¬¡æ•°</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">singleNumbers</span>(<span class="hljs-params">nums</span>):</span> <br>    tmp_res = <span class="hljs-number">0</span>     <br>    a,b = <span class="hljs-number">0</span>,<span class="hljs-number">0</span> <br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> nums:<br>        tmp_res = tmp_res ^ i  <span class="hljs-comment"># å‡è®¾éœ€è¦çš„ç»“æœä¸ºä¸ºaå’Œb é‚£ä¹ˆtmp_res = a^b  note: a^a = 0 </span><br>    <span class="hljs-comment"># å°†æ•°ç»„åˆ†æˆä¸¤éƒ¨åˆ† ä¸€éƒ¨åˆ†åªåŒ…å«a  å¦ä¸€éƒ¨åˆ†åªåŒ…å«b</span><br>    pivot = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">while</span> tmp_res&amp;pivot ==<span class="hljs-number">0</span>:<br>        pivot = pivot&lt;&lt;<span class="hljs-number">1</span><br>    <br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> nums:<br>        <span class="hljs-keyword">if</span> i &amp;pivot:<br>            a = a^i<br>        <span class="hljs-keyword">else</span>:<br>            b = b^i<br>    <span class="hljs-keyword">return</span> [a,b]<br></code></pre></td></tr></table></figure><h4 id="æ•°ç»„ä¸­æ•°å­—å‡ºç°çš„æ¬¡æ•°-II"><a href="#æ•°ç»„ä¸­æ•°å­—å‡ºç°çš„æ¬¡æ•°-II" class="headerlink" title="æ•°ç»„ä¸­æ•°å­—å‡ºç°çš„æ¬¡æ•° II"></a><a href="https://leetcode-cn.com/problems/shu-zu-zhong-shu-zi-chu-xian-de-ci-shu-ii-lcof/">æ•°ç»„ä¸­æ•°å­—å‡ºç°çš„æ¬¡æ•° II</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">singleNumber</span>(<span class="hljs-params">nums</span>):</span><br>  <span class="hljs-comment"># 1.æ•°å­¦ (sum(set(nums))*3-sum(nums))//2  2.å­—å…¸æ€è·¯ 3. ä½è¿ç®—</span><br>  <span class="hljs-comment"># a^a = 0  a^0 = a ä½è¿ç®—</span><br>    res = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">32</span>): <span class="hljs-comment"># 1 &lt;= nums[i] &lt; 2^31é™åˆ¶</span><br>        idx = <span class="hljs-number">1</span> &lt;&lt; i  <span class="hljs-comment"># 0001   0010   0010</span><br>        count = <span class="hljs-number">0</span> <br>        <span class="hljs-keyword">for</span> num <span class="hljs-keyword">in</span> nums:<br>            <span class="hljs-keyword">if</span> num &amp; idx !=<span class="hljs-number">0</span>:<br>                count+=<span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> count%<span class="hljs-number">3</span> ==<span class="hljs-number">1</span>: <span class="hljs-comment"># è¡¨æ˜å”¯ä¸€çš„é‚£ä¸ªæ•°åœ¨è¿™ä¸€ä½ä¸Šä¸º1</span><br>            res = res|idx<br>    <span class="hljs-keyword">return</span> res<br></code></pre></td></tr></table></figure><h4 id="äºŒå‰æ ‘çš„æ·±åº¦"><a href="#äºŒå‰æ ‘çš„æ·±åº¦" class="headerlink" title="äºŒå‰æ ‘çš„æ·±åº¦"></a><a href="https://leetcode-cn.com/problems/er-cha-shu-de-shen-du-lcof/">äºŒå‰æ ‘çš„æ·±åº¦</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">maxDepth</span>(<span class="hljs-params">root</span>):</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root:<span class="hljs-keyword">return</span> <span class="hljs-number">0</span> <span class="hljs-comment"># é€’å½’å‡ºå£</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> + max(self.maxDepth(root.left),self.maxDepth(root.right))<br><span class="hljs-comment"># éé€’å½’æ–¹æ³•ï¼š BFS è·å¾—å±‚æ•°å³äºŒå‰æ ‘çš„æ·±åº¦</span><br></code></pre></td></tr></table></figure><h4 id="é“¾è¡¨ä¸­å€’æ•°ç¬¬kä¸ªèŠ‚ç‚¹"><a href="#é“¾è¡¨ä¸­å€’æ•°ç¬¬kä¸ªèŠ‚ç‚¹" class="headerlink" title="é“¾è¡¨ä¸­å€’æ•°ç¬¬kä¸ªèŠ‚ç‚¹"></a><a href="https://leetcode-cn.com/problems/lian-biao-zhong-dao-shu-di-kge-jie-dian-lcof/">é“¾è¡¨ä¸­å€’æ•°ç¬¬kä¸ªèŠ‚ç‚¹</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getKthFromEnd</span>(<span class="hljs-params">head, k</span>):</span><br>    <span class="hljs-comment"># æ€è·¯1: éå†ç»Ÿè®¡é“¾è¡¨é•¿åº¦ï¼Œå€’æ˜¯ç¬¬kä¸ªèŠ‚ç‚¹ä¾¿æ˜¯é¡ºæ•°n-kä¸ªèŠ‚ç‚¹</span><br>    <span class="hljs-comment"># å¿«æ…¢æŒ‡é’ˆæ€è·¯</span><br>    slow,fast = head,head<br>    index = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(k): <span class="hljs-comment"># å¿«æŒ‡é’ˆå…ˆèµ°kæ­¥</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> fast: <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br>        fast = fast.next<br>    <span class="hljs-keyword">while</span> fast:<br>        slow = slow.next<br>        fast = fast.next<br>    <span class="hljs-keyword">return</span> slow<br></code></pre></td></tr></table></figure><h4 id="äºŒå‰æ ‘çš„é•œåƒ"><a href="#äºŒå‰æ ‘çš„é•œåƒ" class="headerlink" title="äºŒå‰æ ‘çš„é•œåƒ"></a><a href="https://leetcode-cn.com/problems/er-cha-shu-de-jing-xiang-lcof/">äºŒå‰æ ‘çš„é•œåƒ</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mirrorTree</span>(<span class="hljs-params">root</span>):</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root: <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span> <span class="hljs-comment"># é€’å½’å‡ºå£</span><br>    root.left, root.right = self.mirrorTree(root.right),self.mirrorTree(root.left)<br>    <span class="hljs-keyword">return</span> root<br><span class="hljs-comment"># éé€’å½’æ–¹æ³•ï¼š BFS å¯¹æ¯ä¸€å±‚è¿›è¡Œè¿­ä»£ </span><br><span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> deque <br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mirrorTree</span>(<span class="hljs-params">root</span>):</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root: <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span> <br>    queue = deque()<br>    queue.append(root)<br>    <span class="hljs-keyword">while</span> queue: <span class="hljs-comment"># å¯¹æ¯ä¸€å±‚çš„æ¯ä¸€ä¸ªèŠ‚ç‚¹è¿›è¡Œéå†</span><br>        node = queue.popleft()<br>        tmp_left, tmp_right =node.left, node.right<br>        <span class="hljs-keyword">if</span> tmp_left:<br>            queue.append(tmp_left)<br>            node.right = tmp_left<br>        <span class="hljs-keyword">else</span>:<br>            node.right = <span class="hljs-literal">None</span><br>        <span class="hljs-keyword">if</span> tmp_right:<br>            queue.append(tmp_right)<br>            node.left = tmp_right  <br>        <span class="hljs-keyword">else</span>:<br>            node.left = <span class="hljs-literal">None</span>              <br>    <span class="hljs-keyword">return</span> root<br></code></pre></td></tr></table></figure><h4 id="æ‰“å°ä»1åˆ°æœ€å¤§çš„nä½æ•°"><a href="#æ‰“å°ä»1åˆ°æœ€å¤§çš„nä½æ•°" class="headerlink" title="æ‰“å°ä»1åˆ°æœ€å¤§çš„nä½æ•°"></a><a href="https://leetcode-cn.com/problems/da-yin-cong-1dao-zui-da-de-nwei-shu-lcof/">æ‰“å°ä»1åˆ°æœ€å¤§çš„nä½æ•°</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">printNumbers</span>(<span class="hljs-params">n</span>):</span><br>    <span class="hljs-keyword">return</span> [ i <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>,<span class="hljs-number">10</span>**n) ]<br></code></pre></td></tr></table></figure><h4 id="æ›¿æ¢ç©ºæ ¼"><a href="#æ›¿æ¢ç©ºæ ¼" class="headerlink" title="æ›¿æ¢ç©ºæ ¼"></a><a href="https://leetcode-cn.com/problems/ti-huan-kong-ge-lcof/">æ›¿æ¢ç©ºæ ¼</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">replaceSpace</span>(<span class="hljs-params">self, s</span>):</span><br>    <span class="hljs-keyword">return</span> s.replace(<span class="hljs-string">&#x27; &#x27;</span>,<span class="hljs-string">&#x27;%20&#x27;</span>)<br></code></pre></td></tr></table></figure><h4 id="ä»å°¾åˆ°å¤´æ‰“å°é“¾è¡¨"><a href="#ä»å°¾åˆ°å¤´æ‰“å°é“¾è¡¨" class="headerlink" title="ä»å°¾åˆ°å¤´æ‰“å°é“¾è¡¨"></a><a href="https://leetcode-cn.com/problems/cong-wei-dao-tou-da-yin-lian-biao-lcof/">ä»å°¾åˆ°å¤´æ‰“å°é“¾è¡¨</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reversePrint</span>(<span class="hljs-params">head</span>):</span><br>    res = []<br>    <span class="hljs-keyword">while</span> head:<br>        res.append(head.val)<br>        head = head.next<br>    <span class="hljs-keyword">return</span> res[::<span class="hljs-number">-1</span>]    <br><span class="hljs-comment"># é€’å½’è§£æ³• return reversePrint(head.next) + [head.val] if head else []</span><br></code></pre></td></tr></table></figure><h4 id="åè½¬é“¾è¡¨"><a href="#åè½¬é“¾è¡¨" class="headerlink" title="åè½¬é“¾è¡¨"></a><a href="https://leetcode-cn.com/problems/fan-zhuan-lian-biao-lcof/">åè½¬é“¾è¡¨</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">reverseList</span>(<span class="hljs-params">head</span>):</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> head: <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span><br>    cur,pre = head,<span class="hljs-literal">None</span><br>    <span class="hljs-keyword">while</span> cur:<br>        tmp = cur.next<br>        cur.next = pre<br>        pre = cur<br>        cur = tmp <br>    <span class="hljs-keyword">return</span> pre <br></code></pre></td></tr></table></figure><h4 id="äºŒå‰æœç´¢æ ‘çš„ç¬¬kå¤§èŠ‚ç‚¹"><a href="#äºŒå‰æœç´¢æ ‘çš„ç¬¬kå¤§èŠ‚ç‚¹" class="headerlink" title="äºŒå‰æœç´¢æ ‘çš„ç¬¬kå¤§èŠ‚ç‚¹"></a><a href="https://leetcode-cn.com/problems/er-cha-sou-suo-shu-de-di-kda-jie-dian-lcof/">äºŒå‰æœç´¢æ ‘çš„ç¬¬kå¤§èŠ‚ç‚¹</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">kthLargest</span>(<span class="hljs-params">root, k</span>):</span><br>    <span class="hljs-comment"># ä¸­åºéå† è·å¾—æœ‰åºæ•°ç»„åè¿”å›ç¬¬kä¸ªå¤§çš„æ•°å­—ã€‚ ä¸­åºéå†ï¼š å·¦å­æ ‘ + root + å³å­æ ‘</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">traverse</span>(<span class="hljs-params">root</span>):</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root: <span class="hljs-keyword">return</span> <br>        res = []<br>        <span class="hljs-keyword">if</span> root.left:<br>            res+=(traverse(root.left)) <span class="hljs-comment"># æ³¨æ„ä¸èƒ½ä½¿ç”¨append  å¦åˆ™ä¼šå½¢æˆä¸€ä¸ªåµŒå¥—åˆ—è¡¨ </span><br>        res.append(root.val)<br>        <span class="hljs-keyword">if</span> root.right:<br>            res+=(traverse(root.right))<br>        <span class="hljs-keyword">return</span> res<br>    res = traverse(root)<br>    <span class="hljs-keyword">return</span> res[-k]<br></code></pre></td></tr></table></figure><h4 id="åˆå¹¶ä¸¤ä¸ªæ’åºçš„é“¾è¡¨"><a href="#åˆå¹¶ä¸¤ä¸ªæ’åºçš„é“¾è¡¨" class="headerlink" title="åˆå¹¶ä¸¤ä¸ªæ’åºçš„é“¾è¡¨####"></a><a href="https://leetcode-cn.com/problems/he-bing-liang-ge-pai-xu-de-lian-biao-lcof/">åˆå¹¶ä¸¤ä¸ªæ’åºçš„é“¾è¡¨</a>####</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">mergeTwoLists</span>(<span class="hljs-params">l1,l2</span>):</span><br>    <span class="hljs-comment"># æ€è·¯1: æ–°å»ºä¸€ä¸ªé“¾è¡¨ï¼Œä¾æ¬¡æ’å…¥åˆé€‚çš„èŠ‚ç‚¹</span><br>    cur = dummy = ListNode(<span class="hljs-number">0</span>) <br>    <span class="hljs-keyword">while</span> l1 <span class="hljs-keyword">and</span> l2:<br>        <span class="hljs-keyword">if</span> l1.val &lt; l2.val:<br>            cur.next, l1 = l1, l1.next<br>        <span class="hljs-keyword">else</span>:<br>            cur.next, l2 = l2, l2.next<br>        cur = cur.next<br>    cur.next = l1 <span class="hljs-keyword">if</span> l1 <span class="hljs-keyword">else</span> l2<br>    <span class="hljs-keyword">return</span> dummy.next<br><br>    <span class="hljs-comment"># æ€è·¯2: ä½¿ç”¨é€’å½’è¿›è¡Œ</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> l1:<span class="hljs-keyword">return</span> l2<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> l2:<span class="hljs-keyword">return</span> l1<br>    <span class="hljs-keyword">if</span> l1.val &lt;= l2.val:<br>        l1.next = self.mergeTwoLists(l1.next,l2)<br>        <span class="hljs-keyword">return</span> l1<br>    <span class="hljs-keyword">else</span>:<br>        l2.next = self.mergeTwoLists(l1,l2.next)<br>        <span class="hljs-keyword">return</span> l2<br></code></pre></td></tr></table></figure><h4 id="äºŒè¿›åˆ¶ä¸­1çš„ä¸ªæ•°"><a href="#äºŒè¿›åˆ¶ä¸­1çš„ä¸ªæ•°" class="headerlink" title="äºŒè¿›åˆ¶ä¸­1çš„ä¸ªæ•°"></a><a href="https://leetcode-cn.com/problems/er-jin-zhi-zhong-1de-ge-shu-lcof/">äºŒè¿›åˆ¶ä¸­1çš„ä¸ªæ•°</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">hammingWeight</span>(<span class="hljs-params">n</span>):</span><br>    <span class="hljs-comment"># ä½è¿ç®— n&amp;(nâˆ’1)  äºŒè¿›åˆ¶æ•°å­—næœ€å³è¾¹çš„ 1 å˜æˆ 0 ï¼Œå…¶ä½™ä¸å˜ã€‚</span><br>    res = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">while</span> n:<br>        res += <span class="hljs-number">1</span><br>        n &amp;= n - <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> res<br>    <span class="hljs-comment"># n&amp;1 =1 =&gt; n äºŒè¿›åˆ¶ æœ€å³ä¸€ä½ ä¸º 1 ï¼›n&amp;1 = 0 =&gt; n äºŒè¿›åˆ¶ æœ€å³ä¸€ä½ ä¸º 0</span><br>    res = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">while</span> n:<br>        res += n&amp;<span class="hljs-number">1</span><br>        n = n&gt;&gt;<span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> res<br></code></pre></td></tr></table></figure><h4 id="ç”¨ä¸¤ä¸ªæ ˆå®ç°é˜Ÿåˆ—"><a href="#ç”¨ä¸¤ä¸ªæ ˆå®ç°é˜Ÿåˆ—" class="headerlink" title="ç”¨ä¸¤ä¸ªæ ˆå®ç°é˜Ÿåˆ—"></a><a href="https://leetcode-cn.com/problems/yong-liang-ge-zhan-shi-xian-dui-lie-lcof/">ç”¨ä¸¤ä¸ªæ ˆå®ç°é˜Ÿåˆ—</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CQueue</span>:</span><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span>(<span class="hljs-params">self</span>):</span><br>       self.A,self.B = [],[]<br>       <span class="hljs-comment"># A è´Ÿè´£å…¥é˜Ÿ  Bè´Ÿè´£å‡ºé˜Ÿ</span><br><br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">appendTail</span>(<span class="hljs-params">self, value</span>):</span><br>        self.A.append(value)<br>    <br>    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">deleteHead</span>(<span class="hljs-params">self</span>):</span><br>        <span class="hljs-keyword">if</span> self.B: <span class="hljs-keyword">return</span> self.B.pop()<br>        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.A: <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span><br>        <span class="hljs-keyword">while</span> self.A:<br>            self.B.append(self.A.pop())<br>        <span class="hljs-keyword">return</span> self.B.pop()<br></code></pre></td></tr></table></figure><h4 id="å¤æ‚é“¾è¡¨çš„å¤åˆ¶-å¾…å®š"><a href="#å¤æ‚é“¾è¡¨çš„å¤åˆ¶-å¾…å®š" class="headerlink" title="å¤æ‚é“¾è¡¨çš„å¤åˆ¶ ##å¾…å®š"></a><a href="https://leetcode-cn.com/problems/fu-za-lian-biao-de-fu-zhi-lcof/">å¤æ‚é“¾è¡¨çš„å¤åˆ¶</a> ##å¾…å®š</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">copyRandomList</span>(<span class="hljs-params">head</span>):</span><br><br></code></pre></td></tr></table></figure><h4 id="äºŒå‰æ ‘çš„æœ€è¿‘å…¬å…±ç¥–å…ˆ-å¾…å®š"><a href="#äºŒå‰æ ‘çš„æœ€è¿‘å…¬å…±ç¥–å…ˆ-å¾…å®š" class="headerlink" title="äºŒå‰æ ‘çš„æœ€è¿‘å…¬å…±ç¥–å…ˆ##å¾…å®š"></a><a href="https://leetcode-cn.com/problems/er-cha-shu-de-zui-jin-gong-gong-zu-xian-lcof/">äºŒå‰æ ‘çš„æœ€è¿‘å…¬å…±ç¥–å…ˆ</a>##å¾…å®š</h4><h4 id="å’Œä¸ºsçš„è¿ç»­æ­£æ•°åºåˆ—"><a href="#å’Œä¸ºsçš„è¿ç»­æ­£æ•°åºåˆ—" class="headerlink" title="å’Œä¸ºsçš„è¿ç»­æ­£æ•°åºåˆ—"></a><a href="https://leetcode-cn.com/problems/he-wei-sde-lian-xu-zheng-shu-xu-lie-lcof/">å’Œä¸ºsçš„è¿ç»­æ­£æ•°åºåˆ—</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">findContinuousSequence</span>(<span class="hljs-params">target</span>):</span><br>    <span class="hljs-comment"># æ»‘åŠ¨çª—å£è§£å†³</span><br>    nums = list(range(<span class="hljs-number">1</span>,(target//<span class="hljs-number">2</span>+<span class="hljs-number">2</span>))) <span class="hljs-comment"># å€™é€‰çš„æœ€å¤§å€¼ä¸ä¼šè¶…é«˜target/2 +1</span><br>    res = []<br>    start_window,total = <span class="hljs-number">0</span>,nums[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">for</span> end_window <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>,len(nums)):<br>        total += nums[end_window]<br>        <span class="hljs-keyword">while</span> total&gt;=target:<br>            <span class="hljs-keyword">if</span> total == target:  <span class="hljs-comment"># çª—å£å’Œ = target =&gt;å½“å‰çª—å£åŠ å…¥ç»“æœ çª—å£èµ·ç‚¹å³ç§»</span><br>                res.append(nums[start_window:end_window+<span class="hljs-number">1</span>])<br>            total -= nums[start_window]<br>            start_window+=<span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> res<br></code></pre></td></tr></table></figure><h4 id="é‡å»ºäºŒå‰æ ‘"><a href="#é‡å»ºäºŒå‰æ ‘" class="headerlink" title="é‡å»ºäºŒå‰æ ‘"></a><a href="https://leetcode-cn.com/problems/zhong-jian-er-cha-shu-lcof/">é‡å»ºäºŒå‰æ ‘</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">buildTree</span>(<span class="hljs-params">preorder, inorder</span>):</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> preorder:<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">None</span> <br>    root = preorder[<span class="hljs-number">0</span>]<br>    pos = inorder.index(root)<br><br>    binary_tree = TreeNode(root)<br>    binary_tree.left = self.buildTree(preorder[<span class="hljs-number">1</span>:pos+<span class="hljs-number">1</span>],inorder[:pos])<br>    binary_tree.right = self.buildTree(preorder[pos+<span class="hljs-number">1</span>:],inorder[pos+<span class="hljs-number">1</span>:])<br>    <span class="hljs-keyword">return</span> binary_tree<br><br></code></pre></td></tr></table></figure><h4 id="ä»ä¸Šåˆ°ä¸‹æ‰“å°äºŒå‰æ ‘-I"><a href="#ä»ä¸Šåˆ°ä¸‹æ‰“å°äºŒå‰æ ‘-I" class="headerlink" title="ä»ä¸Šåˆ°ä¸‹æ‰“å°äºŒå‰æ ‘ I"></a><a href="https://leetcode-cn.com/problems/cong-shang-dao-xia-da-yin-er-cha-shu-lcof/">ä»ä¸Šåˆ°ä¸‹æ‰“å°äºŒå‰æ ‘ I</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">levelOrder</span>(<span class="hljs-params">root</span>):</span><br>    <span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> deque<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root:<span class="hljs-keyword">return</span> []<br>    queue = deque()<br>    queue.append(root)<br>    res = []<br>    <span class="hljs-keyword">while</span> queue:<br>        level_size = len(queue)<br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(level_size):<br>            node = queue.popleft()<br>            <span class="hljs-keyword">if</span> node.left:<br>                queue.append(node.left)<br>            <span class="hljs-keyword">if</span> node.right:<br>                queue.append(node.right)<br>            res.append(node.val)<br>    <span class="hljs-keyword">return</span> res <br></code></pre></td></tr></table></figure><h4 id="ä»ä¸Šåˆ°ä¸‹æ‰“å°äºŒå‰æ ‘-II"><a href="#ä»ä¸Šåˆ°ä¸‹æ‰“å°äºŒå‰æ ‘-II" class="headerlink" title="ä»ä¸Šåˆ°ä¸‹æ‰“å°äºŒå‰æ ‘ II"></a><a href="https://leetcode-cn.com/problems/cong-shang-dao-xia-da-yin-er-cha-shu-ii-lcof/">ä»ä¸Šåˆ°ä¸‹æ‰“å°äºŒå‰æ ‘ II</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">levelOrder</span>(<span class="hljs-params">root</span>):</span><br>    <span class="hljs-comment"># BFS å±‚åºéå† ä½¿ç”¨é˜Ÿåˆ—å®ç°</span><br>    <span class="hljs-keyword">from</span> collections <span class="hljs-keyword">import</span> deque<br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> root: <span class="hljs-keyword">return</span> []<br>    queue = deque()<br>    queue.append(root)<br>    res = []<br>    <span class="hljs-keyword">while</span> queue:<br>        level_size = len(queue)<br>        cur_level = []<br>        <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> range(level_size):<br>            node = queue.popleft()<br>            cur_level.append(node.val)<br>            <span class="hljs-keyword">if</span> node.left:<br>                queue.append(node.left)<br>            <span class="hljs-keyword">if</span> node.right:<br>                queue.append(node.right)<br>        res.append(cur_level)<br>    <span class="hljs-keyword">return</span> res <br></code></pre></td></tr></table></figure><h4 id="ç¤¼ç‰©çš„æœ€å¤§ä»·å€¼"><a href="#ç¤¼ç‰©çš„æœ€å¤§ä»·å€¼" class="headerlink" title="ç¤¼ç‰©çš„æœ€å¤§ä»·å€¼"></a><a href="https://leetcode-cn.com/problems/li-wu-de-zui-da-jie-zhi-lcof/">ç¤¼ç‰©çš„æœ€å¤§ä»·å€¼</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">maxValue</span>(<span class="hljs-params">grid</span>):</span> <br>    <span class="hljs-comment"># äºŒç»´dp  grid[i][j] = max(grid[i][j - 1], grid[i - 1][j]) +  grid[i][j]</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(grid)):<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> range(len(grid[<span class="hljs-number">0</span>])):<br>            <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span> <span class="hljs-keyword">and</span> j == <span class="hljs-number">0</span>: <span class="hljs-keyword">continue</span><br>            <span class="hljs-keyword">if</span> i == <span class="hljs-number">0</span>: grid[i][j] += grid[i][j - <span class="hljs-number">1</span>]<br>            <span class="hljs-keyword">elif</span> j == <span class="hljs-number">0</span>: grid[i][j] += grid[i - <span class="hljs-number">1</span>][j]<br>            <span class="hljs-keyword">else</span>: grid[i][j] += max(grid[i][j - <span class="hljs-number">1</span>], grid[i - <span class="hljs-number">1</span>][j])<br>    <span class="hljs-keyword">return</span> grid[<span class="hljs-number">-1</span>][<span class="hljs-number">-1</span>]<br></code></pre></td></tr></table></figure><h4 id="æ•°ç»„ä¸­å‡ºç°æ¬¡æ•°è¶…è¿‡ä¸€åŠçš„æ•°å­—"><a href="#æ•°ç»„ä¸­å‡ºç°æ¬¡æ•°è¶…è¿‡ä¸€åŠçš„æ•°å­—" class="headerlink" title="æ•°ç»„ä¸­å‡ºç°æ¬¡æ•°è¶…è¿‡ä¸€åŠçš„æ•°å­—"></a><a href="https://leetcode-cn.com/problems/shu-zu-zhong-chu-xian-ci-shu-chao-guo-yi-ban-de-shu-zi-lcof/">æ•°ç»„ä¸­å‡ºç°æ¬¡æ•°è¶…è¿‡ä¸€åŠçš„æ•°å­—</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">majorityElement</span>(<span class="hljs-params">nums</span>):</span><br>    <span class="hljs-keyword">return</span> sorted(nums)[len(nums)//<span class="hljs-number">2</span>]  <span class="hljs-comment">#  æ’åºåå–ä¸­é—´çš„æ•°</span><br><br>    <span class="hljs-comment">#Boyer-Moore æŠ•ç¥¨æ³• O(n)</span><br>    res = nums[<span class="hljs-number">0</span>]<br>    cal = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> nums[<span class="hljs-number">1</span>:]:<br>        <span class="hljs-keyword">if</span> cal ==<span class="hljs-number">0</span>: <br>            res = i<br>        <span class="hljs-keyword">if</span> i == res:<br>            cal+=<span class="hljs-number">1</span><br>        <span class="hljs-keyword">else</span>:<br>            cal-=<span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> res<br></code></pre></td></tr></table></figure><h4 id="å’Œä¸ºsçš„ä¸¤ä¸ªæ•°å­—"><a href="#å’Œä¸ºsçš„ä¸¤ä¸ªæ•°å­—" class="headerlink" title="å’Œä¸ºsçš„ä¸¤ä¸ªæ•°å­—"></a><a href="https://leetcode-cn.com/problems/he-wei-sde-liang-ge-shu-zi-lcof/">å’Œä¸ºsçš„ä¸¤ä¸ªæ•°å­—</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">twoSum</span>(<span class="hljs-params">nums,target</span>):</span>  <br>    left, right = <span class="hljs-number">0</span>,len(nums)<span class="hljs-number">-1</span> <span class="hljs-comment"># ä½¿ç”¨åŒæŒ‡é’ˆ ç©ºé—´å¤æ‚åº¦O(1)</span><br>    <span class="hljs-keyword">while</span> left&lt;right:<br>        sums = nums[left]+nums[right]<br>        <span class="hljs-keyword">if</span> sums&lt;target:<br>            left+=<span class="hljs-number">1</span><br>        <span class="hljs-keyword">elif</span> sums&gt;target:<br>            right-=<span class="hljs-number">1</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> [nums[left],nums[right]]<br>    <span class="hljs-keyword">return</span> []<br></code></pre></td></tr></table></figure><h4 id="ä¸‘æ•°"><a href="#ä¸‘æ•°" class="headerlink" title="ä¸‘æ•°"></a><a href="https://leetcode-cn.com/problems/chou-shu-lcof/">ä¸‘æ•°</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">nthUglyNumber</span>(<span class="hljs-params">n</span>):</span><br>    <span class="hljs-comment"># å¸¦æ¡ä»¶çš„åŠ¨æ€è§„åˆ’</span><br>    dp, a, b, c = [<span class="hljs-number">1</span>] * n, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, n):<br>        n2, n3, n5 = dp[a] * <span class="hljs-number">2</span>, dp[b] * <span class="hljs-number">3</span>, dp[c] * <span class="hljs-number">5</span><br>        dp[i] = min(n2, n3, n5)<br>        <span class="hljs-keyword">if</span> dp[i] == n2: a += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> dp[i] == n3: b += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">if</span> dp[i] == n5: c += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> dp[<span class="hljs-number">-1</span>]<br></code></pre></td></tr></table></figure><h4 id="è°ƒæ•´æ•°ç»„é¡ºåºä½¿å¥‡æ•°ä½äºå¶æ•°å‰é¢"><a href="#è°ƒæ•´æ•°ç»„é¡ºåºä½¿å¥‡æ•°ä½äºå¶æ•°å‰é¢" class="headerlink" title="è°ƒæ•´æ•°ç»„é¡ºåºä½¿å¥‡æ•°ä½äºå¶æ•°å‰é¢"></a><a href="https://leetcode-cn.com/problems/diao-zheng-shu-zu-shun-xu-shi-qi-shu-wei-yu-ou-shu-qian-mian-lcof/">è°ƒæ•´æ•°ç»„é¡ºåºä½¿å¥‡æ•°ä½äºå¶æ•°å‰é¢</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">exchange</span>(<span class="hljs-params">self, nums: List[int]</span>) -&gt; List[int]:</span><br>    left,right = <span class="hljs-number">0</span>,len(nums)<span class="hljs-number">-1</span><br>    <span class="hljs-keyword">while</span> left&lt;right:<br>    <span class="hljs-comment"># ä¿è¯nums[left]å¥‡æ•°,nums[right]ä¸ºå¶æ•°</span><br>        <span class="hljs-keyword">if</span> nums[left]%<span class="hljs-number">2</span>==<span class="hljs-number">1</span>:  <br>            left+=<span class="hljs-number">1</span><br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">if</span> nums[right]%<span class="hljs-number">2</span> ==<span class="hljs-number">1</span>:<br>                nums[left],nums[right]=nums[right],nums[left]<br>                left+=<span class="hljs-number">1</span><br>                right-=<span class="hljs-number">1</span><br>            <span class="hljs-keyword">else</span>:<br>                right-=<span class="hljs-number">1</span><br>    <span class="hljs-keyword">return</span> nums<br></code></pre></td></tr></table></figure><h4 id="è‚¡ç¥¨çš„æœ€å¤§åˆ©æ¶¦"><a href="#è‚¡ç¥¨çš„æœ€å¤§åˆ©æ¶¦" class="headerlink" title="è‚¡ç¥¨çš„æœ€å¤§åˆ©æ¶¦"></a><a href="https://leetcode-cn.com/problems/gu-piao-de-zui-da-li-run-lcof/">è‚¡ç¥¨çš„æœ€å¤§åˆ©æ¶¦</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">maxProfit</span>(<span class="hljs-params">prices</span>):</span><br>    <span class="hljs-comment"># opt[i] = max(opt[i-1],prices[i]-min(prices[:i])) åŠ¨æ€è§„åˆ’è½¬ç§»æ–¹ç¨‹</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> prices: <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>    min_price = prices[<span class="hljs-number">0</span>] <span class="hljs-comment"># å­˜å‚¨å½“å¤©å‰æœ€ä½çš„è‚¡ç¥¨</span><br>    opt = [<span class="hljs-number">0</span>]*len(prices)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>,len(prices)):<br>        <span class="hljs-keyword">if</span> prices[i]&lt;min_price:<br>            min_price = prices[i]<br>        opt[i] = max(opt[i<span class="hljs-number">-1</span>],prices[i]-min_price)<br>    <br>    <span class="hljs-keyword">return</span> opt[<span class="hljs-number">-1</span>]<br></code></pre></td></tr></table></figure><h4 id="åœ†åœˆä¸­æœ€åå‰©ä¸‹çš„æ•°å­—"><a href="#åœ†åœˆä¸­æœ€åå‰©ä¸‹çš„æ•°å­—" class="headerlink" title="åœ†åœˆä¸­æœ€åå‰©ä¸‹çš„æ•°å­—"></a><a href="https://leetcode-cn.com/problems/yuan-quan-zhong-zui-hou-sheng-xia-de-shu-zi-lcof/">åœ†åœˆä¸­æœ€åå‰©ä¸‹çš„æ•°å­—</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python"><br></code></pre></td></tr></table></figure><h4 id="æŠŠå­—ç¬¦ä¸²è½¬æ¢æˆæ•´æ•°"><a href="#æŠŠå­—ç¬¦ä¸²è½¬æ¢æˆæ•´æ•°" class="headerlink" title="æŠŠå­—ç¬¦ä¸²è½¬æ¢æˆæ•´æ•°"></a><a href="https://leetcode-cn.com/problems/ba-zi-fu-chuan-zhuan-huan-cheng-zheng-shu-lcof/">æŠŠå­—ç¬¦ä¸²è½¬æ¢æˆæ•´æ•°</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">strToInt</span>(<span class="hljs-params">self, str: str</span>) -&gt; int:</span><br>    sign,res = <span class="hljs-number">1</span>,<span class="hljs-number">0</span><br>    str = str.strip()<br>    <br>    <span class="hljs-comment"># æƒ…å†µ1: å­—ç¬¦ä¸²åªæœ‰ç©ºæ ¼</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> str: <span class="hljs-keyword">return</span> <span class="hljs-number">0</span> <br>    <span class="hljs-comment"># é¦–å…ˆåˆ¤æ–­ç¬¬ä¸€ä¸ªå­—ç¬¦</span><br>    <span class="hljs-keyword">if</span> str[<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;-&#x27;</span> : sign = <span class="hljs-number">-1</span><br>    <span class="hljs-keyword">elif</span> str[<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;+&#x27;</span>: sign = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">elif</span> <span class="hljs-string">&#x27;0&#x27;</span>&lt;=str[<span class="hljs-number">0</span>]&lt;=<span class="hljs-string">&#x27;9&#x27;</span>:res = res*<span class="hljs-number">10</span> + int(str[<span class="hljs-number">0</span>])<br>    <span class="hljs-keyword">else</span>: <span class="hljs-keyword">return</span> res <br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> str[<span class="hljs-number">1</span>:]:<br>        <span class="hljs-keyword">if</span> <span class="hljs-string">&#x27;0&#x27;</span>&lt;=i&lt;=<span class="hljs-string">&#x27;9&#x27;</span>:<br>            res = res*<span class="hljs-number">10</span> + ord(i) - ord(<span class="hljs-string">&#x27;0&#x27;</span>)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">break</span><br>    <span class="hljs-keyword">if</span> sign&gt; <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">return</span> res <span class="hljs-keyword">if</span> res &lt; <span class="hljs-number">2</span>**<span class="hljs-number">31</span><span class="hljs-number">-1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">2</span>**<span class="hljs-number">31</span><span class="hljs-number">-1</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> res*sign <span class="hljs-keyword">if</span> res*sign &gt; <span class="hljs-number">-2</span>**<span class="hljs-number">31</span> <span class="hljs-keyword">else</span>  <span class="hljs-number">-2</span>**<span class="hljs-number">31</span><br></code></pre></td></tr></table></figure><h4 id="æ•°å€¼çš„æ•´æ•°æ¬¡æ–¹"><a href="#æ•°å€¼çš„æ•´æ•°æ¬¡æ–¹" class="headerlink" title="æ•°å€¼çš„æ•´æ•°æ¬¡æ–¹"></a><a href="https://leetcode-cn.com/problems/shu-zhi-de-zheng-shu-ci-fang-lcof/">æ•°å€¼çš„æ•´æ•°æ¬¡æ–¹</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">myPow</span>(<span class="hljs-params">self, x: float, n: int</span>) -&gt; float:</span><br>    <span class="hljs-comment">### åˆ†æ²»æ€æƒ³</span><br>    <span class="hljs-keyword">if</span> n == <span class="hljs-number">0</span>: <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> <span class="hljs-comment"># base </span><br>    <span class="hljs-keyword">if</span> n&lt;<span class="hljs-number">0</span> : x,n = <span class="hljs-number">1</span>/x,-n  <br>    <span class="hljs-keyword">if</span> n %<span class="hljs-number">2</span> == <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">return</span> self.myPow(x,n//<span class="hljs-number">2</span>)**<span class="hljs-number">2</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> x * self.myPow(x,n//<span class="hljs-number">2</span>)**<span class="hljs-number">2</span><br></code></pre></td></tr></table></figure><h4 id="æ•°å­—åºåˆ—ä¸­æŸä¸€ä½çš„æ•°å­—"><a href="#æ•°å­—åºåˆ—ä¸­æŸä¸€ä½çš„æ•°å­—" class="headerlink" title="æ•°å­—åºåˆ—ä¸­æŸä¸€ä½çš„æ•°å­—"></a><a href="https://leetcode-cn.com/problems/shu-zi-xu-lie-zhong-mou-yi-wei-de-shu-zi-lcof/">æ•°å­—åºåˆ—ä¸­æŸä¸€ä½çš„æ•°å­—</a></h4><h4 id="0ï½n-1ä¸­ç¼ºå¤±çš„æ•°å­—"><a href="#0ï½n-1ä¸­ç¼ºå¤±çš„æ•°å­—" class="headerlink" title="0ï½n-1ä¸­ç¼ºå¤±çš„æ•°å­—"></a><a href="https://leetcode-cn.com/problems/que-shi-de-shu-zi-lcof/">0ï½n-1ä¸­ç¼ºå¤±çš„æ•°å­—</a></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">missingNumber</span>(<span class="hljs-params">self, nums: List[int]</span>) -&gt; int:</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(nums)):<br>        <span class="hljs-keyword">if</span> nums[i] != i:<br>            <span class="hljs-keyword">return</span> i<br>    <span class="hljs-keyword">return</span> len(nums) <span class="hljs-comment"># ç±»ä¼¼ [0]è¿™æ ·çš„æƒ…å†µï¼Œç¼ºå¤±çš„ä¸º1</span><br><br>    <span class="hljs-comment"># æ€è·¯2: æ’åºæ•°ç»„ä¸­çš„æœç´¢é—®é¢˜ï¼Œé¦–å…ˆæƒ³åˆ°&quot;äºŒåˆ†&quot;è§£å†³ã€‚</span><br>    xxx<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Algorithm</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Leetcode</tag>
      
      <tag>Python</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
